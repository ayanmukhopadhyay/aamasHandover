{% extends 'base.html' %}

{% block includes %}
    {% load staticfiles %}
    <link href="{% static "css/specific_elements.css" %}" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
{% endblock %}

{% block content %}

{#<style type="text/css">#}
{#    .tg  {border-collapse:collapse;border-spacing:0;}#}
{#    .tg td{font-family:Arial, sans-serif;font-size:12px;padding:5px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:break-all;border-color:black;white-space: nowrap}#}
{#    .tg th{font-family:Arial, sans-serif;font-size:12px;font-weight:normal;padding:5px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:break-all;border-color:black;white-space: nowrap}#}
{#    .tg .tg-s6z2{border-color:inherit;text-align:center;vertical-align:top}#}
{#    .tg .tg-uys7{border-color:inherit;text-align:center}#}
{#    .tg .tg-us36{border-color:inherit;vertical-align:top}#}
{#    .tg .tg-y2k2{font-weight:bold;text-decoration:underline;border-color:inherit;text-align:center}#}
{#    .tg .tg-yw4l{vertical-align:top}#}
{#    .tg .tg-9353{font-weight:bold;text-decoration:underline;border-color:inherit;text-align:center;vertical-align:top}#}
{#    .tg .tg-s6z2{text-align:center}#}
{#    .tg .tg-hgcj{font-weight:bold;text-align:center}#}
{#    .tg .tg-yw4l{vertical-align:top}#}
{#    .tg .tg-031e{vertical-align:top}#}
{#</style>#}

<style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0;}
    .tg td{font-family:Arial, sans-serif;font-size:12px;padding:5px 5px;border-style:solid;border-width:1px;text-align:center}
    .tg th{font-family:Arial, sans-serif;font-size:12px;font-weight:normal;padding:5px 5px;border-style:solid;border-width:1px;text-align:center}
    .tg .tg-s6z2{border-color:inherit;text-align:center;vertical-align:middle}
    .tg .tg-s6z2{text-align:center}
    .tg .tg-031e{vertical-align:top}
    .tg .tg-s6z3{vertical-align:middle;text-align:center;word-wrap:normal}
</style>

<div>
<table class="tg">
            <tr>
<td class="tg-s6z3">Session<br></td>
{#<td class="tg-s6z2">Paper ID</td>#}
<td class="tg-031e">Authors</td>
<td class="tg-031e">Title</td>
{#<td class="tg-031e"> Abstract</td>#}
</tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 15 (10:30-11:50)<br>Auctions And Mechanism Design 3</td>
{#    <td class="tg-s6z2">232</td>#}
    <td class="tg-031e">Matthias Gerstgrasser</td>
    <td class="tg-031e">On the Complexity of Optimal Correlated Auctions and Reverse Auctions</td>
{#    <td class="tg-031e"> &nbsp;&nbsp; We investigate the problem of finding a revenue-optimal auction with correlated bidders. We give an algorithm for the exact solution for two bidders, and for a 5/3-approximation for many bidders, improving from O runtime to O for both problems by exploiting structural properties of this problem directly. We show that for correlated bidders, reverse auctions behave differently from auctions. For two bidders we discuss a constant-factor reduction in complexity. For k &gt;= 3 bidders, we show that the optimal reverse auction must sometimes buy k copies of the item.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">85</td>#}
    <td class="tg-031e">Mason Wright, Michael Wellman</td>
    <td class="tg-031e">Evaluating the Stability of Non-Adaptive Trading in Continuous Double Auctions</td>
{#    <td class="tg-031e"> The continuous double auction  is the predominant mechanism in modern securities markets. Despite much prior study of CDA strategies, fundamental questions about the CDA remain open, such as:  to what extent can outcomes in a CDA be accurately modeled by optimizing agent actions over only a simple, non-adaptive policy class; and  when and how can a policy that conditions its actions on market state deviate beneficially from an optimally parameterized, but simpler, policy like Zero Intelligence . To investigate these questions, we present an experimental comparison of the strategic stability of policies found by reinforcement learning  over a massive space, or through empirical Nash-equilibrium solving over a smaller space of non-adaptive, ZI policies. Our findings indicate that in a plausible market environment, an adaptive trading policy can deviate beneficially from an equilibrium of ZI traders, by conditioning on signals of the likelihood a trade will execute or the favorability of the current bid and ask. Nevertheless, the surplus earned by well-calibrated ZI policies is empirically observed to be nearly as great as what a deviating reinforcement learner could earn, using a much larger policy space. This finding supports the idea that it is reasonable to use equilibrated ZI traders in studies of CDA market outcomes. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">170</td>#}
    <td class="tg-031e">Eleftherios Anastasiadis, Argyrios Deligkas</td>
    <td class="tg-031e">Heterogeneous Facility Location Games</td>
{#    <td class="tg-031e"> We study heterogeneous $k$-facility location games on a line segment. In this model there are $k$ facilities to be placed on a line segment where each facility serves a different purpose. Thus, the preferences of the agents over the facilities can vary arbitrarily. Our goal is to design strategy proof mechanisms that locate the facilities in a way to maximize the minimum utility among the agents. For $k=1$, if the agents' locations are known, we prove that the mechanism that locates the facility on an optimal location is strategy proof. For $k \geq 2$, we prove that there is no optimal strategy proof mechanism, deterministic or randomized, even when $k=2$ and there are only two agents with known locations. We derive inapproximability bounds for deterministic and randomized strategy proof mechanisms. Finally, we provide strategy proof mechanisms that achieve constant approximation. All of our mechanisms are simple and communication efficient. As a byproduct we show that some of our mechanisms can be used for other objectives as the social welfare and the happiness and achieve constant approximation. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">166</td>#}
    <td class="tg-031e">Wen Shen, Jacob Crandall, Ke Yan, Cristina Lopes</td>
    <td class="tg-031e">Information Design in Crowdfunding under Thresholding Policies</td>
{#    <td class="tg-031e"> In crowdfunding,&nbsp; an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible.&nbsp; We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our results demonstrate that despite its ease of implementation, the immediate-disclosure policy is not optimal when backers follow thresholding policies. With appropriate heuristics, an entrepreneur can benefit from dynamic information disclosure. Our work sheds light on information design in a dynamic setting where agents make decisions using thresholding policies.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 16 (10:30-11:50)<br>Economic Paradigms</td>
{#    <td class="tg-s6z2">414</td>#}
    <td class="tg-031e">Lei Niu, Fenghui Ren, Minjie Zhang</td>
    <td class="tg-031e">Feasible Negotiation Procedures for Multiple Interdependent Negotiations</td>
{#    <td class="tg-031e"> In an agent society, agents usually have different knowledge and goals and perform differently in order to achieve their individual or joint goals. Agent negotiation provides an effective solution to help agents reach agreements on their future behaviours in the society to guarantee their goals can be achieved successfully. In an agent society, agents may need to conduct Multiple Interdependent Negotiations,  with different opponents and for different purposes, in order to achieve a goal. By considering the complexity of negotiation environments, interdependencies, opponents and issues in the agent society, to efficiently conduct MIN is a challenging research issue. To the best of authors' knowledge, most of the state-of-art work primarily focuses on the single negotiation scenario and tries to propose sophisticated negotiation protocols and strategies to help individual agents to succeed in the single negotiation. However, very little work has been done with consideration of interdependencies and trade-offs among multiple negotiations, so as to help both individual agents as well as the agent society, to increase their welfare. This paper promotes the research on agent negotiations from the single negotiation level to the multiple negotiations level. To effectively conduct MIN in an agent society, this paper proposes three feasible negotiation procedures, which attempt to conduct MIN in a successive way, in a concurrent way, and in a clustered way by considering different negotiation situations, respectively. A simulated agent society is built to test the proposed negotiation procedures with random experimental settings. According to the experimental results, the successive negotiation procedure produces the highest time efficiency, the concurrent negotiation procedure promises the highest profits and success rates, and the clustered negotiation procedure provides a well-balanced solution between the negotiation efficiency and effectiveness.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">504</td>#}
    <td class="tg-031e">Benno Kuckuck, Jorg Rothe</td>
    <td class="tg-031e">Sequential Allocation Rules are Separable: Refuting a Conjecture on Scoring-Based Allocation of Indivisible Goods</td>
{#    <td class="tg-031e"> Baumeister et al. introduced scoring allocation correspondences and rules, parameterized by an aggregation function ⋆  and a scoring vector s. Among the properties they studied is separability, a.k.a. consistency [16], a central property important in many social decision contexts. Baumeister et al. [2] show that some common scoring allocation rules fail to be separable and conjecture that “, no positional scoring allocation rule is separable.” We refute this conjecture by showing that  the family of sequential allocation rules—an elicitation-free protocol for allocating indivisible goods based on picking sequences [10]—is separable for each coherent collection of picking sequences, and  every sequential allocation rule can be expressed as a scoring allocation rule for a suitable choice of scoring vector and social welfare ordering.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">423</td>#}
    <td class="tg-031e">David Klaska, Antonin Kucera, Tomas Lamser, Vojtech Rehak</td>
    <td class="tg-031e">Automatic Synthesis of Efficient Regular Strategies in Adversarial Patrolling Games</td>
{#    <td class="tg-031e"> We give a polynomial-time algorithm for synthesizing efficient regular strategies in patrolling games with general topology. Regular strategies use finite-state automata to gather some information about the history of defender's moves, which results in substantially better protection of the targets. So far, the scope of automatic strategy synthesis was limited to positional strategies  or to regular strategies where the underlying finite-state automata had to supplied manually. In this paper, we show how to synthesize the underlying finite-state automata  algorithmically,  and we also design a novel  gradient-based    strategy improvement method which runs in polynomial time and produces high-quality strategies for patrolling games of realistic size. To evaluate the quality of these strategies, we also develop an algorithm for computing an  upper   bound  on the best achievable protection, and compare the quality of the constructed strategies against this bound.   </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">307</td>#}
    <td class="tg-031e">Fanny Pascual, Krzysztof Rzadca, Piotr Skowron</td>
    <td class="tg-031e">Collective Schedules: Scheduling Meets Computational Social Choice</td>
{#    <td class="tg-031e"> When scheduling public works or events in a shared facility one needs to accomodate preferences of a population.&nbsp; We formalize this problem by introducing the notion of a collective schedule. We show how to extend fundamental tools from the social choice theory---the Kemeny rule and the Condorcet principle---to collective scheduling. We study the computational complexity of finding collective schedules. We also perform simulations demonstrating that optimal collective schedules can be found for instances with realistic sizes. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 17 (10:30-11:50)<br>Game Theory 2</td>
{#    <td class="tg-s6z2">503</td>#}
    <td class="tg-031e">Alvaro Perez-Diaz, Enrico Gerding, Frank McGroarty</td>
    <td class="tg-031e">Coordination of Electric Vehicle Aggregators: A Coalitional Approach</td>
{#    <td class="tg-031e">  Given the rapid rise of electric vehicles  worldwide, and the ambitious targets set for the near future, the smart charging of an EV fleet must be seen as a priority. Specifically, we study a scenario where EV charging is managed through self-interested EV aggregators  who compete in the day-ahead market in order to purchase the electricity needed to meet their clients' requirements. In order to reduce electricity costs and lower the impact on electricity markets, we study the possibility of inter-aggregator cooperation. Specifically, we model the system as a coalitional game and prove that the resulting game is superadditive and balanced, hence having a non-empty core. However, due to the game not being convex, the Shapley value is not guaranteed to lie in the core. As an alternative, we propose employing the payment mechanism provided by the least-core, which we show to be in the core in our setting. Furthermore, a realistic empirical evaluation is presented, using real market and driver data from the Iberian Peninsula. The simulations show that large payment reductions can be achieved when using the coordination mechanism. Moreover, we show that the individual payments of the least-core are very close to the Shapley value, suggesting that the payment mechanism is both fair and stable.                 </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">749</td>#}
    <td class="tg-031e">Sai Ganesh, Sameh Mohamed, Georgios Piliouras</td>
    <td class="tg-031e">Three body problems in evolutionary game dynamics: Convergence, Periodicity and Limit Cycles</td>
{#    <td class="tg-031e">  We study the asymptotic behavior of replicator dynamics in settings of network interaction. We&nbsp;focus on three agent graphical games where each edge/game is either a 2x2 zero-sum or a 2x2 coordination/partnership&nbsp;game. Using tools from dynamical systems such as Lyapunov functions and&nbsp;invariant functions we establish that this simple family of games can exhibit an interesting range of behaviors such as global convergence, periodicity for all initial conditions as well as limit cycles.&nbsp;   In contrast, we do not observe more complex behavior such as toroids or chaos whilst it is possible to reproduce them in slightly more complicated settings.    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">756</td>#}
    <td class="tg-031e">Haris Aziz,Serge Gaspers, Edward Lee, Kamran Najeebullah</td>
    <td class="tg-031e">Defender Stackelberg Game with Inverse Geodesic Length as Utility Metric</td>
{#    <td class="tg-031e">  The inverse geodesic length  is a well-known and widely used measure of network performance. It equals the sum of the inverse distances of all pairs of vertices in the network. A Stackelberg game is a strategic game in which one player commits to a strategy while taking into account that other players will respond accordingly. We propose a natural defender-attacker Stackelberg game on a network in which the defender wants to maximize the IGL level of the network and commits to protecting parts of the network while having knowledge of the strength of an attacker that wants to weaken the network. We present several algorithmic and complexity results concerning the problem of finding the optimal commitment for the defender. Some of our computational hardness results also answer open problems posed in prior work on IGL.&nbsp;   </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">176</td>#}
    <td class="tg-031e">Jiarui Gan, Edith Elkind, Michael Wooldridge</td>
    <td class="tg-031e">Stackelberg Security Games with Multiple Uncoordinated Defenders</td>
{#    <td class="tg-031e"> Stackelberg security games have received much attention in recent years. While most existing work focuses on single-defender games, there are many real-world scenarios that involve multiple defenders . It is therefore important to investigate security games with multiple defenders. In this paper, we focus on uncoordinated defenders who jointly protect a set of targets, but may have different valuations for these targets; each defender schedules her own resources and selfishly optimizes her own utility. We generalize the standard  model of Stackelberg security games to this setting and formulate an equilibrium concept that captures the nature of strategic interaction among the players. We argue that an exact equilibrium may fail to exist, and, in fact, deciding whether it exists is NP-hard. However, under mild assumptions, every multi-defender security game admits an $\epsilon$-equilibrium for every $\epsilon&gt;0$, and the respective limit points can be efficiently approximated.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 18 (10:30-11:50)<br>Agent Cooperation 1</td>
{#    <td class="tg-s6z2">632</td>#}
    <td class="tg-031e">Mohammad Rostami, Soheil Kolouri, Kyungnam Kim, Eric Eaton</td>
    <td class="tg-031e">Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition</td>
{#    <td class="tg-031e"> Lifelong machine learning methods acquire knowledge over a series of consecutive tasks, continually building upon their experience.&nbsp; Current lifelong learning algorithms rely upon a single learning agent that has centralized access to all data. In this paper, we extend the idea of lifelong learning from a single agent to a network of multiple agents that collectively learn a series of tasks. Each agent faces some  set of tasks; the key idea is that knowledge learned from these tasks may benefit other agents trying to learn different  tasks.&nbsp; Our Collective Lifelong Learning Algorithm  provides an efficient way for a network of agents to share their learned knowledge in a distributed and decentralized manner, while preserving the privacy of the locally observed data. We provide theoretical guarantees for robust performance&nbsp; of the algorithm and empirically demonstrate that CoLLA outperforms existing approaches for distributed multi-task learning on a variety of data sets.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">403</td>#}
    <td class="tg-031e">Shizhao Sun, Wei Chen, Jiang Bian, Xiaoguang Liu, Tie-Yan Liu</td>
    <td class="tg-031e">Slim-DP: A Multi-Agent System for Communication-Efficient Distributed Deep Learning</td>
{#    <td class="tg-031e"> To afford the huge computational cost, large-scale deep neural networks  are usually trained on the distributed system, especially the widely-used parameter server architecture, consisting of a parameter server as well as multiple local workers with powerful GPU cards. During the training, local workers frequently pull the global model and push their computed gradients from/to the parameter server. Due to the limited bandwidth, such frequent communication will cause severe bottleneck for the training acceleration. As recent attempts to address this problem, quantization methods have been proposed to compress the gradients for efficient communication. However, such methods overlook the effects of compression on the model performance such that they either suffer from a low compression ratio or an accuracy drop. In this paper, to better address this problem, we investigate the distributed deep learning as a multi-agent system  problem. Specifically, 1) local workers and the parameter server are separate agents in the system; 2) the objective of these agents is to maximize the efficacy of the learned model through their cooperative interactions; 3) the strategy of the agents describes how they take actions, i.e. communicate their computed gradients or the global model, given the certain state; 4) rational agents always select the best-response strategy with the optimal utility. Inspired by this, we design a MAS approach for distributed training of DNN. In our method, the agents first estimate the utility  of each action,  and then take the best-response strategy based on their estimated utilities mixed with $\epsilon$-random exploration. We call our new method \emph{Slim-DP} as it, being different from the standard data-parallelism, only communicates a subset of the gradient or the global model. Our experimental results demonstrate that our proposed Slim-DP can reduce more communication cost and achieve better speedup without loss of accuracy than the standard data parallelism and its quantization version.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">489</td>#}
    <td class="tg-031e">Thomy Phan, Lenz Belzner, Thomas Gabor, Kyrill Schmid</td>
    <td class="tg-031e">Leveraging Statistical Multi-Agent Online Planning with Emergent Value Function Approximation</td>
{#    <td class="tg-031e"> Making decisions is a great challenge in distributed autonomous environments due to enormous state spaces and uncertainty. Many online planning algorithms rely on statistical sampling to avoid searching the whole state space, while still being able to make acceptable decisions. However, planning often has to be performed under strict computational constraints making online planning in multi-agent systems highly limited, which could lead to poor system performance, especially in stochastic domains.  In this paper, we propose  Emergent Value function Approximation&nbsp;  for Distributed Environment  an approach to integrate global experience into multi-agent online planning in stochastic domains to consider global effects during local planning. For this purpose, a value function is approximated online based on the emergent system behaviour by using methods of reinforcement learning.  We empirically evaluated EVADE with two statistical multi-agent online planning algorithms in a highly complex and stochastic smart factory environment, where multiple agents need to process various items at a shared set of machines. Our experiments show that EVADE can effectively improve the performance of multi-agent online planning, while offering efficiency w.r.t. the breadth and depth of the planning process. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">656</td>#}
    <td class="tg-031e">Joanna Turner, Qinggang Meng, Gerald Schaefer, Andrea Soltoggio</td>
    <td class="tg-031e">Distributed Strategy Adaptation with a Prediction Function in Multi-Agent Task Allocation</td>
{#    <td class="tg-031e"> Coordinating multiple agents to complete a set of tasks under time constraints is a complex problem. Distributed consensus-based task allocation algorithms address this problem without the need for human supervision. With such algorithms, agents add tasks to their own schedule according to specified allocation strategies. Various factors, such as the available resources and number of tasks, may affect the efficiency of a particular allocation strategy. The novel idea we suggest is that each individual agent can predict the best task inclusion strategy locally, based on the limited task assignment information communicated among networked agents. Using supervised classification learning, a function is trained to predict the most appropriate strategy between two well known insertion heuristics. Using the proposed method, agents are shown to correctly predict and select the optimal insertion heuristic to achieve the overall highest number of task allocations. The adaptive agents consistently match the performances of the best non-adaptive agents across a variety of scenarios. This study aims to demonstrate the possibility and potential performance benefits of giving agents greater decision making capabilities to independently adapt the task allocation process in line with the problem of interest. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 19 (10:30-11:50)<br>Scheduling And Planning</td>
{#    <td class="tg-s6z2">99</td>#}
    <td class="tg-031e">Roman Bartak, Jiri Svancara, Marek Vlk</td>
    <td class="tg-031e">A Scheduling-Based Approach to Multi-Agent Path Finding with Weighted and Capacitated Arcs</td>
{#    <td class="tg-031e"> Multi-agent path finding  deals with the problem of finding a collision-free path for a set of agents. The agents are located at nodes of a directed graph, they can move over the arcs, and each agent has its own destination node. It is not possible for two agents to be at the same node at the same time. The usual setting is that each arc has length one so at any time step, each agent either stays in the node, where it is, or moves to one of its neighboring nodes.     This paper suggests to model the MAPF problem using scheduling techniques, namely, nodes and arcs are seen as resources. The concept of optional activities is used to model which nodes and arcs an agent will visit. We first describe a model, where each agent can visit each node at most once. Then, we extend the model to allow agents re-visiting the nodes.     The major motivation for the scheduling model of MAPF is its capability to naturally include other constraints. We will study particularly the problems, where the capacity of arcs can be greater than one,  and the lengths of arcs can be greater than one . These extensions make the model closer to reality than the original MAPF formulation. We compare the efficiency of models experimentally. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">549</td>#}
    <td class="tg-031e">Wolfgang Hoenig, Scott Kiesel, Andrew Tinka, Joseph Durham, Nora Ayanian</td>
    <td class="tg-031e">Conflict-Based Search with Optimal Task Assignment</td>
{#    <td class="tg-031e"> We consider a variant of the Multi-Agent Path-Finding problem that seeks both task assignments and collision-free paths for a set of agents navigating on a graph, while minimizing the sum of costs of all agents. Our approach extends Conflict-Based Search,  a framework that has been previously used to find collision-free paths for a given fixed task assignment. Our key ideas are to operate on a search forest rather than a search tree and to create the forest on demand, avoiding the factorial explosion of all possible task assignments. We show that our new algorithm, CBS-TA, is complete and optimal. The CBS framework allows us to extend our method to ECBS-TA, a bounded suboptimal version. We provide extensive empirical results comparing CBS-TA to task assignment followed by CBS, Conflict-Based Min-Cost-Flow,  and an integer linear program  solution, demonstrating the advantages of our algorithm. Our results highlight a significant advantage in jointly optimizing the task assignment and path planning for very dense cases compared to the traditional method of solving those two problems independently. For large environments with many robots we show that the traditional approach is reasonable, but that we can achieve similar results with the same runtime but stronger suboptimality guarantees. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">480</td>#}
    <td class="tg-031e">Bruno Escoffier, Evripidis Bampis, Sasa Mladenovic</td>
    <td class="tg-031e">Fair resource allocation over time</td>
{#    <td class="tg-031e"> We consider the over-time version of the Max-Min Fair Allocation problem. In the usual  problem, given a set of resources and a set of agents, we have to allocate the resources to agents in such a way that the utility of the least happiest agent is maximized. In the over-time version there is a time horizon t=1,2,..., T, with at each time t a set of agents and a set of available resources that may change over the time defining instance I_t; we seek a sequence of allocations  that&nbsp;  are near-optimal at each time t, and  are as stable as possible: we want to minimize transition costs induced by modification between allocations at time t and time .   We focus on the impact of the knowledge of the future on the quality and the stability of the returned solutions by distinguishing three settings: the off-line setting where the whole set of instances through the time horizon is known in advance, the online setting where no future instance is known, and the k-lookahead setting where at time t, the instances at times t+1,..., t+k are known. We first consider the case without restrictions where the set of resources and the set of agents are the same for all instances and where every resource can be allocated to any agent. For the off-line setting, we show that the over-time version of the problem is much harder than the static one, since it becomes NP-hard even for families of instances for which the static problem is trivial. Then, we provide a r/-approximation algorithm for the off-line setting using as&nbsp; subroutine an r-approximation algorithm for the static version. We also give a r/-competitive algorithm for the online setting using also as subroutine an r-approximation algorithm for the static version.   Furthermore, for the case with restrictions, we show that in the off-line setting it is possible to get a polynomial-time algorithm with the same approximation ratio as in the case without restrictions, while for the online setting, we prove that it is not possible to find an online algorithm with bounded competitive ratio. For the 1-lookahead setting however, we give a r/-approximation algorithm using as subroutine an r-approximation algorithm for the static version.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS4</td>#}
    <td class="tg-031e">Vivek Nallur and Siobhan Clarke</td>
    <td class="tg-031e">Clonal Plasticity: An Autonomic Mechanism for Multi-Agent Systems to Self-Diversify</td>
    <td class="tg-031e"></td>
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 20 (10:30-11:50)<br>Agent-Based Simulation 1</td>
{#    <td class="tg-s6z2">262</td>#}
    <td class="tg-031e">Emilio Cruciani, Emanuele Natale, Andre Nusser, Giacomo Scornavacca</td>
    <td class="tg-031e">Phase Transition of the 2-Choices Dynamics on Core-Periphery Networks</td>
{#    <td class="tg-031e"> Consider the following process on a network: Each agent initially holds either opinion  blue &nbsp;or  red ; then, in each round, each agent looks at two random neighbors and, if the two have the same opinion, the agent adopts it. This process is known as the  2-Choices &nbsp;dynamics and is arguably the most basic non-trivial  opinion dynamics &nbsp;modeling voting behavior on social networks. Despite its apparent simplicity, 2-Choices has been analytically characterized only on networks with a strong expansion property - under assumptions on the initial configuration that establish it as a fast  majority consensus  protocol.&nbsp;  In this work, we aim at contributing to the understanding of the 2-Choices dynamics by considering its behavior on a class of networks with Core-Periphery structure, a well-known topological assumption in social networks. In a nutshell, assume that a densely-connected subset of agents, the  core,  holds a different opinion from the rest of the network, the  periphery . Then, depending on the strength of the cut between the core and the periphery, a phase-transition phenomenon occurs: Either the core's opinion rapidly spreads among the rest of the network, or a  metastability &nbsp;phase takes place, in which both opinions coexist in the network for superpolynomial time. The interest of our result is twofold. On the one hand, by looking at the 2-Choices dynamics as a simplistic model of competition among opinions in social networks, our theorem sheds light on the  influence &nbsp;of the core on the rest of the network, as a function of the core's connectivity towards the latter. On the other hand, to the best of our knowledge, we provide the first analytical result which shows a heterogeneous behavior of a simple dynamics as a function of structural parameters of the network. Finally, we validate our theoretical predictions with extensive experiments on real networks. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">334</td>#}
    <td class="tg-031e">Flavio Pinheiro, Fernando Santos</td>
    <td class="tg-031e">Local Wealth Redistribution Promotes Cooperation in Multiagent Systems</td>
{#    <td class="tg-031e"> Designing mechanisms that promote cooperation in Multiagent Systems has been a long-lasting goal in artificial intelligence. The task is especially challenging when agents are selfish, lack common goals and face social dilemmas, i.e., situations in which individual interest conflicts with social welfare. Past works explored mechanisms that explain cooperation in biological and social systems, providing important clues for the aim of designing cooperative artificial societies. In particular, several works show that cooperation is able to emerge when specific network structures underlie agents' interactions. Notwithstanding, social dilemmas in which defection is highly tempting still lack mechanisms that allow cooperation to be effectively sustained. Here we propose a new redistribution mechanism that can be applied in structured populations of agents. Importantly, we show that, when implemented locally,  redistribution excels in promoting cooperation under regimes where, before, only defection prevailed. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">443</td>#}
    <td class="tg-031e">Yixi Wang, Jianye Hao, Ho-fung Leung, Jianguo Wei, Wenhuan Lu</td>
    <td class="tg-031e">Efficient Convention Emergence through Decoupled Reinforcement Social Learning with Teacher-Student Mechanism</td>
{#    <td class="tg-031e"> In this paper, we design reinforcement learning based  strategies to promote convention emergence in multiagent systems  with large convention space. We apply our approaches to a language coordination problem in which agents need to coordinate on a dominant lexicon for efficient communication. By modeling each lexicon which maps each concept to a single word as a Markov strategy representation, the original single-state convention learning problem can be transformed into a muti-state multiagent coordination problem. The dynamics of lexicon evolutions during an interaction episode can be modeled as a Markov game, which allows agents to improve the action values of each concept separately and incrementally. Specifically we propose two learning strategies, multiple-Q and multiple-R, and also propose incorporating teacher-student mechanism on top of the learning strategies to accelerate lexicon convergence speed. Extensive experiments verify that our approaches outperform the state-of-the-art approaches in terms of convergence efficiency and convention quality.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">398</td>#}
    <td class="tg-031e">Raquel Roses, Cristina Kadar, Charlotte Gerritsen, Chris Ovi Rouly</td>
    <td class="tg-031e">Agent-Based Simulation of Offender Mobility: Integrating Activity Nodes from Location-Based Social Networks</td>
{#    <td class="tg-031e">In recent#}
{#    years, simulation techniques have been applied to investigate the#}
{#    spatio-temporal dynamics of crime. Researchers have instantiated mobile offenders#}
{#    in agent-based simulations for theory testing, experimenting with prevention#}
{#    strategies, and crime prediction purposes, despite facing challenges due to the#}
{#    complex dynamics of crime and the lack of detailed information about offender#}
{#    mobility. This paper presents an agent-based model to explore offender#}
{#    mobility, focusing on the interplay between the agent’s awareness space and#}
{#    activity nodes. To instantiate a realistic urban environment, we use open and location-based#}
{#    social networks data to design the road network, and as proxy for human#}
{#    activity we use activity nodes, respectively. 18 mobility strategies have been#}
{#    tested, combining search distance strategies  and target selection strategies#}
{#    . We analyze and compare the different mobility#}
{#    strategies, and show the impact of using activity nodes extracted from social#}
{#    networks to simulate offender mobility. This agent-based model provides a basis#}
{#    for comparing offender mobility in crime simulations by inferring offender#}
{#    mobility in urban areas from real world data.#}
{##}
{#     </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 21 (10:30-11:50)<br>Engineering Multiagent Systems 1</td>
{#    <td class="tg-s6z2">543</td>#}
    <td class="tg-031e">Andrei Ciortea, Simon Mayer, Florian Michahelles</td>
    <td class="tg-031e">Repurposing Manufacturing Lines on the Fly with Multi-agent Systems for the Web of Things</td>
{#    <td class="tg-031e"> Multi-agent systems  have long been envisioned as a key enabling technology in manufacturing, but this promise is yet to be realized: the lack of proper models, architectures, tooling, and the high level of expertise required for designing and programming agent-based manufacturing systems hindered their large-scale acceptance. The emerging Web of Things now being standardized at W3C and IETF provides new research opportunities that can help MAS enter the mainstream and achieve their long-promised impact. In this paper, we integrate these new developments with MAS and automated planning in order to design scalable and flexible agent-based manufacturing systems that can be re-purposed on-the-fly: our agents synthesize production plans using semantic descriptions of Web-based artifacts and coordinate with one another via semantic organizations. The deployed systems use the Web as an application architecture,  which facilitates the seamless integration of geographically distributed production cells. Engineers can program and re-purpose the systems using an intuitive interface that runs in any standard Web browser and on any device. To demonstrate our approach, we implemented a prototypical production cell that integrates two industry-grade robots and an augmented reality interface for human workers. Together, these contributions demonstrate a means to achieve an intriguing vision for the forthcoming fourth industrial revolution: a global collective intelligence for manufacturing. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">689</td>#}
    <td class="tg-031e">Shahrzad Gholami, Milind Tambe, Sara Mc Carthy, Bistra Dilkina, Andrew Plumptre, Margaret Driciru, Fred Wanyama, Aggrey Rwetsiba, Mustapha Nsubaga, Joshua Mabonga, Eric Enyel, Tom Okello </td>
    <td class="tg-031e">Adversary models account for imperfect crime data: Forecasting and planning against real-world poachers</td>
{#    <td class="tg-031e"> Poachers are engaged in extinction#}
{#    level wholesale slaughter, so it is critical to harness historical data for#}
{#    predicting poachers' behavior. However, in these domains, data collected about#}
{#    adversarial actions are remarkably imperfect, where reported negative instances#}
{#    of crime may be mislabeled or uncertain. Unfortunately, past attempts to#}
{#    develop predictive and prescriptive models to address this problem suffer from#}
{#    shortcomings from a modeling perspective as well as in the implementability of#}
{#    their techniques. Most notably these models i) neglect the uncertainty in crime#}
{#    data, leading to inaccurate and biased predictions of adversary behavior, ii)#}
{#    use coarse-grained crime analysis and iii) do not provide a convincing#}
{#    evaluation as they only look at a single protected area. Additionally, they iv)#}
{#    proposed time-consuming techniques which cannot be directly integrated into low#}
{#    resource outposts. In this innovative application paper, we  introduce#}
{#    iWare-E a novel imperfect-observation aWare Ensemble  technique, which#}
{#    is designed to handle the uncertainty in crime information efficiently. This#}
{#    approach leads to superior accuracy for adversary behavior prediction  compared to the previous state-of-the-art. We also demonstrate#}
{#    the country-wide efficiency of the models and are the first to  evaluate#}
{#    our adversary behavioral model across different protected areas in Uganda,#}
{#    i.e., Murchison Fall and Queen Elizabeth National,  as#}
{#    well as  on fine-grained temporal resolutions. Lastly,  we provide a#}
{#    scalable planning algorithm to design fine-grained patrol routes for the rangers,#}
{#    which achieves up to 150% improvement in number of predicted attacks detected.#}
{#    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">471</td>#}
    <td class="tg-031e">Jan Mrkos, Antonin Komenda, Michal Jakob</td>
    <td class="tg-031e">Revenue Maximization for Electric Vehicle Charging Service Providers using Sequential Dynamic Pricing</td>
{#    <td class="tg-031e">With the rising penetration of electric vehicles,  the provision of EV charging is becoming a standard commercial service. With this shift, EV charging service providers are looking for ways to make their business more profitable. Dynamic pricing is a proven technique to increase revenue in markets with time-variant, heterogeneous demand. In this paper, we propose a Markov Decision Process -based approach to revenue-maximizing dynamic pricing for charging service providers. We implement the approach using an ensemble of policy iteration MDP solvers and evaluate it using a simulation based on real-world data. We show that our proposed method achieves significantly higher revenue than methods utilizing flat-based pricing. In addition to achieving higher revenue for charging service providers, the method also increases the efficiency of allocation measured in terms of the total utilization of the charging station.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">184</td>#}
    <td class="tg-031e">Bryan Wilder,Han Ching Ou, Kayla de la Haye, Milind Tambe</td>
    <td class="tg-031e">Optimizing network structure for preventative health</td>
{#    <td class="tg-031e"> Diseases such as heart disease, stroke, or diabetes affect hundreds of millions of people. Such conditions are strongly impacted by obesity, and establishing healthy lifestyle behaviors is a critical public health challenge with many applications. Changing health behaviors is inherently a multiagent problem since people's behavior is strongly influenced by those around them. Hence, practitioners often attempt to modify the social network of a community by adding or removing edges in ways that will lead to desirable behavior change. To our knowledge, no previous work considers the algorithmic problem of finding the optimal set of edges to add and remove. We propose the RECONNECT algorithm, which efficiently finds high-quality solutions for a range of different network intervention problems. We evaluate RECONNECT in a highly realistic simulated environment based on the Antelope Valley region in California which draws on demographic, social, and health-related data. We find the RECONNECT outperforms an array of baseline policies, in some cases yielding a 150% improvement over the best alternative.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 22 (10:30-11:50)<br>Robotics: Human-Robot Interaction</td>
{#    <td class="tg-s6z2">R70</td>#}
    <td class="tg-031e">Mihai Pomarlan, John Bateman</td>
    <td class="tg-031e">Robot Program Construction via Grounded Natural Language Semantics & Simulation</td>
{#    <td class="tg-031e"> Robots acting in semi-structured, human environments need to understand the effects of their actions and the instructions given by a human user. Simulation has been considered a promising reasoning technique to help tackle both problems. In this paper, we present a system that constructs an executable robot program from a linguistic semantic specification resulting from parsing a natural language sentence; in effect, our system grounds the semantic specification into the produced robot plan. The plan can then be run in a simulated environment, which allows one to infer more about the plan than was present in the initial semantic specification. Our system allows modeling how actions can be modified by subclauses, which we showcase by a transport action. Simulation runs allow discovery of better parameters, either locally for a subtask or such that the entire task is better performed; simulation reveals these parameterizations may differ.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R73</td>#}
    <td class="tg-031e">Andrea Vanzo, Jose Luis Part, Yanchao Yu, Daniele Nardi, Oliver Lemon</td>
    <td class="tg-031e">Incrementally Learning Semantic Attributes through Dialogue Interaction</td>
{#    <td class="tg-031e"> Enabling a robot to properly interact with users plays a key role in the effective deployment of robotic platforms in domestic environments. Robots must be able to rely on interaction to improve their behaviour and adaptively understand their operational world. Semantic mapping is the task of building a representation of the environment, that can be enhanced through interaction with the user. In this task, a proper and effective acquisition of semantic attributes of targeted entities is essential for the task accomplishment itself. In this paper, we focus on the problem of learning dialogue policies to support semantic attributes acquisition, that optimise the effort required by humans in providing knowledge to the robot through dialogue. To this end, we design our Dialogue Manager as a hierarchical Markov Decision Process, solving the optimisation problem through Reinforcement Learning. The Dialogue Manager depends on an on-line incremental visual classifier, based on a Load-Balancing Self-Organizing Incremental Neural Network . Experiments in a simulated scenario show the effectiveness of the proposed solution, suggesting that perceptual information can be properly exploited to reduce human tutoring cost.Moreover, a policy trained on a small amount of data generalises well to larger datasets, and so the proposed on-line scheme, as well as the real-time nature of the processing, are suited for an extensive deployment in real scenarios. To this end, the whole system has been tested on a real robot. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R76</td>#}
    <td class="tg-031e">Dogancan Kebude, Cem Eteke, Tevfik Metin Sezgin, Baris Akgun</td>
    <td class="tg-031e">Communicative Cues for Reach-to-Grasp Motions: From Humans to Robots</td>
{#    <td class="tg-031e">Intent communication is an important challenge in the context of human-robot interaction. The aim of this work is to identify subtle non-verbal cues that make communication among humans fluent and using them to generate intent expressive robot motion. A human-human reach-to-grasp experiment  identified two temporal and two spatial cues:  relative time to reach maximum hand aperture,   overall motion duration,   exaggeration in motion,  and  change in grasp modality . Results showed there was statistically significant difference in the temporal cues between no-intention and intention conditions. A follow-up experiment  was conducted based on these results. Reach-to-grasp motions of a simulated robot containing different cue combinations were shown to the participants. They were asked to guess the target object during robot's motion, based on the assumption that intent expressive motion would result in earlier and more accurate guesses. Results showed that, OT, GM and several cue combinations led to faster and more accurate guesses which imply they can be used to generate communicative motion. However, MA had no effect, and surprisingly Exg had a negative effect on expressiveness.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R103</td>#}
    <td class="tg-031e">Michiel de Jong, Kevin Zhang, Aaron Roth, Travers Rhodes, Robin Schmucker, Chenghui Zhou, Sofia Ferreira, Joao Cartucho, Manuela Veloso</td>
    <td class="tg-031e">Towards a Robust Interactive and Learning Social Robot</td>
{#    <td class="tg-031e">Pepper is a humanoid robot, specifically designed for social interaction, that has been deployed in a variety of public environments. A programmable version of Pepper is also available, enabling our focused research on perception and behavior robustness and capabilities of an interactive social robot. We address Pepper perception by integrating state-of-the-art vision and speech recognition systems and experimentally analyzing their effectiveness. As we recognize limitations of the individual perceptual modalities, we introduce a multi-modality approach to increase the robustness of human social interaction with the robot. We combine vision, gesture, speech, and input from an onboard tablet, a remote mobile phone, and external microphones. Our approach includes the proactive seeking of input from a different modality, adding robustness to the failures of the separate components. We also introduce a learning algorithm to improve communication capabilities over time, updating speech recognition through social interactions. Finally, we realize the rich robot body-sensory data and introduce both a nearest-neighbor and a deep learning approach to enable Pepper to classify and speak up a variety of its own body motions. We view the contributions of our work to be relevant both to Pepper specifically and to other general social robots.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 23 (13:30-15:30)<br>Applications Of Game Theory</td>
{#    <td class="tg-s6z2">648</td>#}
    <td class="tg-031e">Aaron Schlenker, Milind Tambe, Long Tran-Thanh, Phebe Vayanos, Yevgeniy Vorobeychik, Omkar Thakoor, Haifeng Xu, Fei Fang </td>
    <td class="tg-031e">Deceiving Cyber Adversaries: A Game Theoretic Approach</td>
{#    <td class="tg-031e"> An important way cyber adversaries find vulnerabilities in modern networks is through reconnaissance, in which they attempt to identify configuration specifics of network hosts. To increase uncertainty of adversarial reconnaissance, the network administrator  can introduce deception into responses to network scans, such as obscuring certain system characteristics.  We introduce a novel game theoretic model of deceptive interactions of this kind between a defender and a cyber attacker, which we call the Cyber Deception Game. We consider both a powerful  attacker, who is knows the defender's exact deception strategy, and a naive attacker who is not. We show that the problem is NP-hard for both types of attackers. For the case with a powerful attacker, we provide a mixed-integer linear program solution, sped up with a novel cut generation method, as well as a fast and effective greedy algorithm. Similarly, we provide complexity results and propose exact and heuristic approaches when the attacker is naive. Our extensive experimental analysis demonstrates the effectiveness of our approaches. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">342</td>#}
    <td class="tg-031e">Atiyeh Ashari Ghomi, Allan Borodin, Omer Lev</td>
    <td class="tg-031e">Seasonal Goods and Spoiled Milk: Pricing for a Limited Shelf-Life</td>
{#    <td class="tg-031e"> We examine the case of items with a limited shelf-life where storing an item  may carry a cost to a buyer . For example, eggs, milk, or Groupon coupons have a fixed expiry date, and seasonal goods can suffer a decrease in value. We show how this setting contrasts with recent results by Berbeglia et al. for items with infinite shelf-life.  We prove tight bounds on the seller's profits showing how they relate to the items' shelf-life. We show, counterintuitively, that in our limited shelf-life setting, increasing storage costs can sometimes lead to less profit for the seller which cannot happen when items have unlimited shelf-life. We also provide an algorithm that calculates optimal prices.  Finally, we examine empirically the relationship between profits and buyer utility as the storage cost and shelf-life duration change, and observe properties, some of which are unique to the limited shelf-life setting. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">151</td>#}
    <td class="tg-031e">Mohammad Irfan, Tucker Gordon</td>
    <td class="tg-031e">The Power of Context in Networks: Ideal Point Models with Social Interactions</td>
{#    <td class="tg-031e"> Game theory has been widely used for modeling strategic behaviors in networked multiagent systems. However, the context within which these strategic behaviors take place has not received much attention. We present a model of strategic behavior in networks that incorporates the behavioral context. We focus on the contextual aspects of Senate voting. A senator's decision to vote  yea &nbsp;or  nay &nbsp;on a bill comes as a result of their ideologies, agendas, and their interactions with other senators. One salient model in political science is the  ideal point model,  which assigns each senator and each bill a number on the real line of political spectrum. These points then allow for prediction of future voting behavior. We extend the classical ideal point model with network-structured interactions among senators. In contrast to the ideal point model's prediction of individual voting behavior, we predict  joint voting behaviors &nbsp;in a game-theoretic fashion. Our model also includes the characteristics of a bill. This allows it to outperform previous models that solely focus on the networked interactions among senators with no bill-specific parameters. We focus on two fundamental questions: learning the model using real-world data and computing  stable outcomes &nbsp;of the model in order to predict joint voting behaviors. We demonstrate the effectiveness of our model through experiments using data from the 114th U.S. Congress. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">339</td>#}
    <td class="tg-031e">Kai Wang, Qingyu Guo, Phebe Vayanos, Milind Tambe, Bo An</td>
    <td class="tg-031e">Equilibrium Refinement in Security Games with Arbitrary Scheduling Constraints</td>
{#    <td class="tg-031e"> Significant research effort in security games has focused in devising strategies that perform well even when the attacker deviates from optimal  behavior. In most of these frameworks, a price needs to be paid to ensure robustness against this unpredictability. However, equilibrium refinement is an attractive alternative to boost solution robustness at no cost even though it has not received as much attention in security game literature. In this framework, resources are strategically allocated to secure an optimal outcome against a rational adversary while simultaneously protecting other targets to ensure good outcomes against boundedly rational or constrained attackers. Unfortunately, existing approaches for equilibrium refinement in security games cannot effectively address scheduling constraints that arise frequently in real-world applications. In this paper, we aim to fill this gap and make several key contributions. First, we show that existing approaches for equilibrium refinement can fail in the presence of scheduling constraints. Second, we investigate the properties of the best response of the attacker. Third, we leverage these properties to devise novel iterative algorithms to compute the optimally refined equilibrium, with polynomially many calls to an LP oracle for zero-sum games. Finally, we conduct extensive experimental evaluations that showcase i) the superior performance of our approach in the face of a boundedly rational attacker and ii) the attractive scalability properties of our algorithm that can solve realistic-sized instances. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">716</td>#}
    <td class="tg-031e">Weiran Shen, Pingzhong Tang, Yuan Deng</td>
    <td class="tg-031e">Coalitional Permutation Manipulations in the Gale-Shapley Algorithm</td>
{#    <td class="tg-031e"> In this paper, we consider permutation manipulations by any subset of women, which is motivated by the college admissions process in China. Our result also answer the open problem on what can be achieved by permutation manipulations. We present an efficient algorithm to find a strategy profile such that the induced matching is stable and Pareto-optimal while the strategy profile itself is inconspicuous. Surprisingly, we show that such a strategy profile actually forms a Nash equilibrium of the manipulation game.#}
{#        In the end, we show that it is NP-complete to find a manipulation that is strictly better for all members of the coalition. This result demonstrates a sharp contrast between weakly better off outcomes and strictly better off outcomes.#}
{#     </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">269</td>#}
    <td class="tg-031e">Gianpiero Monaco, Luca Moscardelli, Yllka Velaj</td>
    <td class="tg-031e">Stable Outcomes in Modified Fractional Hedonic Games</td>
{#    <td class="tg-031e"> In  coalition formation games  self-organized coalitions are created as a result of the strategic interactions of independent agents. For each couple of agents,  weight w i,j  = w j,i  reflects how much agents i and j benefit from belonging to the same coalition. We consider the modified fractional hedonic game, that is a coalition formation game in which agents’ utilities are such that the total benefit of agent i belonging to a coalition  is averaged over all the other members of that coalition, i.e., excluding herself. Modified fractional hedonic games constitute a class of succinctly representable hedonic games.   We are interested in the scenario in which agents, individually or jointly, choose to form a new coalition or to join an existing one, until a stable outcome is reached. To this aim, we consider common stability notions, leading to strong Nash stable outcomes, Nash stable outcomes or core stable outcomes: we study their existence, complexity and performance, both in the case of general weights and in the case of 0-1 weights. In particular, we completely characterize the existence of the considered stable outcomes and show many tight or asymptotically tight results on the performance of these natural stable outcomes for modified fractional hedonic games, also highlighting the differences with respect to the model of fractional hedonic games, in which the total benefit of an agent in a coalition is averaged over all members of that coalition, i.e., including herself. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="5" nowrap>Session 24 (13:30-15:30)<br>Social Choice Theory 2</td>
{#    <td class="tg-s6z2">612</td>#}
    <td class="tg-031e">Ulle Endriss </td>
    <td class="tg-031e">Judgment Aggregation with Rationality and Feasibility Constraints</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">322</td>#}
    <td class="tg-031e">Andrea Loreggia, Nicholas Mattei, Francesca Rossi, K. Brent Venable</td>
    <td class="tg-031e">On the Distance Between CP-nets</td>
{#    <td class="tg-031e"> Preferences play a key role in decision making, whether such decision are made by a single individual or a group. In a multi-agent context, it is also important to know how to aggregate preferences to reach a collective decision. Moreover, being able to measure the distance between the preference of two individuals is important to identify the amount of disagreement and possibly reach consensus. In this paper we define a notion of distance between CP-nets, a formalism that can compactly encode conditional qualitative preferences. We consider the Kendall-tau distance between the partial orders induced by CP-nets, and we define two tractable approximations of that distance, which can be computed in time polynomial in the number of features of the CP-nets. We then perform experiments to demonstrate the quality of these approximations compared to the Kendall-tau distance. We also relate our two notions of distance to the distance rationalizability of sequential plurality voting for CP-nets. </td>#}
    </tr>
{#    <tr>#}
{# <td class="tg-s6z2">110</td>#}
{#    <td class="tg-031e">Haris Aziz</td>#}
{#    <td class="tg-031e">Generalizing Top Trading Cycles for Housing Markets with Fractional Endowments</td>#}
{#    <td class="tg-031e"> The housing market setting constitutes a fundamental model of exchange economies of goods. Most of the work concerning housing markets does not cater for randomized assignments or allocation of time-shares. Recently, house allocation with fractional endowment of houses was considered by Athanassoglou and Sethuraman  who posed the open problem of generalizing Gale's Top Trading Cycles  algorithm for fractional endowments. In this paper, we present a generalization of TTC called FTTC that is polynomial-time as well as core stable and Pareto optimal with respect to stochastic dominance. For the standard setting in which each agent owns one discrete house, FTTC coincides with a state of the art strategyproof mechanism for housing markets with discrete endowments and weak preferences. We show that FTTC satisfies a maximal set of desirable properties by proving two impossibility theorems. One of the theorems implies several impossibility results in the literature.&nbsp;  </td>#}
{#    </tr>#}
    <tr>
{#    <td class="tg-s6z2">109</td>#}
    <td class="tg-031e">Haris Aziz, Jiayin Chen, Serge Gaspers, Zhaohong Sun</td>
    <td class="tg-031e">Stability and Pareto Optimality in Refugee Allocation Matchings</td>
{#    <td class="tg-031e"> We focus on the refugee matching problem---a general ``two-sided matching under preferences'' model with multi-dimensional feasibility constraints that was formalized by Delacretaz, Kominers, and Teytelboym . We propose a taxonomy of stability concepts for the problem; identify relations between them; and show that even for two natural weakenings of the standard stability concept, &nbsp;non-existence and NP-hardness results persist. We then identify several natural weaker stability concepts for which we present a polynomial-time and strategy-proof algorithm that returns a stable matching. We also examine the complexity of computing and {testing} Pareto optimal matchings.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">198</td>#}
    <td class="tg-031e">Nawal Benabbou, Mithun Chakraborty, Xuan-Vinh Ho, Jakub Sliwinski, Yair Zick</td>
    <td class="tg-031e">Diversity Constraints in Public Housing Allocation</td>
{#    <td class="tg-031e"> The state of Singapore operates a national public housing program, accounting for over $80\%$ of its residential real estate. Singapore uses its housing allocation program to ensure ethnic diversity in its neighborhoods; it does so by imposing ethnic quotas: every ethnic group must not own more than a certain percentage in a housing project, thus ensuring that every neighborhood contains members from each ethnic group. However, imposing diversity constraints naturally results in some welfare loss. Our work studies the tradeoff between diversity and social welfare from the perspective of computational economics. We model the problem as a an extension of the classic assignment problem, with additional diversity constraints. While the classic assignment program is poly-time computable, we show that adding diversity constraints makes the problem computationally intractable; however, we identify a $\tfrac{1}{2}$-approximation algorithm, as well as reasonable agent utility models which admit poly-time algorithms. In addition, we study the {\em price of diversity}: this is the loss in welfare incurred by imposing diversity constraints; we provide upper bounds on the price of diversity as a function of natural problem parameters; next, we analyze public data from Singapore's Housing Development Board, and create a simulated framework testing the welfare loss due to diversity constraints in realistic large-scale scenarios. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">293</td>#}
    <td class="tg-031e">Marco Faella, Luigi Sauro</td>
    <td class="tg-031e">Do all tournaments admit irrelevant matches?</td>
{#    <td class="tg-031e"> We consider tournaments played by a set of agents in order to establish a ranking among them. We introduce the notion of irrelevant match, as a match that does not influence the ultimate ranking of the involved parties. After discussing the basic properties of this notion, we seek out tournaments that have no irrelevant matches, focusing on the class of tournaments where each agent challenges each other exactly once. We prove that tournaments with a static schedule and at least 5 agents always include  irrelevant matches. Conversely, dynamic schedules can be devised in ways that avoid irrelevant matches, at least for one of the involved agents.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 25 (13:30-15:30)<br>Learning And Adaptation 3</td>
{#    <td class="tg-s6z2">727</td>#}
    <td class="tg-031e">Elad Liebman, Eric Zavesky, Peter Stone</td>
    <td class="tg-031e">A Stitch in Time - Autonomous Model Management via Reinforcement Learning</td>
{#    <td class="tg-031e"> Concept drift - a change, either sudden or gradual, in the underlying  properties of data - is one of the most prevalent challenges to  maintaining high-performing learned models over time in autonomous  systems.  In the face of concept drift, one can hope that the old model  is sufficiently representative of the new data despite the concept  drift, one can discard the old data and retrain a new model with  new data, or one can use transfer learning methods to combine  the old data with the new to create an updated model.  Which of  these three options is chosen affects not only near-term decisions, but  also future needs to transfer or retrain.  In this paper, we thus model  response to concept drift as a sequential decision making problem and  formally frame it as a Markov Decision Process.  Our reinforcement  learning approach to the problem shows promising results on one  synthetic and two real-world datasets.session`</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">559</td>#}
    <td class="tg-031e">Merwan Barlier, Olivier Pietquin, Romain Laroche</td>
    <td class="tg-031e">Training Dialogue Systems With Human Advice</td>
{#    <td class="tg-031e"> One major drawback of Reinforcement Learning  Spoken Dialogue Systems is that they inherit from the general exploration requirements of RL which makes them hard to deploy from an industry perspective. On the other hand, industrial systems rely on human expertise and hand written rules so as to avoid irrelevant behavior to happen and maintain acceptable experience from the user point of view.&nbsp;&nbsp;  In this paper, we attempt to bridge the gap between those two worlds by providing an easy way to incorporate all kinds of human expertise in the training phase of a Reinforcement Learning Dialogue System. Our approach, based on the TAMER framework, enables safe and efficient policy learning by combining the traditional Reinforcement Learning reward signal with an additional reward, encoding expert advices.  Experimental results show that our method leads to substantial improvements over more traditional Reinforcement Learning methods. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">582</td>#}
    <td class="tg-031e">Ayush Jain, Doina Precup</td>
    <td class="tg-031e">Eligibility Traces for Options</td>
{#    <td class="tg-031e"> Temporally extended actions not only represent knowledge in the hierarchical setup in reinforcement learning, they also improve exploration while reducing the complexity of choosing actions. The option framework provides a concrete way to implement and reason about temporal abstraction. This work attempts to test the utility of eligibility traces with options and find good ways of doing multi-step intra-option updates. Three algorithms, based on off-policy methods - importance sampling, tree backup and retrace, are proposed for using eligibility traces with options.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">677</td>#}
    <td class="tg-031e">Ramya Ramakrishnan, Ece Kamar, Debadeepta Dey, Julie Shah, Eric Horvitz</td>
    <td class="tg-031e">Discovering Blind Spots in Reinforcement Learning</td>
{#    <td class="tg-031e"> Agents trained in simulation often make errors in the real world, due to mismatches between training and testing environments. These mistakes can be dangerous and difficult to discover because the agent cannot a priori predict them. In this work, we propose using oracle feedback to learn a predictive model of these blind spots to reduce costly errors in real world execution. We focus on blind spots in reinforcement learning that occur due to incomplete state representation: The agent does not have the appropriate features to represent the true state of the world and thus cannot distinguish many states from each other. We formalize the problem of discovering blind spots in RL as a noisy supervised learning problem with class imbalance. Our learning methodology combines techniques for label aggregation, calibration, and supervised learning to reason explicitly about various forms of noise emerging from different forms of oracle feedback, including oracle demonstrations and corrections, to predict blind spots in unseen regions of the state space. We evaluate our approach on two domains and show that its predictive performance achieves higher performance than baseline approaches, and that the learned model can be used to selectively query the oracle at execution time to prevent errors. We also empirically analyze the biases of various forms of oracle feedback, including demonstrations and corrections, and how they impact the discovery of blind spots.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">32</td>#}
    <td class="tg-031e">Felipe Leno Da Silva, Anna Helena Reali Costa</td>
    <td class="tg-031e">Object-Oriented Curriculum Generation for Reinforcement Learning</td>
{#    <td class="tg-031e">#}
{#     Autonomously learning a complex task takes a very long time for Reinforcement Learning  agents.&nbsp; One way to learn faster is by dividing a complex task into several simple subtasks and organizing them in a Curriculum that guides Transfer Learning  methods to reuse knowledge in a convenient &nbsp;sequence.&nbsp;  &nbsp;However, previous works do not take into account the TL method to build specialized Curricula, leaving the burden of a careful subtask selection to a human.&nbsp;  We here rely on Object-Oriented task descriptions to guide both the Curriculum generation and knowledge reuse procedures, autonomously building object-based Curricula.&nbsp;  We also propose a novel procedure for autonomously dividing the target task into simpler ones under minimal human supervision.&nbsp;  Our experiments show that our proposal achieves a better performance using both manually given and autonomously generated subtasks when compared to the state-of-the-art technique in two different domains.#}
{#     </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">277</td>#}
    <td class="tg-031e">Zhuoshu Li, Zhitang Chen, Pascal Poupart, Sanmay Das, Yanhui Geng</td>
    <td class="tg-031e">Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach</td>
{#    <td class="tg-031e"> The reinforcement learning literature typically assumes fixed state transition functions for the sake of tractability. However, in many real-world tasks, the state transition function changes over time, and this change may be governed by exogenous variables outside of the control loop. This can make policy learning difficult. In this paper, we propose a new algorithm to address the aforementioned challenge by embedding the state transition functions at different timestamps into a Reproducing Kernel Hilbert Space; the exogenous variable, as the cause of the state transition evolution, is estimated by projecting the embeddings into the subspace that preserves maximum variance. By augmenting the observable state vector with the estimated exogenous variable, standard RL algorithms such as Q-learning are able to learn faster and better. Experiments with both synthetic and real data demonstrate the superiority of our proposed algorithm over standard and advanced variants of Q-learning algorithms in dynamic environments.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 26 (13:30-15:30)<br>Agent-Based Simulation 2</td>
{#    <td class="tg-s6z2">248</td>#}
    <td class="tg-031e">Yuexin Ma, Dinesh Manocha, Wenping Wang</td>
    <td class="tg-031e">Efficient Reciprocal Collision Avoidance between Heterogeneous Agents Using CTMAT</td>
{#    <td class="tg-031e"> We present a novel algorithm for reciprocal collision avoidance between heterogeneous agents of different shapes and sizes. We present a novel CTMAT representation based on medial axis transform to compute a tight fitting bounding shape for each agent. Each CTMAT is represented using tuples, which are composed of circular arcs and line segments. Based on the reciprocal velocity obstacle formulation, we reduce the problem to solving a low-dimensional linear programming between each pair of tuples belonging to adjacent agents. We precompute the Minkowski Sums of tuples to accelerate the runtime performance. Finally, we provide an efficient method to update the orientation of each agent in a local manner. We have implemented the algorithm and highlight its performance on benchmarks corresponding to road traffic scenarios and different vehicles. The overall runtime performance is comparable to prior multi-agent collision avoidance algorithms that use circular or elliptical agents. Our approach is less conservative and results in fewer false collisions.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">36</td>#}
    <td class="tg-031e">Weihua Li, Quan Bai, Minjie Zhang, Tung Doan Nguyen</td>
    <td class="tg-031e">Modelling Multiple Influences Diffusion in On-line Social Networks</td>
{#    <td class="tg-031e"> In on-line social networks, innovations in the presence of one or more influences disseminate through the topological structure of the networks rapidly. In reality, various influences normally coexist in the same context and have subtle relations, such as supportive, contradictory and competitive relations, affecting the users' decisions of adopting any innovations. Therefore, modelling diffusion process of multiple influences is an important, yet challenging research question. By employing the agent-based modelling, in this paper, a distributed approach has been proposed to model the diffusion process of multiple influences in social networks. The proposed model has been applied in the undesirable influence minimisation problem, where the time series is taken into consideration. The experimental results show our model can be utilised to minimise the adverse impact of a certain influence by injecting other influences. Furthermore, the proposed model also sheds light on understanding, investigating and analysing multiple influences in social networks  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">637</td>#}
    <td class="tg-031e">Gizem Korkmaz, Monica Capra, Adriana Kraig, Chris Kuhlman, Kiran Lakkaraju, Fernando Vega-Redondo</td>
    <td class="tg-031e">Coordination and Common Knowledge on Communication Networks</td>
{#    <td class="tg-031e"> Protest is a collective action problem and can be modeled as a coordination game in which two or more people each take an action with the potential to achieve shared mutual benefits, only if their actions coincide. In the context of protest participation, successful coordination requires that people know each others' willingness to participate, and that this information is common knowledge.&nbsp; Social networks can facilitate the creation of common knowledge through the flow of messages.&nbsp; Although there is a rich experimental literature that documents behavior in coordination games with and without communication, little is known about how people coordinate behaviors within a social network and how different types of communication structures affect behavior.  In this paper, we develop a theoretically based on-line experiment with Amazon Mechanical Turk participants to characterize the emergence of common knowledge and coordination through interactions within a network. Our experiment is designed to identify the effects of both social network topology and communication and to falsify the game-theoretic predictions.&nbsp; Our data reveal that choices are affected by the network structure and they move towards the theoretical predictions with communication. We use our behavioral findings to simulate dynamics in more complex networks through agent-based modeling. Thus, we combine human behaviors identified in experiments with realistic social network structures to reveal patterns not previously observed.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">548</td>#}
    <td class="tg-031e">Alex Kuefler, Mykel Kochenderfer</td>
    <td class="tg-031e">Burn-In Demonstrations for Multi-Modal Imitation Learning</td>
{#    <td class="tg-031e"> Recent work on imitation learning has generated policies that reproduce expert behavior from multi-modal data. However, past approaches have focused only on recreating a small number of distinct, expert maneuvers, or have relied on supervised learning techniques that produce unstable policies. This work extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce behavior over an extended period of time. Our approach involves reformulating the typical imitation learning setting to include ``burn-in demonstrations'' upon which policies are conditioned at test time. We demonstrate that our approach outperforms standard InfoGAIL in maximizing the mutual information between predicted and unseen style labels in road scene simulations, and we show that our method leads to policies that imitate expert autonomous driving systems over long time horizons.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">323</td>#}
    <td class="tg-031e">Adam Coates, Anthony Kleerekoper, Liangxu Han</td>
    <td class="tg-031e">A Unified Framework for Opinion Dynamics</td>
{#    <td class="tg-031e">      Opinion dynamics is the study of how large groups#}
{#    interact with one another and reach consensus, with applications to#}
{#    various areas such as computer networks, politics, and sociology. It is#}
{#    typically explored using agent-based modeling, with a wide variety of#}
{#    available models. Numerous opinion dynamics models have been#}
{#    proposed, but it has been pointed out that there is a lack of a shared#}
{#    framework. We extend earlier attempts and provide a unified framework.#}
{#    The advantages of such a framework include the reduction of duplication#}
{#    and the identification of unexplored parameter space.      Our framework is implemented in a modular simulator which is then used to verify the validity of the framework. We show that the modular approach we propose is able to perfectly replicate results from purpose-built, stand-alone simulators for two widely used models, namely Relative Agreement and CODA.      </td>#}
{#    </tr>#}
    <tr>
{#    <td class="tg-s6z2">704</td>#}
    <td class="tg-031e">Blake Wulfe, Mykel Kochenderfer, Sunil Chintakindi, Sou Cheng Choi, Rory Hartong-Redden, Anuradha Kodali</td>
    <td class="tg-031e">Real-time Prediction of Intermediate-horizon Automotive Collision Risk</td>
{#    <td class="tg-031e">   Advanced collision avoidance and driver hand-off systems can benefit from the ability to accurately predict, in real time, the probability a vehicle will be involved in a collision within an intermediate horizon of 10 to 20 seconds. The rarity of collisions in real-world data poses a significant challenge to developing this capability because, as we demonstrate empirically, intermediate-horizon risk prediction depends heavily on high-dimensional driver behavioral features. As a result, a large amount of data is required to fit an effective predictive model. In this paper, we assess whether simulated data can help alleviate this issue. Focusing on highway driving, we present a three-step approach for generating data and fitting a predictive model capable of real-time prediction. First, high-risk automotive scenes are generated using importance sampling on a learned Bayesian network scene model. Second, collision risk is estimated through Monte Carlo simulation. Third, a neural network domain adaptation model is&nbsp; trained on real and simulated data to address discrepancies between the two domains. Experiments indicate that simulated data can mitigate issues resulting from collision rarity, thereby improving risk prediction in real-world data.    </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 27 (13:30-15:30)<br>Argumentation</td>
{#    <td class="tg-s6z2">98</td>#}
    <td class="tg-031e">Ofer Arieli, AnneMarie Borg</td>
    <td class="tg-031e">Hypersequential Argumentation Frameworks: An Instantiation in the Modal Logic S5</td>
{#    <td class="tg-031e"> In this paper we introduce hypersequent-based frameworks for the modeling of defeasible reasoning by means of logic-based argumentation. These frameworks are an extension of sequent-based argumentation frameworks, in which arguments are represented not only by sequents, but by more general expressions, called hypersequents. This generalization allows to incorporate, as the deductive-base of our formalism, some well-studied logics like the modal logic S5, the relevance logic RM, and Gödel-Dummett logic LC, to which no cut-free sequent calculi are known. In this paper we take S5 as the core logic and show that the hypersequent-based argumentation frameworks that are obtained in this case yield a robust defeasible variant of S5 with several desirable properties.  </td>#}
    </tr>
    <tr>
    <td class="tg-031e">Ofer Arieli, AnneMarie Borg, Christian Straber</td>
    <td class="tg-031e">Prioritized Sequent-Based Argumentation</td>
    <tr>
{#    <td class="tg-s6z2">225</td>#}
    <td class="tg-031e">Zhiwei Zeng, Xiuyi  Fan,  Chunyan  Miao,  Cyril  Leung,  Chin Jing  Jih,  Ong Yew  Soon</td>
    <td class="tg-031e">Context-based and Explainable Decision Making with Argumentation</td>
{#    <td class="tg-031e"> Argumentation-based approaches to decision making have gained#}
{#    considerable research interest, due to their ability to select and#}
{#    justify decisions. In order to make better decisions, context is a key#}
{#    piece of information that needs to be considered. However, most existing#}
{#    argumentation-based models and frameworks have not modelled#}
{#    or reasoned with context explicitly. In this paper, we present a#}
{#    new argumentation-based approach for making context-based and#}
{#    explainable decisions. We propose a graphical representation for#}
{#    modelling decision problems involving varying contexts, Decision#}
{#    Graph with Context,  and a reasoning mechanism for making#}
{#    context-based decisions which relies on the Assumption-based#}
{#    Argumentation formalism. Based on these constructs, we introduce#}
{#    two types of explanations, argument explanation and context explanation, identifying the reasons for the decisions made from an#}
{#    argument-view and a context-view respectively. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">81</td>#}
    <td class="tg-031e">Abdelraouf Hecham, Pierre Bisquert, Madalina Croitoru</td>
    <td class="tg-031e">On a Flexible Representation for Defeasible Reasoning Variants</td>
{#    <td class="tg-031e"> We propose Statement Graphs,  a new logical formalism for defeasible reasoning based on argumentation. Using a flexible labeling function, SGs can capture the variants of defeasible reasoning . We evaluate our approach with respect to human reasoning and propose a working first order defeasible reasoning tool that, compared to the state of the art, has richer expressivity at no added computational cost.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">42</td>#}
    <td class="tg-031e">Pierpaolo Dondio</td>
    <td class="tg-031e">Ranking Semantics Based on Subgraphs Analysis</td>
{#    <td class="tg-031e"> In this paper we first propose a measure of the sensitivity of an argument in an abstract argumentation framework. The index is an indicator of how sensitive is the label assigned to the argument by an argumentation semantics. This numerical indicator is derived from the topology of the graph via a subgraphs analysis, coupled with the postulates of the chosen semantics.   Using the total rank on arguments induced by such indicator, we propose two ranking-based semantics. We compare the behaviour of our ranking-semantics with recent proposals and a widespread set of properties identified in literature.  A key feature of the semantics is that the attack relation between arguments keeps the same meaning as found in Dung' abstract semantics.#}

{##}
{#      By still relying on Dung' semantics we can soundly deal with any graph configuration, produce justified results, minimize the addition of ad-hoc postulates and provide a clear interpretation of the ranking of arguments.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">501</td>#}
    <td class="tg-031e">Emmanuel Hadoux, Anthony Hunter</td>
    <td class="tg-031e">Learning and Updating User Models for Subpopulations in Persuasive Argumentation Using Beta Distributions</td>
{#    <td class="tg-031e"> Persuasion is an activity that involves one party  trying to induce another party  to believe or do something. It is an important and multifaceted human facility both in professional life  and everyday life . Recently, some proposals in the field of computational models of argument have been made for probabilistic models of what the persuadee knows about, or believes. However, they cannot efficiently model uncertainty on the belief of individuals and cannot represent populations. We propose to use mixtures of beta distributions and apply them on real data gathered by linguists. We show that we can represent the belief and its uncertainty using beta mixtures and that we can predict the evolution of this belief after an argument is given. We also present examples of how to use the mixtures in practice to replace general belief update functions. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="5" nowrap>Session 28 (13:30-15:30)<br>Commuication</td>
{#    <td class="tg-s6z2">579</td>#}
    <td class="tg-031e">Paula Chocron, Marco Schorlemmer</td>
    <td class="tg-031e">Inferring Commitment Semantics in Multi-Agent Interactions</td>
{#    <td class="tg-031e"> Commitments are a useful abstraction to specify the social semantics of multi-agent communication languages. To use them in open and heterogeneous systems, it is necessary to develop solutions to the problem of interoperability, an effort that has already provided methods to, for example, align commitments between interlocutors. In this paper we consider the problem of commitment semantics inference, which can be summarized as follows: how can an agent that arrives to a community with an established language discover its social semantics, only by observing interactions? We introduce a method based on simple learning techniques that tackles this problem. We show that the basic commitment semantics is not possible to infer, and discuss different ways of enriching it that make inference feasible. We show experimentally how our technique performs for each of these extensions. To the best of our knowledge, that is the first approach that tackles the problem of inferring commitment semantics.  </td>#}
    </tr>
    <tr>
    <td class="tg-031e">Chenxi Qiu, Anna Squicciarini, Dev Khare,  Barbara Carminati, James Caverlee </td>
    <td class="tg-031e">CrowdEval: A Cost-Efficient Strategy to Evaluate Crowdsourced Workers Reliability</td>
    </tr>
    <tr>
{#    <td class="tg-s6z2">274</td>#}
    <td class="tg-031e">Samuel Christie, Amit Chopra, Munindar Singh</td>
    <td class="tg-031e">Compositional Correctness in Multiagent Interactions</td>
{#    <td class="tg-031e"> &nbsp; An interaction protocol specifies the constraints on communication  &nbsp; between agents in a multiagent system.&nbsp; Ideally, we would like to be  &nbsp; able to treat protocols as modules and compose them in a declarative  &nbsp; manner to systematically build more complex protocols.&nbsp; Supporting  &nbsp; composition correctly requires taking into account the causal  &nbsp; dependencies between protocols.&nbsp; One particular problem that may  &nbsp; arise from inadequate consideration of causal dependencies is that  &nbsp; the enactment of a composite protocol may violate \emph{atomicity};  &nbsp; that is, some components may be initiated but prevented from  &nbsp; completing.&nbsp; We use this \emph{all or nothing} principle as the  &nbsp; basis for formalizing atomicity as a novel correctness property for  &nbsp; protocols.     &nbsp; Our contributions are the following.&nbsp; One, we motivate and formalize  &nbsp; atomicity and highlight its distinctiveness from related correctness  &nbsp; notions.&nbsp; Two, we give a decision procedure for verifying atomicity  &nbsp; and report results from an implementation.&nbsp; For concreteness of  &nbsp; exposition and technical development, we adopt BSPL as an exemplar  &nbsp; of information-based approaches. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS2</td>#}
    <td class="tg-031e">Kurtulus Kullu, Ugur Gudukbay and Dinesh Manocha</td>
    <td class="tg-031e">ACMICS: an Agent Communication Model for Interacting Crowd Simulation</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS3</td>#}
    <td class="tg-031e">Michael Winikoff, Nitin Yadav and Lin Padgham</td>
    <td class="tg-031e">A new Hierarchical Agent Protocol Notation</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 29 (13:30-15:30)<br>Blue Sky</td>
{#    <td class="tg-s6z2">B27</td>#}
    <td class="tg-031e">Markus Brill</td>
    <td class="tg-031e">Interactive Democracy</td>
{#    <td class="tg-031e">Interactive Democracy is an umbrella term that encompasses a variety of approaches to make collective decision making processes more engaging and responsive. A common goal of these approaches is to utilize modern information technology---in particular, the Internet---in order to enable more interactive decision making processes. An integral part of many interactive democracy proposals are online decision platforms that provide much more  flexibility and interaction possibilities than traditional democratic systems. This is achieved by embracing the novel paradigm of delegative voting, often referred to as liquid democracy, which aims to reconcile the idealistic appeal of direct democracy with the practicality of representative democracy. The successful design of interactive democracy systems presents a multidisciplinary research challenge; one important aspect concerns the elicitation and aggregation of preferences. However, existing proposals are mostly disconnected from the vast body of scientific literature on preference aggregation and related topics. In this article, I argue that tools and techniques developed in the multiagent systems literature should be employed to aid the design of online decision platforms and other interactive democracy systems. Insights from computational social choice, an emerging research area at the intersection of computer science and economics, will be particularly relevant for this endeavor.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B29</td>#}
    <td class="tg-031e">Ehud Shapiro, Nimrod Talmon</td>
    <td class="tg-031e">Incorporating Reality into Social Choice</td>
{#    <td class="tg-031e">When voting on a proposal one in fact chooses between two alternatives:  A new hypothetical social state depicted by the proposal and  the status quo ; a Yes vote favors a transition to the proposed hypothetical state, while a No vote favors Reality. Social Choice theory generalizes voting on one proposal to ranking multiple proposals; that Reality was forsaken during this generalization is, in our view, inexplicable. Here we propose to rectify this neglect and incorporate Reality into Social Choice, distinguishing Reality from hypothesis. We show that doing so:  Offers a natural resolution to Condorcet's paradox;  Explains what approval voters approve;  Produces a simple and efficient Condorcet-consistent show-of-hands agenda;  Produces democratic action plans, which  start with Reality and proceed in democratically-supported transitions; and  Nullifies Independence of Irrelevant Alternatives and hence abdicates Arrow's Theorem. Arrow's theorem was taken to show that democracy, conceived as government by the will of the people, is an incoherent illusion. Incorporating Reality into Social Choice may clear this intellectual blemish on democracy and offer a coherent, simple, efficient, easy to communicate, and trustworthy path forward to democracy.</td>#}
    </tr>
    <tr>
    <td class="tg-031e">Lois Vanhee, Melania Borit, Jorge Santos</td>
    <td class="tg-031e">Autonomous fishing vessels roving the seas: what multiagent systems have got to do with it</td>
    <tr>
{#    <td class="tg-s6z2">B36</td>#}
    <td class="tg-031e">Sandip Sen, Zenefa Rahaman, Chad Crawford, Osman Yucel</td>
    <td class="tg-031e">Agents for Social  Change</td>
{#    <td class="tg-031e">We are addicted to the Internet and spend a significant portion of our waking hours engaged to that virtual world through the "window" of our electronic devices. A large majority of these interactions occur on online social media. From advertising campaigns to political debates and from trending news topics to communications from family and social circles, social media platforms and services have become invaluable and irreplaceable tools for most of us. Our beliefs and preferences are increasingly shaped and defined by what we see and experience on social media. With this increased reliance also comes the uneasy realization that information and knowledge of value to us is being drowned out in the deluge of forwarded messages and targeted communication from paid advertisers on various social media platforms. This paper seeks to highlight the research challenges underlying the potential for intelligent agents to help stem the tide, to help us deliberate, prioritize and process information of value to us and to our communities, as well as help us reach out, connect to, share and disseminate mutually interesting knowledge with other users. We posit an agent-based ecosystem, where both individual users and organizations see the value and creative possibilities of agent-based solutions to critical problems of connectivity, relevance, varying interest profiles, context, etc.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B39</td>#}
    <td class="tg-031e">Ofra Amir, Finale Doshi-Velez, David Sarne</td>
    <td class="tg-031e">Agent Strategy Summarization</td>
{#    <td class="tg-031e">Intelligent agents and AI-based systems are becoming increasingly prevalent. They support people in different ways, such as providing users with advice, working with them to achieve goals or acting on users’ behalf. One key capability missing in such systems is the ability to present their users with an effective summary of their strategy and expected behaviors under different conditions and scenarios. This capability, which we see as complimentary to those currently under development in the context of “interpretable machine learning” and “explainable AI”, is critical in various settings. In particular, it is likely to play a key role whenever a user needs to understand the strategy of an agent she is working along with, when having to choose between different available agents to act on her behalf, or when requested to determine the level of autonomy to be granted to the agent or approve its strategy. In this paper, we pose the challenge of developing capabilities for strategy summarization, which is not addressed by current theories and methods in the field. We propose a conceptual framework for strategy summarization, which we envision as a collaborative process that involves both agents and people. Last, we suggest possible testbeds that could be used to evaluate progress in research on strategy summarization.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B40</td>#}
    <td class="tg-031e">Petros Papapanagiotou, Alan Davoust, Dave Murray-Rust, Areti Manataki, Max Van Kleek, Nigel Shadbolt, Dave Robertson</td>
    <td class="tg-031e">Social Machines for All</td>
{#    <td class="tg-031e">In today's interconnected world, people interact to a unprecedented degree through the use of digital platforms and services, forming complex `social machines'. These are now homes to autonomous agents as well as people, providing an open space where human and computational intelligence can mingle---a new frontier for distributed agent systems. However, participants typically have limited autonomy to define and shape the machines they are part of. In this paper, we envision a future where individuals are able to develop their own Social Machines, enabling them to interact in a trustworthy, decentralized way. To make this possible, development methods and tools must see their barriers-to-entry  dramatically lowered. People should be able to specify the agent roles and interaction patterns in an intuitive, visual way, analyse and test their designs and deploy them as easy to use systems. We argue that this is a challenging but realistic goal, which should be tackled by navigating the trade-off between the accessibility of the design methods --primarily the modelling formalisms-- and their expressive power. We support our arguments by drawing ideas from different research areas including electronic institutions, agent-based simulation, process modelling, formal verification, and model-driven engineering.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 30 (13:30-15:30)<br>Socially Interactive Agents 2</td>
{#    <td class="tg-s6z2">S61</td>#}
    <td class="tg-031e">Hendrik Buschmeier, Stefan Kopp</td>
    <td class="tg-031e">Communicative Listener Feedback in Human–Agent Interaction: Artificial Speakers Need to Be Attentive and Adaptive</td>
    <tr>
{#    <td class="tg-s6z2">S74</td>#}
    <td class="tg-031e">Sebastien Lalle,  Cristina Conati,  Roger Azevedo</td>
    <td class="tg-031e">Prediction of Student Achievement Goals and Emotion Valence during Interaction with Pedagogical Agents</td>
{#    <td class="tg-031e">There is evidence that Pedagogical Agents  can influence students' emotions while learning with Intelligent Tutoring Systems, and that this influence is modulated by the students' achievement goals for learning. This suggests that students may benefit from personalized PAs that could rectify episodes of negative affect depending on their achievement goals. To ascertain the possibility of devising such personalized PAs, this paper investigates the real-time prediction of both students‚Äô achievement goals and affective valence while interacting with MetaTutor, an agent-based intelligent tutoring system. We train classifiers using eye-tracking data to make such prediction, and show that these classifiers can outperform a majority-class baseline at predicting both achievement goals and emotion valence.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S28</td>#}
    <td class="tg-031e">Katherine Metcalf,  Barry-John Theobald,  Nicholas Apostoloff</td>
    <td class="tg-031e">Learning Sharing Behaviors with Arbitrary Numbers of Agents</td>
{#    <td class="tg-031e">We propose a method for modeling and learning turn-taking behaviors for accessing a shared resource.  We model the individual behavior for each agent in an interaction and then use a multi-agent fusion model to generate a summary over the expected actions of the group to render the model independent of the number of agents.  The individual behavior models are weighted finite state transducers  with weights dynamically updated during interactions, and the multi-agent fusion model is a logistic regression classifier.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S51</td>#}
    <td class="tg-031e">Florian Pecune,  Justine Cassell,  Jingya Chen,  Yoichi Matsuyama</td>
    <td class="tg-031e">Field Study Analysis of a Socially Aware Robot Assistant</td>
{#    <td class="tg-031e">The Socially-Aware Robot Assistant  is an embodied conversational agent that works toward using detection of visual, vocal and verbal cues as an input to estimate the strength of its relationship  with a user. SARA then answers to the user through similar visual, vocal and verbal behaviors with the goal of building and maintaining rapport with that user as we hypothesize that this will improve task performance and user satisfaction over time. In this paper, we report results of a field trial with a semi-automatic SARA system that took place in a large high-profile conference. Participants interacted with SARA during the whole conference, receiving recommendations about sessions to attend and/or people to meet. We analyzed these interactions to shed light on the dynamics of the rapport level between SARA and the conference attendees, and investigate how SARA's task performance would influence the evolution of rapport over time. Although we did not find evidence supporting our claim that the recommendations' outcomes would influence rapport dynamics, our findings emphasize the importance of interactional features plays in both rapport and SARA's task performance.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S52</td>#}
    <td class="tg-031e">Johnathan Mell,  Gale Lucas,  Jonathan Gratch</td>
    <td class="tg-031e">Welcome to the Real World: How Agent Strategy Increases Human Willingness to Deceive</td>
{#    <td class="tg-031e">Humans that negotiate through representatives often instruct those representatives to act in certain ways that align with both the client's goals and his or her social norms. However, which tactics and ethical norms humans endorse vary widely from person to person, and these endorsements may be easy to manipulate. This work presents the results of a study that demonstrates that humans that interact with an artificial agent may change what kinds of tactics and norms they endorse‚Äîoften dramatically. Previous work has indicated that people that negotiate through artificial agent representatives may be more inclined to fairness than those people that negotiate directly. Our work qualifies that initial picture, demonstrating that subsequent experience may change this tendency toward fairness. By exposing human negotiators to tough, automated agents, we are able to shift the participant‚Äôs willingness to deceive others and utilize ‚Äúhard-ball‚Äù negotiation techniques. In short, what techniques people decide to endorse is dependent upon their context and experience. We examine the effects of interacting with four different types of automated agents, each with a unique strategy, and how this subsequently changes which strategies a human negotiator might later endorse. In the study, which was conducted on an online negotiation platform, four different types of automated agents negotiate with humans over the course of a 10-minute interaction. The agents differ in a 2x2 design according to agent strategy  and agent attitude . These results show that in this multi-issue bargaining task, humans that interacted with a tough agent were more willing to endorse deceptive techniques when instructing their own representative. These kinds of techniques were endorsed even if the agent the human encountered did not use deception as part of its strategy. In contrast to some previous work, there was not a significant effect of agent attitude. These results indicate the power of allowing people to program agents that follow their instructions, but also indicate that these social norms and tactic endorsements may be mutable in the presence of real negotiation experience.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S31</td>#}
    <td class="tg-031e">Tibor Bosse,  Tilo Hartmann,  Romy Blankendaal,  Nienke Dokter,  Marco Otte,  Linford Goedschalk</td>
    <td class="tg-031e">Virtually Bad: A Study on Virtual Agents that Physically Threaten Human Beings</td>
{#    <td class="tg-031e">This paper introduces the concept of "virtual bad guys": intelligent virtual agents that take a negative or even aggressive stance towards the user. Although they pave the way to various interesting applications, it is hard to create virtual bad guys that are taken seriously by the user, since they are typically unable to apply serious sanctions. To address this issue, this study experimentally investigated the effect of ‚Äúconsequential‚Äù agents that are able to physically threaten their human interlocutors. A consequential agent was developed by equipping users with a  device, through which they were made to believe the agent could mildly shock them. Effects on participants‚Äô levels of anxiety and  stress were measured, and the role of presence and perceived believability of the virtual agent was assessed. The consequential agent triggered a stronger physiological stress response than the non-consequential agent, whereas self-reported levels of anxiety and stress did not significantly differ. Furthermore, while presence and believability were substantially associated with users‚Äô stress response, both states did not mediate or explain the effect of a consequential vs. non-consequential agent on stress, as they did not significantly differ between conditions. Implications of these findings and suggestions for follow-up studies on ‚Äúvirtual bad guys‚Äù are discussed. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 31 (17:00-18:00)<br>Noncooperative Games</td>
{#    <td class="tg-s6z2">53</td>#}
    <td class="tg-031e">Erel Segal-Halevi</td>
    <td class="tg-031e">Competitive Equilibrium for almost All Incomes</td>
{#    <td class="tg-031e"> Competitive equilibrium from equal incomes &nbsp; is a well-known rule for fair allocation of resources among agents with different preferences. It has many advantages, among them is the fact that a CEEI allocation is both Pareto efficient and envy-free. However, when the resources are indivisible, a CEEI allocation might not exist even when there are two agents and a single item.  In contrast to this discouraging non-existence result, Babaioff and Nisan and Talgam-Cohen  recently suggested a new and more encouraging approach to allocation of indivisible items: instead of insisting that the incomes be equal, they suggest to look at the entire space of possible incomes, and check whether there exists a competitive equilibrium for almost all income-vectors  --- all income-space except a subset of measure zero.  They show that a CEFAI exists when there at most 3 indivisible items, or when there are 4 indivisible items and two agents. They also show that when there are 5 items and two agents with arbitrary monotone preferences, there might not exist a CEFAI. They leave open the cases of 4 items with three or four agents.  This paper presents a new way to implement a CEFAI, as&nbsp; a subgame-perfect equilibrium of a sequential game.&nbsp;&nbsp; This new implementation allows us to both offer much simpler solutions to the known cases,  and to prove that a CEFAI exists even in the much more difficult case of 4 items and three agents.&nbsp; Moreover, we prove that a CEFAI might not exist with 4 items and four agents.&nbsp; Thus, this paper completes the characterization of CEFAI for monotone preferences.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">63</td>#}
    <td class="tg-031e">Erel Segal-Halevi</td>
    <td class="tg-031e">Fairly Dividing a Cake after Some Parts Were Burnt in the Oven</td>
{#    <td class="tg-031e"> There is a heterogeneous resource that contains both good parts and bad parts, for example, a cake with some parts burnt, a land-estate with some parts heavily taxed, or a chore with some parts fun to do. The resource has to be divided fairly among n agents, each of whom has a personal value-density function on the resource. The value-density functions can accept any real value --- positive, negative or zero. Can standard cake-cutting procedures, developed for positive valuations, be adapted to this setting? This paper focuses on the question of envy-free cake-cutting with connected pieces. It is proved that such a division exists for 3 agents.    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">635</td>#}
    <td class="tg-031e">Felix Brandt, Christian Saile, Christian Stricker</td>
    <td class="tg-031e">Voting with Ties: Strong Impossibilities via SAT Solving</td>
{#    <td class="tg-031e">Voting rules allow groups of agents to aggregate their preferences in order to reach joint decisions. The Gibbard-Satterthwaite theorem, a seminal result in social choice theory, implies that, when agents have  strict  preferences, all anonymous, Pareto-optimal, and  single-valued  voting rules can be strategically manipulated. In this paper, we consider multi-agent voting when there can be ties in the preferences as well as in the outcomes. These assumptions are extremely natural--especially when there are large numbers of alternatives--and enable us to prove much stronger results than in the overly restrictive setting of strict preferences. In particular, we show that    all anonymous Pareto-optimal rules where ties are broken according to the preferences of a chairman or by means of even-chance lotteries are manipulable, and that    all pairwise Pareto-optimal rules are manipulable, no matter how ties are broken. These results are proved by reducing the statements to finite--yet very large--problems, which are encoded as formulas in propositional logic and then shown to be unsatisfiable by a SAT solver. We also extracted human-readable proofs from minimal unsatisfiable cores of the formulas in question, which were in turn verified by an interactive higher-order theorem prover.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 32 (17:00-18:00)<br>Norms And Trust </td>
{#    <td class="tg-s6z2">415</td>#}
    <td class="tg-031e">Maite Lopez-Sanchez, Juan Antonio Rodriguez-Aguilar, Javier Morales, Michael Wooldridge, Marc Serramia, Carlos Ansotegui, Manel Rodriguez</td>
    <td class="tg-031e">Moral values in norm decision making</td>
{#    <td class="tg-031e"> Most often, both agents and human societies use norms to coordinate their on-going activities. Nevertheless, choosing the 'right' set of norms to regulate these societies constitutes an open problem. Firstly, intrinsic norm relationships may lead to inconsistencies in the chosen set of norms. Secondly, and more importantly, there is an increasing demand of including ethical considerations in the decision making process. This paper focuses on choosing the 'right' norms by considering moral values together with society's partial preferences over these values and the extent to which candidate norms promote them. The resulting decision making problem can then be encoded as a linear program, and hence solved by state-of-the art solvers. Furthermore, we empirically test several optimisation scenarios so to determine the system's performance and the characteristics of the problem that affect its hardness.   </td>#}
    </tr>
    <tr>
    <td class="tg-s6z2">Celso de Melo, Stacy Marcella and Jonathan Gratch</td>
    <td class="tg-031e">Social Decisions and Fairness Change When People’s Interests Are Represented by Autonomous Agents</td>
    </tr>
    <tr>
    <td class="tg-s6z2">Jessica Soares dos Santos, Jean O. Zahn, Eduardo A. Silvestre, Viviane T. Silva and Wamberto W. Vasconcelos</td>
{#    <td class="tg-031e"></td>#}
    <td class="tg-031e">Detection and Resolution of Normative Conflicts in Multi-agent Systems: A Literature Survey</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 33 (17:00-18:00)<br>Planning</td>
{#    <td class="tg-s6z2">460</td>#}
    <td class="tg-031e">Vaishak Belle</td>
    <td class="tg-031e">On Plans With Loops and Noise</td>
{#    <td class="tg-031e"> In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.&nbsp;     Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about  degrees of belief and noise, we revisit the execution  semantics of generalized plans. The specification is then used to  analyse the correctness of example plans.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">178</td>#}
    <td class="tg-031e">Miquel Ramirez, Michael Papasimeon, Nir Lipovetzky, Tim Miller, Adrian Pearce, Lyndon Benke, Enrico Scala, Mohammad Zamani </td>
    <td class="tg-031e">Integrated Hybrid Planning and Programmed Control for Real--Time UAV Maneuvering</td>
{#    <td class="tg-031e"> The automatic generation of realistic behaviour such as tactical intercepts for  Unmanned Aerial Vehicle s  in air combat is a&nbsp;challenging problem. State-of-the-art solutions propose hand--crafted&nbsp;algorithms and heuristics whose performance depends heavily on the initial&nbsp;conditions and aerodynamic properties of the UAVs involved. This&nbsp;paper shows how to employ domain--independent planners, embedded into professional&nbsp;multi--agent simulations, to implement  Model Predictive Control   two--level&nbsp;hybrid control systems for UAVs. Width-based search techniques,&nbsp;taken off-the-shelf from the literature in  classical planning over simulators, &nbsp;are used to generate  real--time control signals  that steer&nbsp;   simulated aircraft as best suits the situation. We compare experimentally the controllers&nbsp;using planners with a behaviour tree that implements tactics widely&nbsp;accepted and used in the real world. Our results indicate hybrid planners derive novel and effective tactics from  first principles  inherent to the dynamical constraints UAVs are subject to. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">369</td>#}
    <td class="tg-031e">Aleck MacNally, Nir Lipovetzky, Miquel Ramirez, Adrian Pearce </td>
    <td class="tg-031e">Action Selection for Transparent Planning</td>
{#    <td class="tg-031e"> We introduce a novel framework to formalise and solve  transparent planning tasks &nbsp;by executing actions selected in a suitable and timely fashion. A  transparent planning task &nbsp;is defined as task where the objective of the agent is to communicate its true goal to observers, thereby making its intentions and its action selection  transparent . We formally define and model these tasks as  Goal POMDP  where the state space is the Cartesian product of the states of the world and a given set of hypothetical goals. Action effects are deterministic in the world states of the problem but probabilistic in the observer's beliefs. Transition probabilities are obtained from making a call to a model-based plan recognition algorithm, which we refer to as an  observer stereotype . We propose an action selection strategy via on-line planning that seeks actions to quickly convey the goal being pursued to an observer assumed to fit a given stereotype. In order to keep run-times feasible, we propose a novel model-based plan recognition algorithm that approximates well-known probabilistic plan recognition methods. The resulting on-line planner, after being evaluated over a diverse set of domains and three different observer stereotypes, is found to convey goal information faster than purely goal-directed planners.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="2" nowrap>Session 34 (17:00-18:00)<br>Engineering Multiagent Systems 2</td>
{#    <td class="tg-s6z2">515</td>#}
{#    <td class="tg-031e"> A networked opinion diffusion process that usually involves extensive spontaneous discussions between connected users, is often propelled by external sources of news or feeds recommended to them. In many applications like marketing design, or product launch, etc., corporations often post curated news or feeds on social media in order to steer the users’ opinions in a desired way. We call such scenarios as opinion shaping or opinion control whereby a few select users called control users post opinionated messages to drive the others’ opinion to reach a given state. In this paper, we propose SmartShape, an opinion control package that jointly selects the control users, as well as computes the optimum rate of control messages, thereby driving the networked opinion dynamics to the desired direction. Furthermore, our proposal also includes a robust shaping suit which makes our control framework resilient to stochastic fluctuations of opinion dynamics, orginating from several sources of randomness. Experiments on several synthetic and real datasets gathered from Twitter, show that SmartShape can accurately determine the quality of a set of control users as well as shape the opinion dynamics more effectively than several baselines. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">379</td>#}
    <td class="tg-031e">Anshuka Rangi, Massimo Franceschetti </td>
    <td class="tg-031e">Multi-armed bandit algorithms for  crowdsourcing systems with  online estimation of  workers' ability</td>
{#    <td class="tg-031e"> Crowdsourcing systems have become a valuable solution for various organizations to outsource work on a temporary basis. &nbsp;Quality assurance in these systems remains a key issue due to the distributed setup of the crowdsourcing platforms and the absence of a priori information about the workers. Our work proposes a notion of Limited-information Crowdsourcing Systems,  where the task master can assign the work &nbsp; based on some &nbsp;knowledge of the workers' ability acquired &nbsp; &nbsp;over time. The key challenges in this new setup are determining an efficient workers' selection policy and estimating the abilities of the workers. For the former challenge, we reduce the problem to an arm-limited, budget limited, multi-armed bandit  set-up and use the simplified bounded KUBE  algorithm &nbsp;of \cite{tran2014efficient} &nbsp;as a solution. This algorithm has previously &nbsp;only been experimentally evaluated, and we provide provable performance guarantees, showing that it is order optimal. This work closes the gap in the literature of budget limited arm limited MAB by proving that expected regret of B-KUBE is $O)$ where $B$ is the total budget of the task master. The latter challenge is solved by &nbsp;formalizing the notion of workers' ability mathematically, and proposing a strategy for the estimation of the workers' &nbsp;ability. Later, we experimentally evaluate B-KUBE in conjunction with this &nbsp;strategy, showing that it outperforms other state-of- the-art MAB algorithms when applied in the same setting.&nbsp;  </td>#}
    </tr>

</table>
</div>

{% endblock %}