{% extends 'base.html' %}

{% block includes %}
    {% load staticfiles %}
    <link href="{% static "css/specific_elements.css" %}" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
{% endblock %}

{% block content %}

{#<style type="text/css">#}
{#    .tg  {border-collapse:collapse;border-spacing:0;}#}
{#    .tg td{font-family:Arial, sans-serif;font-size:12px;padding:5px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:break-all;border-color:black;white-space: nowrap}#}
{#    .tg th{font-family:Arial, sans-serif;font-size:12px;font-weight:normal;padding:5px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:break-all;border-color:black;white-space: nowrap}#}
{#    .tg .tg-s6z2{border-color:inherit;text-align:center;vertical-align:top}#}
{#    .tg .tg-uys7{border-color:inherit;text-align:center}#}
{#    .tg .tg-us36{border-color:inherit;vertical-align:top}#}
{#    .tg .tg-y2k2{font-weight:bold;text-decoration:underline;border-color:inherit;text-align:center}#}
{#    .tg .tg-yw4l{vertical-align:top}#}
{#    .tg .tg-9353{font-weight:bold;text-decoration:underline;border-color:inherit;text-align:center;vertical-align:top}#}
{#    .tg .tg-s6z2{text-align:center}#}
{#    .tg .tg-hgcj{font-weight:bold;text-align:center}#}
{#    .tg .tg-yw4l{vertical-align:top}#}
{#    .tg .tg-031e{vertical-align:top}#}
{#</style>#}

<style type="text/css">
    .tg  {border-collapse:collapse;border-spacing:0;}
    .tg td{font-family:Arial, sans-serif;font-size:12px;padding:5px 5px;border-style:solid;border-width:1px;text-align:center}
    .tg th{font-family:Arial, sans-serif;font-size:12px;font-weight:normal;padding:5px 5px;border-style:solid;border-width:1px;text-align:center}
    .tg .tg-s6z2{border-color:inherit;text-align:center;vertical-align:middle}
    .tg .tg-s6z2{text-align:center}
    .tg .tg-031e{vertical-align:top}
    .tg .tg-s6z3{vertical-align:middle;text-align:center;word-wrap:normal}
</style>

<div>
    <table class="tg">
    <tr>
        <td class="tg-9353" colspan="3"><font color="red"><H5><b>11 July 2018</b></H5></font></td>
    </tr>
    <tr>
    <td class="tg-s6z3">Session (Room No.)<br></td>
    {#<td class="tg-s6z2">Paper ID</td>#}
    <td class="tg-031e">Authors</td>
    <td class="tg-031e">Title</td>
    {#<td class="tg-031e"> Abstract</td>#}
    </tr>
      <tr>
        <td class="tg-s6z3" rowspan="4" nowrap>Session 1 (10:30-11:50) <br> Social Choice Theory 1 (T5)</td>
{#        <td class="tg-s6z2">92</td>#}
        <td class="tg-031e">Siddharth Barman, Sanath Kumar Krishnamurthy, Rohit Vaish </td>
        <td class="tg-031e">Greedy Algorithms for Maximizing Nash Social Welfare</td>
{#        <td class="tg-031e"> We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of  simple,   greedy  algorithms in solving this problem in two interesting special cases.  First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have  identical  valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have  binary  valuations over the goods, an exact solution  can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under  concave  valuations. Notably, for the above mentioned scenarios, our techniques provide a  simple  alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">130</td>#}
        <td class="tg-031e">Piotr Faliszewski, Nimrod Talmon </td>
        <td class="tg-031e">Between Proportionality and Diversity: Balancing District Sizes under the Chamberlin--Courant Rule</td>
{#        <td class="tg-031e"> The Monroe and Chamberlin–Courant  multiwinner rules pro ceed by partitioning the voters into virtual districts and assigning a&nbsp;  unique committee member to each district, so that the voters are as&nbsp;  satisfied with the assignment as possible. The difference between&nbsp;  Monroe and CC is that the former creates equal-sized districts, and&nbsp;  the latter has no constraints. We generalize these rules by requir  ing that the largest district can be at most X times larger than the&nbsp;  smallest one . We show that our new rules&nbsp;  inherit worst-case computational properties from their ancestors,&nbsp;  evaluate the rules experimentally,  and we analyze their approximability.   </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">131</td>#}
        <td class="tg-031e">Haris Aziz, Barton Lee, Nimrod Talmon </td>
        <td class="tg-031e">Proportionally Representative Participatory Budgeting: Axioms and Algorithms</td>
{#        <td class="tg-031e"> Participatory budgeting is one of the exciting developments in deliberative grassroots democracy. We concentrate on approval elections and propose proportional representation axioms in participatory budgeting, by generalizing relevant axioms for approval-based multi-winner elections. We observe a rich landscape with respect to the computational complexity of identifying proportional budgets and computing such, and present budgeting methods that satisfy these axioms by identifying budgets that are representative to the demands of vast segments of the voters.&nbsp; </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">135</td>#}
        <td class="tg-031e">Piotr Faliszewski, Stanislaw Szufa, Nimrod Talmon </td>
        <td class="tg-031e">Optimization-Based Voting Rule Design: The Closer to Utopia the Better</td>
{#        <td class="tg-031e"> In certain situations, such as elections in the Euclidean domain, it is possible to specify clear requirements for the operation of a multiwinner voting rule, for it to provide committees that correspond to some desirable intuitive notions . We formally describe several such requirements, which we refer to as ``utopias''. Supplied with such utopias, we develop an optimization-based mechanism for constructing committee scoring rules that provide results as close to these utopias as possible; we test our mechanism on weakly separable and OWA-based rules. Using our method we recovered some believed connections between known multiwinner voting rules and certain applications and got other interesting insights. </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="4" nowrap>Session 2 (10:30-11:50)<br> Mechanism Design 1 (T6)</td>
{#        <td class="tg-s6z2">124</td>#}
        <td class="tg-031e">Hao Cheng, Lei Zhang, Yi Zhang, Jun Wu, Chongjun Wang </td>
        <td class="tg-031e">Optimal Constraint Collection for Core-selecting Path Mechanism</td>
{#        <td class="tg-031e">#}
{#            In path auctions, strategic bidders make bids for commodities. Each#}
{#        edge of the graph stands for a commodity and the weight on the#}
{#        edge represents the prime cost. Auctioneer needs to purchase a#}
{#        sequence of edges in order to get a path from one vertex to another at a low cost. Path auctions can be considered as a kind of#}
{#        combinatorial reverse-auctions. Computing prices in core-selecting#}
{#        combinatorial auctions is a computationally hard problem, the same#}
{#        is true in core-selecting path auctions. This problem can be solved#}
{#        by core constraint generation algorithm. However, we  nd#}
{#        that there are many redundant constraints and the constraint col-#}
{#        lection can be conciser in core-selecting path mechanism. In this#}
{#        paper,   1  )   we put forward a new approach to get the constraint collection, and reduce the constraint number from exponential   O   #}
{#          to polynomial   O   ,  where   n   is the network diameter;   2  )   we prove#}
{#        that the new constraint collection is not only equivalent to the original collection, but also has no redundant constraint in the worst#}
{#        case;   3  )   we validate our approach on real-world datasets and obtain#}
{#        excellent results. Furthermore, we provide new insights to think#}
{#        over the core-selecting mechanism in combinatorial auctions.#}
{#                </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">196</td>#}
        <td class="tg-031e">Makoto Yokoo, Takamasa Suzuki, Akihisa Tamura </td>
        <td class="tg-031e">Efficient allocation mechanism with endowments and distributional constraints</td>
{#        <td class="tg-031e"> We consider an allocation problem of multiple types objects to agents, where each type of an object has multiple copies,  each agent is endowed with an object, and some distributional constraints are imposed on the allocation . We develop a mechanism that is based on the Top Trading Cycles mechanism, which is strategy-proof, feasible,  Pareto efficient, and individually rational, assuming the distributional constraints are represented as an M-convex set.&nbsp; The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific maximum quotas, and distance constraints.&nbsp; To the best of our knowledge, we are the first to develop a mechanism with these desirable properties.   </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">416</td>#}
        <td class="tg-031e">Kentaro Yahiro, Yuzhe Zhang, Nathanael Barrot, Makoto Yokoo </td>
        <td class="tg-031e">Strategyproof and fair matching mechanism for ratio constraints</td>
{#        <td class="tg-031e"> We introduce a new type of distributional constraints called ratio  constraints, which explicitly specify the required balance among schools in  two-sided matching.&nbsp;  Since ratio constraints do not belong to the known well-behaved class of&nbsp;  constraints called M-convex set, developing a fair and strategyproof  mechanism that can handle them is challenging.&nbsp;  We develop a novel mechanism called  Quota Reduction Deferred Acceptance, &nbsp;  which repeatedly applies the standard DA&nbsp;  by sequentially reducing artificially introduced maximum  quotas. As well as being fair and strategyproof,  QRDA always obtains a weakly better matching for  students compared to a baseline mechanism called&nbsp;  Artificial Cap Deferred Acceptance,  which&nbsp;  uses predetermined artificial maximum quotas.&nbsp;  Experimentally, QRDA performs better in terms of student welfare  and nonwastefulness than ACDA and another fair and strategyproof  mechanism called Extended Seat Deferred Acceptance,  in which&nbsp;  ratio constraints are transformed into minimum/maximum quotas. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">771</td>#}
        <td class="tg-031e">Dengji Zhao, Bin Li, Junping Xu, Dong Hao,  Nicholas R. Jennings</td>
        <td class="tg-031e">Selling Multiple Items via Social Networks</td>
{#        <td class="tg-031e">#}
{#          We consider a market where a seller sells multiple units of a commodity in a social network. Each node/buyer in the social network can only directly communicate with her neighbours, i.e. the seller can only directly sell the commodity to her neighbours without any advertising. In this paper, we design a cost-free advertising mechanism that   incentivizes   all buyers, who are aware of the sale, to invite all their neighbours to join the sale, even though there is no guarantee that their effort will be paid. While traditional prepaid sale promotions such as sponsored search auction cannot guarantee a positive return for the advertisers, our mechanism guarantees that the seller's revenue is greatly improved compared with   VCG   without advertising, and the seller does not need to pay if the advertising is not beneficial to the seller.  </td>#}
        </tr>

        <tr>
{#        <td class="tg-s6z2">476</td>#}
            <td class="tg-s6z3" rowspan="4" nowrap>Session 3 (10:30-11:50)<br> Game Theory 1 (C8)</td>
        <td class="tg-031e">Karl Tuyls, Julien Perolat, Marc Lanctot, Joel Leibo, Thore Graepel </td>
        <td class="tg-031e">A Generalised Method for Empirical Game Theoretic Analysis</td>
{#        <td class="tg-031e"> This paper provides theoretical bounds for empirical game theoretical analysis of complex multi-agent interactions. More precisely, we provide insights on the empirical, or meta game, showing that a Nash equilibrium of the meta-game is an approximate Nash equilibrium of the true underlying game. We provide insights on how many data samples are required to obtain a close enough approximation of the underlying game. Additionally, we extend the meta-game analysis methodology to asymmetric games. The state-of-the-art has only considered empirical games in which agents have access to the same strategy sets and the payoff structure is symmetric, implying that agents are interchangeable. Finally, we carry out an empirical illustration of the generalised method in several domains, illustrating the theory and evolutionary dynamics of several versions of the \textit{AlphaGo} algorithm,  the dynamics of the Colonel Blotto game played by human players on Facebook,  and an example of a meta-game in Leduc Poker,  generated by the PSRO multi-agent learning algorithm.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">218</td>#}
        <td class="tg-031e">Reshef Meir, David Parkes </td>
        <td class="tg-031e">Playing the Wrong Game: Bounding Externalities in Diverse Populations of Agents</td>
{#        <td class="tg-031e">  	 The robustness of multiagent systems can be affected by mistakes or behavioral biases,  with some agents playing the ``wrong game.'' This can change the set of equilibria, and may in turn harm or improve the social welfare of agents in the system. We are interested in bounding what we call the {\em biased price of anarchy}  in populations with diverse agent behaviors, which is the ratio between welfare in the ``wrong'' equilibrium and optimal welfare.&nbsp;&nbsp;   	 We study nonatomic routing games, and derive an externality bound that depends on a key topological parameter of the underlying network.&nbsp;   	 We then prove two general BPoA bounds for games with diverse populations: one that relies on the network structure and the \emph{average bias} of all agents in the population, and one that is independent of the structure but depends on the \emph{maximal bias}. Both types of bounds can be combined with known results to derive concrete BPoA bounds for a variety of specific behaviors .&nbsp;  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">258</td>#}
        <td class="tg-031e">Ganesh Ghalme, SUJIT GUJAR, Amleshwar Kumar, Shweta Jain, Yadati Narahari </td>
        <td class="tg-031e">Design of Coalition Resistant Credit Score Functions for Online Discussion Forums</td>
{#        <td class="tg-031e"> Motivated by the need to design robust, trustworthy online discussion forums,  we design a manipulation resistant credit scoring function to assign scores to agents interacting on a typical ODF. The setting we consider is that of an ODF where the agent utilities are determined by credit scores obtained by the agents in the form of popularity indicators such as upvotes, ratings, shares, and likes. Agents can potentially manipulate the credit scores by strategically awarding the popularity indicators to other agents in order to maximize their own credit score. We focus on a specific but very common form of manipulation, namely, coalition formation. We propose a credit function that discourages formation of coalition by the agents. Our idea is to design such a credit function with the use of community detection algorithms that find an agent set partition by maximizing a community detection metric. Our contribution is to find a characterization for coalition identifying community detection metrics and to show that one can design coalition resistant credit functions with such a metric. In particular, we investigate the modularity metric and show that it is coalition identifying, and show that the proposed credit function with modularity metric is coalition resistant. We validate our theoretical findings with simulations on illustrative datasets.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">513</td>#}
        <td class="tg-031e">Shibashis Guha, Orna Kupferman, Gal Vardi </td>
        <td class="tg-031e">Multi-player Flow Games</td>
{#        <td class="tg-031e">#}
{##}
{#        p, li { white-space: pre-wrap; }#}
{##}
{#          In the traditional maximum-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow into outgoing edges. The problem corresponds to settings in which a central authority has control on all   vertices   of the network. Today's computing environment, however, involves systems with no central authority. In particular, in many applications of flow networks, the   vertices   correspond to decision-points controlled by different and selfish entities. For example, in communication networks, routers may belong to different companies, with different destination objectives. This suggests that the maximum-flow problem should be revisited, and redefined as a game.#}
{##}
{#          We introduce and study {  \em     multi  -player flow games  \/  } . Essentially, the   vertices   of an MFG are partitioned among the players, and a player that owns a vertex directs the flow that reaches it. Each player has a different target vertex, and the objective of each player is to maximize the flow that reaches her target vertex. We study the stability of   MFGs   and show that, unfortunately, an MFG need not have a Nash Equilibrium. Moreover, the Price of Anarchy and even the Price of Stability of   MFGs   are unbounded. That is, the reduction in the flow due to selfish behavior is unbounded. We also study the problem of deciding whether a given MFG has a Nash Equilibrium and show that it is   $\Sigma_2^P$  -complete, as well as the problem of finding optimal strategies for the players, which we show to be NP-complete. We continue with some good news and consider a variant of   MFGs   in which flow may be swallowed. For example, when routers in a communication network may drop messages.​ We show that, surprisingly, while this model seems to   incentivize   selfish behavior, a Nash Equilibrium that achieves the maximum flow always exists, and can be found in polynomial time. Finally, we consider   MFGs   in which the strategies of the players may use non-integral flows, which we show to be stronger. </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="4" nowrap>Session 4 (10:30-11:50)<br> Learning and Adaptation 1 (T1 & T2)</td>
{#        <td class="tg-s6z2">226</td>#}
            <td class="tg-031e">Jakob Foerster, Richard Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, Igor Mordatch </td>
        <td class="tg-031e">Learning with Opponent-Learning Awareness</td>
{#        <td class="tg-031e">#}
{##}
{##}
{##}
{##}
{##}
{##}
{#                              This paper presents a novel framework for automatic learning of#}
{#        complex strategies in human decision making. We observe temporal#}
{#        relationships at the subtask level of expert demonstrations, and#}
{#        determine the different strategies employed in order to successfully#}
{#        complete a task. To capture the relationship between the subtasks#}
{#        and the overall goal, we utilise two external memory modules, one#}
{#        for capturing dependencies within a single expert demonstration,#}
{#        such as the sequential relationship among different sub tasks, and#}
{#        a global memory module for modelling task level characteristics#}
{#        such as best practice employed by different humans based on their#}
{#        domain expertise. Furthermore, we demonstrate how the hidden#}
{#        state representation of the memory can be used as a reward signal#}
{#        to smooth the state transitions, eradicating subtle changes. We#}
{#        evaluate the effectiveness of the proposed model for an autonomous#}
{#        highway driving application, where we demonstrate its capability#}
{#        to learn different expert policies and outperform state-of-the-art#}
{#        methods.&nbsp;#}
{##}
{##}
{#                </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">551</td>#}
        <td class="tg-031e">Tharindu Fernando, Simon Denman, Sridha Sridharan, Clinton Fookes </td>
        <td class="tg-031e">Learning Temporal Strategic Relationships using Generative Adversarial Imitation Learning</td>
{#        <td class="tg-031e"> Multi-agent settings are quickly gathering importance in machine learning. Beyond a plethora of recent work on deep multi-agent reinforcement learning, hierarchical reinforcement learning, generative adversarial networks and decentralized optimization can all be seen as instances of this setting. However, the presence of multiple learning agents in these settings renders the training problem non-stationary and often leads to unstable training or undesired final results. We present Learning with Opponent-Learning Awareness,  a method that reasons about the anticipated learning of the other agents. The LOLA learning rule includes an additional term that accounts for the impact of the agent's policy on the anticipated parameter update of the other agents. We show that the LOLA update rule can be efficiently calculated using an extension of the likelihood ratio policy gradient update, making the method suitable for model-free reinforcement learning. This method thus scales to large parameter and input spaces and nonlinear function approximators. Preliminary results show that the encounter of two LOLA agents leads to the emergence of tit-for-tat and therefore cooperation in the infinitely iterated prisoners' dilemma, while independent learning does not. In this domain, LOLA also receives higher payouts compared to a naive learner, and is robust against exploitation by higher order gradient-based methods. Applied to infinitely repeated matching pennies, LOLA agents converge to the Nash equilibrium. In a round robin tournament we show that LOLA agents can successfully shape the learning of a range of multi-agent learning algorithms from literature, resulting in the highest average returns on the IPD. We also apply LOLA to a grid world task with an embedded social dilemma using deep recurrent policies. Again, by considering the learning of the other agent, LOLA agents learn to cooperate out of selfish interests.&nbsp;  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">595</td>#}
        <td class="tg-031e">Melrose Roderick, Christopher Grimm, Stefanie Tellex </td>
        <td class="tg-031e">Deep Abstract Q-Networks</td>
{#        <td class="tg-031e"> We examine the problem of learning and planning on high-dimensional domains with long horizons and sparse rewards. Recent approaches have shown great successes in many Atari 2600 domains. However, domains with long horizons and sparse rewards, such as Montezuma’s Revenge and Venture, remain challenging for existing methods. Methods using abstraction  have shown to be useful in tackling long-horizon problems. We combine recent techniques of deep reinforcement learning with existing model-based approaches using an expert-provided state abstraction. We construct toy domains that elucidate the problem of long horizons, sparse rewards and high-dimensional inputs, and show that our algorithm significantly outperforms previous methods on these domains. Our abstraction-based approach outperforms Deep Q-Networks  on Montezuma’s Revenge and Venture, and exhibits backtracking behavior that is absent from previous methods. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">687</td>#}
        <td class="tg-031e">Shayegan Omidshafiei, Dong-Ki Kim, Jason Pazis, Jonathan How </td>
        <td class="tg-031e">Crossmodal Attentive Skill Learner</td>
{#        <td class="tg-031e"> This paper introduces the Crossmodal Attentive Skill Learner,  integrated with the recently-introduced Asynchronous Advantage Option-Critic  architecture to enable hierarchical reinforcement learning across multiple sensory inputs. We provide concrete examples where the approach not only improves performance in a single task, but accelerates transfer to new tasks. We demonstrate the attention mechanism anticipates and identifies useful latent features, while filtering irrelevant sensor modalities during execution. We modify the Arcade Learning Environment to support audio queries, and conduct evaluations of crossmodal learning in the Atari games H.E.R.O. and Amidar. Finally, building on the recent work of Babaeizadeh et al.,  we open-source a fast hybrid CPU-GPU implementation of CASL.  </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="4" nowrap>Session 5 (10:30-11:50)<br> Logic for Multiagent Systems 1 (C3)</td>
{#        <td class="tg-s6z2">608</td>#}
        <td class="tg-031e">Fiona Berreby, Gauvain Bourgne, Jean-Gabriel Ganascia </td>
        <td class="tg-031e">Event-Based and Scenario-Based Causality for Computational Ethics</td>
{#        <td class="tg-031e"> This paper makes use of high-level action languages to investigate aspects of causality that are central to ethical reasoning. We identify properties that causal relations assume and that determine how, as well as to what extent, we may ascribe ethical responsibility on their basis. The paper is structured in three parts. First, we present an extension of the Event Calculus that enables the agent to generate plans of actions, with the particularity that they integrate both actions and omissions. Second, we present an account of \textit{event-based} causality that is grounded in the architecture of event preconditions and effects, and that distinguishes four types of causal relations contingent on the nature of the entities that compose them. Namely, it discriminates actions and omissions from automatic events, and produced outcomes from avoided ones. Third, we examine notions of \textit{scenario-based} causality whose role it is to scrutinise and buttress the causal relations previously identified. Inquiring into the other possible versions of modelled scenarios, we account for simple counter-factual validity,  criticality,  extrinsic necessity,  and elicited necessity . The model is implemented in Answer Set Programming.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">125</td>#}
        <td class="tg-031e">Wojciech Jamroga, Wojciech Penczek, Piotr Dembinski, Antoni Mazurkiewicz </td>
        <td class="tg-031e">Towards Partial Order Reductions for Strategic Ability</td>
{#        <td class="tg-031e"> We propose a general semantics for strategic abilities of agents in asynchronous systems, with and without perfect information. Based on the semantics, we show some general complexity results for verification of strategic abilities in asynchronous interaction. More importantly, we develop a methodology for partial order reduction in verification of agents with imperfect information, based on the notion of traces. We show that the reduction preserves an important subset of strategic properties, both with and without the fairness assumption. Interestingly, the reduction does not work for strategic abilities under perfect information.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">231</td>#}
        <td class="tg-031e">Jeremy Kong, Alessio Lomuscio </td>
        <td class="tg-031e">Model Checking Multi-Agent Systems against LDLK Specifications on Finite Traces</td>
{#        <td class="tg-031e"> We introduce the logic LDL f K, a variant of the epistemic logic LDLK, interpreted on finite traces of multi-agent systems. We explore the verification problem of multi-agent systems against LDL f K specifications and give algorithms for the reduction of LDL f K model checking to LDLK verification on a different model and different specification. We analyse the resulting complexity and show it to be PSPACE-complete. We report on a full implementation of the algorithm and assess its performance on a number of examples.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">243</td>#}
        <td class="tg-031e">Christopher Leturc, Gregory Bonnet </td>
        <td class="tg-031e">A normal modal logic for trust in the sincerity</td>
{#        <td class="tg-031e"> In the field of multi-agent systems, as some agents may be not reliable or honest, a particular attention is paid to the notion of trust. There are two main approaches for trust: trust assessment and trust reasoning. Trust assessment is often realized with fuzzy logic and reputation systems which aggregate testimonies -- individual agents' assessments -- to evaluate the agents' global reliability. In the domain of trust reasoning, a large set of works focus also on trust in the reliability as for instance Liau's BIT modal logic where trusting a statement means the truster can believe it. However, very few works focus on trust in the sincerity of a statement -- meaning the truster can believe the trustee believes it. Consequently, we propose in this article a modal logic to reason about an agent's trust in the sincerity towards a statement formulated by another agent. We firstly introduce a new modality of trust in sincerity and then we prove that our system is sound and complete. Finally, we extend our notion of individual trust about the sincerity to shared trust and we show that it behaves like a KD system.    </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="4" nowrap>Session 6 (10:30-11:50)<br> Social Networks (C2)</td>
{#        <td class="tg-s6z2">491</td>#}
        <td class="tg-031e">Sandipan Sikdar, Tanmoy Chakraborty, Soumya Sarkar, Niloy Ganguly, Animesh Mukherjee </td>
        <td class="tg-031e">ComPAS: Community Preserving Sampling for Streaming Graphs</td>
{#        <td class="tg-031e"> In the era of big data, graph sampling is indispensable in many&nbsp; settings. Existing sampling methods are mostly designed for static&nbsp;  graphs, and aim to preserve basic structural properties of the original&nbsp;  graph  in the&nbsp;  sample. We argue that for any sampling method it is impossible to&nbsp;  produce an universal representative sample which can preserve all&nbsp;  the properties of the original graph; rather sampling should be ap  plication specific . Here we consider community detection as an application&nbsp;  scenario. We propose ComPAS, a novel sampling strategy that un  like previous methods, is not only designed for streaming graphs&nbsp;   but&nbsp;  also preserves the community structure of the original graph in the&nbsp;  sample. Empirical results on both synthetic and different real-world&nbsp;  graphs show that ComPAS is the best to preserve the underlying&nbsp;  community structure with average performance reaching 73.2% of&nbsp;  the most informed algorithm for static graphs.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">212</td>#}
        <td class="tg-031e">Yijin Cai, Hong Zheng, Jiamou Liu, Bo Yan,  Hongyi  Su,  Yiping Liu </td>
        <td class="tg-031e">Balancing the Pain and Gain of Hobnobbing</td>
{#        <td class="tg-031e">  The establishment of interpersonal ties is a pivotal problem in the structural analysis of social networks. In particular, link recommendation problem asks for valuable future links to establish by an individual. Existing methods for this problem rely on link prediction that evaluates the likelihood of successful tie creation between two individuals. Such methods do not consider the social capital gained by agents, nor do they concern with the required cost of&nbsp;this process. In light of this limitation, we propose a utility-based network building problem, with an aim to strike a balance between the gained social capital – in the form of closeness centrality – and the cost of establishing ties. We propose algorithms to solve this problem over networks whose nodes may or may not be labelled with attributes, and test their performance on a range of synthesized and real-world social networks. By having multiple agents adopting utility-based network building strategies, we propose a suite of models of&nbsp; network formation and demonstrate empirically that the they capture important structural properties. In particular, we investigate the emergence of a core/periphery structure as a joint result of preferential attachment and network building strategies &nbsp;.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">577</td>#}
        <td class="tg-031e">Chenxi Qiu, Anna Squicciarini, Christopher Griffin, Prasanna Umar </td>
        <td class="tg-031e">Combating Behavioral Deviance via User Behavior Control</td>
{#        <td class="tg-031e"> Compared to traditional behavioral deviance, online deviant behavior  is more likely to spread over online social communities since it is not restricted by time and space, and can occur more frequently and intensely. To control risks associated with the spread of deviant and anti-normative behavior, it is essential to understand online users’ reaction when they interact with other users. In this paper, we model online users’ behavior interaction as an evolutionary game on a graph and analyze users’ behavior dynamics under different network conditions. Based on this theoretical framework, we then investigate behavior control strategies that aim to eliminate behavioral deviance. Finally, we use a real world dataset from a social network to verify the accuracy of our model’s hypothesis.We also and test the performance of our behavior control strategy through simulations based on both real and synthetically generated data. The experimental results demonstrate that our behavior control methods can effectively eliminate the impact of bullying behavior even when the proportion of bullying messages is higher than 60%. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">570</td>#}
        <td class="tg-031e">Sixie Yu, Yevgeniy Vorobeychik, Scott Alfeld </td>
        <td class="tg-031e">Adversarial Classification on Social Networks</td>
{#        <td class="tg-031e"> The spread of unwanted or malicious content through social me- dia has become a major challenge. Traditional examples of this include social network spam, but an important new concern is the propagation of fake news through social media. A common ap- proach for mitigating this problem is by using standard statistical classification to distinguish malicious  instances from benign . However, such an approach ignores the fact that malicious instances propagate through the network, which is consequential both in quantifying consequences,  and capturing de- tection redundancy . An additional concern is evasion attacks, whereby the generators of malicious instances modify the nature of these to escape detection. We model this problem as a Stackelberg game between the defender who is choosing parameters of the detection model, and an attacker, who is choosing both the node at which to initiate malicious spread, and the nature of malicious entities. We develop a novel bi-level programming approach for this problem, as well as a novel solution approach based on implicit function gradients, and experimentally demonstrate the advantage of our approach over alternatives which ignore network structure.  </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="4" nowrap>Session 7 (10:30-11:50)<br> Robotics: Planning (C7)</td>
{#        <td class="tg-s6z2">R40</td>#}
        <td class="tg-031e">Shih-Yun Lo, Shiqi Zhang, Peter Stone </td>
        <td class="tg-031e">PETLON: Planning Efficiently for Task-Level-Optimal Navigation</td>
{#        <td class="tg-031e"> Intelligent mobile robots have recently become able to operate&nbsp; autonomously in large-scale indoor environments for&nbsp;  extended periods of time. Task planning in such environments&nbsp;  involves sequencing the robot’s high-level goals and&nbsp;  subgoals, and typically requires reasoning about the locations&nbsp;  of people, rooms, and objects in the environment, and&nbsp;  their interactions to achieve a goal. One of the prerequisites&nbsp;  for optimal task planning that is often overlooked is having&nbsp;  an accurate estimate of the actual distance  a&nbsp;  robot needs to navigate from one location to another. State-of-the-  art motion planners, though often computationally complex,&nbsp;  are designed exactly for this purpose of finding routes&nbsp;  through constrained spaces. In this work, we focus on integrating   task and motion planning  to achieve task-level&nbsp; optimal planning for robot navigation while maintaining&nbsp;  manageable computational efficiency. To this end, we introduce&nbsp;  TMP algorithm PETLON  for everyday service tasks&nbsp;  using a mobile robot. PETLON is more efficient than planning&nbsp;  approaches that pre-compute motion costs of all possible&nbsp;  navigation actions, while still producing plans that are optimal&nbsp;  at the task level.#}
{#        p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Helvetica}#}
{#         </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R47</td>#}
        <td class="tg-031e">Alessandro Riva, Jacopo Banfi, Carlo Fanton, Nicola Basilico, Francesco Amigoni</td>
        <td class="tg-031e">A Journey Among Pairs of Vertices: Computing Robots' Paths for Performing Joint Measurements</td>
{#        <td class="tg-031e"> The problem of performing joint measurements recurs in many robotic applications, like constructing communication maps from signal strength samples gathered on the field. In spite of this, a theory supporting efficient algorithms has not been yet developed and ad hoc methods are usually employed. In this paper, we consider an environment represented by a metric graph and prove that the problem of jointly performing measurements from given vertices is NP-hard when either the total traveled distance or the task completion time have to be minimized. Given the difficulty of finding optimal paths in an efficient way, we propose a greedy randomized approach able to cope with both the optimization objectives. In settings for which joint measurements must be taken for all pairs of vertices, we prove that a deterministic greedy algorithm achieves an O approximation factor for the traveled distance objective, where m is the number of robots and n the number of vertices, and an O approximation factor for the completion time. Experiments in simulation show that our algorithms perform well in practice, also when compared to an ad hoc method taken from the literature.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R55</td>#}
        <td class="tg-031e">Yue Wang, Swarat Chaudhuri, Lydia Kavraki </td>
        <td class="tg-031e">Bounded Policy Synthesis for POMDPs with Safe-Reachability Objectives</td>
{#        <td class="tg-031e">Planning robust executions under uncertainty is a fundamental challenge for building autonomous robots. Partially Observable Markov Decision Processes  provide a standard framework for modeling uncertainty in many applications. In this work, we study POMDPs with safe-reachability objectives, which require that with a probability above some threshold, a goal state is eventually reached while keeping the probability of visiting unsafe states below some threshold. This POMDP formulation is different from the traditional POMDP models with optimality objectives and we show that in some cases, POMDPs with safe-reachability objectives can provide a better guarantee of both safety and reachability than the existing POMDP models through an example. A key algorithmic problem for POMDPs is policy synthesis, which requires reasoning over a vast space of beliefs . To address this challenge, we introduce the notion of a goal-constrained belief space, which only contains beliefs reachable from the initial belief under desired executions that can achieve the given safe-reachability objective. Our method compactly represents this space over a bounded horizon using symbolic constraints, and employs an incremental Satisfiability Modulo Theories  solver to efficiently search for a valid policy over it. We evaluate our method using a case study involving a partially observable robotic domain with uncertain obstacles. The results show that our method can synthesize policies over large belief spaces with a small number of SMT solver calls by focusing on the goal-constrained belief space.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R84</td>#}
        <td class="tg-031e">Sarra Alqahtani, Ian Riley, Samuel Taylor, Rose Gamble, Roger Mailler </td>
        <td class="tg-031e">MTL Robustness for Path Planning with A*</td>
{#        <td class="tg-031e">Maintaining the safety of an autonomous drone while it executes a mission is a primary concern in presence of fixed and mobile enemies.  Path planning using A* fails to deliver a feasible, safe plan when a drone has resource limitations in such environments. Enhancing A* with constraint optimization techniques may improve outcomes, but significantly increases path determination time. We define Robust A*  that introduces the use of a safety margin to maximize the robustness of the drone to meet mission requirements while managing resource restrictions. We rely on a theory of robustness based on Metric Temporal Logic  as applied to offline verification and online control of hybrid systems. By satisfying the predefined MTL constraints, RA* dynamically defines a safety margin between the drone and an enemy, while constraining the margin size given the droneâ€™s resources. The safety margin creates a robust neighborhood around the dynamically generated path. The robust neighborhood holds all valid trajectories within the current world state. When the world state changes, RA* first examines the robust neighborhood to find a valid trajectory before initiating the path re-planning. We evaluate RA* using the Rassim simulator. The results show that the algorithm generates faster and safer paths than the classical A* in the presence of moving enemies. .</td>#}
        </tr>

        <tr>
        <td class="tg-s6z3" rowspan="6" nowrap>Session 8 (13:30-15:30)<br> Social Choice on Networks (T5)</td>
{#        <td class="tg-s6z2">390</td>#}
        <td class="tg-031e">Matthias Mnich, Martin Koutecky, Dusan Knop </td>
        <td class="tg-031e">A Unifying Framework for Manipulation Problems</td>
{#        <td class="tg-031e"> <p>Manipulation models for electoral systems are a coreresearch theme in socialchoice theory;they&nbsp;include bribery,  control,  lobbying in referenda and others. We develop a unifying framework for manipulation models with few types of people, one of the most commonly studied scenarios. A critical insight of our framework is to separate the descriptive complexity of the voting rule R from the number of types of people. This allows us to finally settle the computational complexity of R-Swap Bribery, one of the most fundamental manipulation problems. In particular, we prove that R-Swap Bribery is fixed-parameter tractable when R is Dodgson’s rule and Young’s rule, when parameterized by the number of candidates. This way, we resolve a long-standing open question from 2007 which was explicitly asked by Faliszewski et al. [JAIR 40, 2011]. Our algorithms reveal that the true hardness of bribery problems often stems from the complexity of the voting rules. On one hand, we give a fixed-parameter algorithm parameterized by number of types of people for complex voting rules. Thus, we reveal that R-Swap Bribery with Dodgson’s rule is much harder than with Condorcet’s rule, which can be expressed by a conjunction of linear inequalities, while Dodson’s rule requires quantifier alternation and a bounded number of disjunctions of linear systems. On the other hand, we give an algorithm for quantifier-free voting rules which is parameterized only by the number of conjunctions of the voting rule and runs in time polynomial in the number of types of people. This way, our framework explains why Shift Bribery is polynomial-time solvable for the plurality voting rule, making explicit that the rule is simple in that it can be expressed with a single linear inequality, and that the number of voter types is polynomial.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">108</td>#}
        <td class="tg-031e">Bryan Wilder, Yevgeniy Vorobeychik </td>
        <td class="tg-031e">Controlling Elections through Social Influence</td>
{#        <td class="tg-031e"> Election control considers the problem of an adversary who attempts to tamper with a voting process, in order to either ensure that their favored candidate wins  or another candidate loses . As online social networks have become significant sources of information for potential voters, a new tool in an attacker's arsenal is to effect control by harnessing social influence, for example, by spreading fake news and other forms of misinformation through online social media.  We consider the computational problem of election control via social influence, studying the conditions under which finding good adversarial strategies is computationally feasible. We consider two objectives for the adversary in both the constructive and destructive control settings: probability and margin of victory . We present several strong negative results, showing, for example, that the problem of maximizing POV is inapproximable for any constant factor. On the other hand, we present approximation algorithms which provide somewhat weaker approximation guarantees, such as bicriteria approximations for the POV objective and constant-factor approximations for MOV. Finally, we present mixed integer programming formulations for these problems. Experimental results show that our approximation algorithms often find near-optimal control strategies, indicating that election control through social influence is a salient threat to election integrity. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">128</td>#}
        <td class="tg-031e">Amittai Cohen-Zemach, Yoad Lewenberg, Jeffrey Rosenschein </td>
        <td class="tg-031e">Gerrymandering Over Graphs</td>
{#        <td class="tg-031e"> In many real-life scenarios, voting problems consist of several phases: an overall set of voters is partitioned into subgroups, each subgroup chooses a preferred candidate, and the final winner is selected from among those candidates. The attempt to skew the outcome of such a voting system through strategic partitioning of the overall set of voters into subgroups is known as ``gerrymandering''. We investigate the problem of gerrymandering over a network structure; the voters are embedded in a social network, and the task is to divide the network into connected components such that a target candidate will win in a plurality of the components. We first show that the problem is NP-complete in the worst case. We then perform a series of simulations, using random graph models incorporating a homophily factor. In these simulations we show that a simple greedy algorithm can be quite successful in finding a partition in favor of a specific candidate.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">463</td>#}
        <td class="tg-031e">Robert Bredereck, Andrzej Kaczmarczyk, Rolf Niedermeier </td>
        <td class="tg-031e">Envy-Free Allocations Respecting Social Networks</td>
{#        <td class="tg-031e"> Finding an envy-free allocation of indivisible resources to agents is a central task in many multiagent systems. Often, non-trivial envy-free allocations do not exist, and finding them can be a computationally hard task. Classic envy-freeness requires that every agent likes the resources allocated to it at least as much as the resources allocated to any other agent. In many situations this assumption can be relaxed since agents often do not even know each other. We enrich the envy-freeness concept by taking into account  social networks of the agents. Thus, we compare every agent’s resources with those of its neighbors. This leads to a “more local” concept of envy-freeness. We also consider a strong variant where every agent must like its own allocations more than those of all its neighbors.  We analyze the classic and the parameterized complexity of finding allocations that are envy-free with respect to one of the variants of our new concept, and that either are complete, are Pareto-efficient, or optimize the utilitarian social welfare. To this end, we study different restrictions of the agents’ preferences and of the social network structure. We identify cases that become easier  and cases that become harder  when comparing classic envy-freeness with our graph-based envy-freeness. Furthermore, we spot cases where graph envy-freeness is easier to decide than strong graph envy-freeness, and vice versa.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">479</td>#}
        <td class="tg-031e">Aureacutelie Beynier, Laurent Gourves, Julien Lesca, Nicolas Maudet, Yann Chevaleyre, Anaëlle Wilczynski </td>
        <td class="tg-031e">Local Envy-Freeness in House Allocation Problems</td>
{#        <td class="tg-031e"> We study the fair division problem consisting in &nbsp;allocating one item per agent so as to avoid  envy, in a setting where only agents connected in a given social network may experience envy. In a variant of the problem, agents themselves can be located on the network by the central authority. These problems turn out to be difficult even on very simple graph structures, but we identify several tractable cases. We further provide practical algorithms and experimental insights.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">173</td>#}
        <td class="tg-031e">Alan Tsang, Amirali Salehi-Abari, Kate Larson </td>
        <td class="tg-031e">Boundedly Rational Voters in Large Networks</td>
{#        <td class="tg-031e"> In Iterative Voting, voters first cast their ballots but may change their minds upon observing the ballots of others.&nbsp; Previous models have extended Iterative Voting to the incomplete information domain of social networks, where voters only observe the ballots of their friends.&nbsp; However, these models are based on computationally-intensive calculations of expected utilities.&nbsp; We propose a framework of bounded rationality for voters situated in social networks.&nbsp; Using this framework, we propose and test a number of heuristics that reduce the computation required for optimal strategic reasoning by several orders of magnitude compared to previous work, while retaining similar qualitative behaviors.&nbsp; These heuristics enable us to conduct simulations on how the size of the voting population affects strategic behavior.&nbsp; To illustrate the effectiveness of our approach, we apply our heuristics to explore the Micromega rule –-- an observation in political science that large political parties favor small assemblies.&nbsp; We find that the size of electoral districts is a contributing factor to the Micromega rule in some networks. Fringe candidates retain more support in smaller districts, while larger parties dominate in larger districts. </td>#}
        </tr>

        <tr>
                    <td class="tg-s6z3" rowspan="6" nowrap>Session 9 (13:30-15:30)<br> Auctions and Mechanism Design 2 (T6)</td>
{#        <td class="tg-s6z2">115</td>#}
        <td class="tg-031e">Keiichiro Hayakawa, Enrico Gerding, Sebastian Stein, Takahiro Shiga </td>
        <td class="tg-031e">Price-based Online Mechanisms for Settings with Uncertain Future Procurement Costs and Multi-Unit Demand</td>
{#        <td class="tg-031e"> We examine the use of online mechanism design in settings where consumers have multi-unit demand, goods are procured and allocated over time, and future procurement costs are uncertain and only become known at the time of allocation. An important application with such characteristics is demand response, where electricity wholesale prices depend on overall demand and the availability of renewables. We formulate this as a mechanism design problem and focus specifically on the property that the mechanism does not revoke any allocated items. For this setting, we characterise a class of price-based mechanisms that guarantee dominant-strategy incentive compatibility, individual rationality, and no cancellation. We present three specific such mechanisms in this domain and evaluate them in an electric vehicle charging setting. Using extensive numerical simulations, we show that a mechanism based on the first-come first-serve principle performs well in settings where future procurement costs can be estimated reliably or supply is very tight, while a responsive mechanism performs very well when the estimated procurement costs are highly uncertain and supply is not as tight. We moreover show that a well-defined price-based mechanism can lead to high profits for the operator of the mechanism in many real-world situations. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">141</td>#}
        <td class="tg-031e">John P. Dickerson, Karthik Abinav Sankararaman, Aravind Srinivasan, Pan Xu </td>
        <td class="tg-031e">Assigning Tasks to Workers based on Historical Data: Online Task Assignment with Two-sided Arrivals</td>
{#        <td class="tg-031e"> Efficient allocation of tasks to workers is a central problem in crowdsourcing. In this paper, we consider a special setting inspired from spatial crowdsourcing platforms where both workers and tasks arrive dynamically. Additionally, we assume all tasks are&nbsp; heterogeneous&nbsp; and each worker-task assignment brings a distinct reward. The natural challenge lies in how to incorporate the uncertainty in the arrivals from both workers and tasks into our online allocation policy such that the total expected rewards are maximized. To attack this challenge,&nbsp; we assume the arrival patterns of worker "types" and task "types" are not erratic and can be predicted from historical data. To be more specific, we consider a finite time horizon T and assume in each time-step, a single worker and task are sampled  from two respective distributions independently, and this sampling process repeats identically and independently for the entire T online time-steps.     Our model, called Online Task Assignment Problem with Two-Sided Arrival,  is a significant generalization of the classical online task assignment problem where the set of tasks is assumed to be available offline.&nbsp; For the general version of OTAP-TSA, we present an optimal non-adaptive algorithm which achieves an online competitive ratio of 0.295. For the special case of OTAP-TSA&nbsp;where the reward is a function of just the worker type, we present an improved algorithm  and achieves a competitive ratio of at least 0.345. On the hardness side, along with showing that the ratio obtained by our non-adaptive algorithm is the best possible among all non-adaptive algorithms, we further show that no  algorithm can achieve a ratio better than 0.581,  even for the special case of OTAP-TSA&nbsp;with homogenous tasks . At the heart of our analysis lies a new technical tool,  called the two-stage birth-death process, which may be of independent interest. Finally, we perform numerical experiments on two real-world datasets obtained from crowdsourcing platforms to complement our theoretical results. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">363</td>#}
        <td class="tg-031e">Chaolun Xia, Shan Muthukrishnan </td>
        <td class="tg-031e">Arbitrage-free Pricing in User-based Markets</td>
{#        <td class="tg-031e">#}
{#            Users have various attributes, and in user-based markets there are buyers who wish to#}
{#        buy a target set of users with specific sets of attributes. The problem we address is that, given a set#}
{#        of demand from the buyers, how to allocate users to buyers, and how to price the transactions. This#}
{#        problem arises in online advertising, and is particularly relevant in advertising in social platforms like#}
{#        Facebook, LinkedIn and others where users are represented with many attributes, and advertisers are#}
{#        buyers with specific targets. This problem also arises more generally in selling data about online users,#}
{#        in a variety of data markets.#}
{##}
{#                              We introduce   arbitrage-free   pricing, that is, pricing that prevents buyers from acquiring a lower unit#}
{#        price for their true target by strategically choosing substitute targets and combining them suitably.#}
{#        We show that   uniform   pricing – pricing where all the targets have identical price – can be computed in#}
{#        polynomial time, and while this is arbitrage-free, it is also a logarithmic approximation to the maximum#}
{#        revenue arbitrage-free pricing solution. We also design a different arbitrage-free non-uniform pricing#}
{#        – pricing where different targets have different prices – solution which has the same guarantee as the#}
{#        arbitrage-free uniform pricing but is empirically more effective as we show through experiments. We#}
{#        also study more general versions of this problem and present hardness and approximation results.&nbsp;#}
{##}
{##}
{#                </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">360</td>#}
        <td class="tg-031e">Yuho Wada, Tomohiro Ono, Taiki Todo, Makoto Yokoo </td>
        <td class="tg-031e">Facility Location with Variable and Dynamic Populations</td>
{#        <td class="tg-031e">   Facility location is a well-studied problem in social choice literature, where agents' preferences are restricted to be singlepeaked. When the number of agents is considered as a variable,  a social choice function must be defined so that it can take any possible number of preferences as input. Furthermore, there exist cases where multiple choices must be made continuously while agents dynamically dynamically arrive/leave. Under such variable/ dynamic populations, a social choice function needs to give each agent an incentive to sincerely report her existence . In this paper we consider facility location models with variable/dynamic populations. For a static,  variable population model, we provide a necessary and sufficient condition for a social choice function to satisfy participation, as well as truthfulness, anonymity, and Pareto efficiency. It is considered as a further restriction of median voter schemes. For a dynamic model, we first propose an online social choice function, which is optimal for the total sum of the distances between the choices in previous and current periods, among any Pareto efficient functions.We then define a generalized class of online social choice functions and compare their performance in both theoretical and experimental way.&nbsp;      </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">278</td>#}
        <td class="tg-031e">Manisha Padala, Cv Jawahar, SUJIT GUJAR </td>
        <td class="tg-031e">Learning Optimal Redistribution Mechanisms Through Neural Networks</td>
{#        <td class="tg-031e"> We consider a social setting where $p$ public resources/objects are to be allocated among $n$ competing and strategic agents so as to maximize social welfare . This is called allocative efficiency . We need the agents to report their valuations&nbsp; for obtaining these resources, truthfully. This is called dominant strategy incentive compatibility . Typically, we use auction based mechanisms to achieve AE and DSIC. However, due to Green-Laffont Impossibility Theorem, we cannot ensure budget balance in the system while ensuring AE and DSIC. That is, the net transfer of money cannot be zero. This problem has been addressed by designing a redistribution mechanism so as to ensure minimum surplus of money as well as AE and DSIC. The objective could be to minimize surplus in expectation or in worst case and these objects could be homogeneous or heterogeneous. The designing of such mechanisms is non-trivial and especially designing redistribution mechanisms which perform well in expectation becomes analytically challenging for heterogeneous settings.&nbsp;     In this paper, we take a completely different, data-driven approach. We train a neural network to determine an optimal redistribution mechanism based on given settings with both the objectives,&nbsp; optimal in expectation and optimal in worst case. We also propose a loss function to train neural network to optimize worst case. We design&nbsp; neural networks with underlying rebate functions to be linear as well as nonlinear in terms of bids of the agents. Our networks achieve the theoretical guarantees for the cases where it has been solved. We observe that a neural network based redistribution mechanism for homogeneous settings which uses nonlinear rebate functions, outperforms linear rebate functions when the objective is optimal in expectation. Our approach also yields an optimal in expectation redistribution mechanism for heterogeneous settings. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">599</td>#}
        <td class="tg-031e">Zhe Feng, Harikrishna Narasimhan, David Parkes </td>
        <td class="tg-031e">Deep Learning for Revenue-Optimal Auctions with Budgets</td>
{#        <td class="tg-031e"> The design of revenue-maximizing auctions for settings with private budgets is a hard task. Even the single-item case is not fully understood, and there are no known optimal auctions, or even characterization results, for multi-item settings. In this work, we model a mechanism as a neural network, and use machine learning for the automated design of optimal auctions.&nbsp; We extend the {\em RegretNet} framework~\cite{deep-auction} to handle private budget constraints and&nbsp; Bayesian incentive compatibility.&nbsp; We discover new auctions with very close approximations to incentive-compatibility and high revenue for multi-unit auctions with private budgets, including problems with unit-demand bidders. For benchmarking purposes, we also illustrate that {\em RegretNet} can obtain essentially optimal designs for simpler settings where analytical solutions are available~\cite{CHE2000,Malakhov2008,PAI2014}. </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="6" nowrap>Session 10 (13:30-15:30)<br> Logic and Games (C3)</td>
{#        <td class="tg-s6z2">566</td>#}
        <td class="tg-031e">Lavindra de Silva </td>
        <td class="tg-031e">HTN Acting: A Formalism and an Algorithm</td>
{#        <td class="tg-031e"> Hierarchical Task Network  planning is a practical and efficient#}
{#        approach to planning when 'standard operating procedures' for a domain are available. Like Belief-Desire-Intention  agent#}
{#        reasoning, HTN planning performs hierarchical and context-based#}
{#        refinement of goals into subgoals and basic actions. However, while#}
{#        HTN planners 'lookahead' over the consequences of choosing one#}
{#        refinement over another, BDI agents interleave refinement with acting#}
{#        in the real world. There has been a renewed interest in making#}
{#        HTN planners behave more like BDI agent systems, e.g. to have a#}
{#        unified representation for acting and planning. However, past work#}
{#        on the subject has remained informal or implementation-focused.#}
{#        Thus, this paper is a formal account of HTN acting, which supports#}
{#        interleaved deliberation, action, and failure recovery. To this end,#}
{#        we use the syntax of the most general HTN planning formalism and#}
{#        build on its core machinery, and we provide an algorithm which#}
{#        combines our new formalism with the continual processing of exogenous#}
{#        events. We also study the properties of HTN acting and#}
{#        its relation to HTN planning.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">100</td>#}
        <td class="tg-031e">Valentin Goranko, Sebastian Enqvist </td>
        <td class="tg-031e">Socially Friendly and Group Protecting Coalition Logics</td>
{#        <td class="tg-031e"> We consider extensions of Coalition Logic  which can express statements about inter-related powers of coalitions to achieve their respective goals. In particular, we introduce and study two new extensions of CL. One of them is the ``Socially Friendly Coalition Logic'' SFCL, which is also a multi-agent extension of the recently introduced ``Instantial Neighborhood Logic'' INL. The logic SFCL can express the claim that a coalition has a collective strategy to guarantee achieving its explicitly stated goal while acting in a `socially friendly way', by enabling the remaining agents to achieve other  goals of their choice. The other new extension is the ``Group Protecting Coalition Logic'' GPCL which enables reasoning about entire coalitional goal assignments, in which every group of agents has its own specified goal. &nbsp;GPCL can express &nbsp;claims to the effect that there is an action profile of the grand coalition such that, by playing it, every sub-coalition of agents can guarantee satisfaction of its own private goal  while acting towards achievement of the common goal of the grand coalition. For each of these logics, we discuss its expressiveness, introduce the respective notion of bisimulation and prove bisimulation invariance and Hennessy-Milner property. We then also present sound and complete axiomatic systems and prove decidability for both logics.&nbsp;  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">229</td>#}
        <td class="tg-031e">Joseph Boudou, Emiliano Lorini </td>
        <td class="tg-031e">Concurrent Game Structures for Temporal STIT Logic</td>
{#        <td class="tg-031e">  The paper introduces a new semantics for STIT logic    based on concurrent game structures,  thereby strengthening the connection   between STIT and existing logics for MAS including coalition logic, alternating-time   temporal logic and strategy logic, whose languages are usually interpreted over CGSs. Moreover, it   provides a complexity result for a rich temporal STIT language interpreted over these structures.   The language extends that of full computation tree logic CTL* by individual agency operators,   allowing to express sentences of the form ``agent i sees to it that phi is true, as a consequence her choice''.   </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">47</td>#}
        <td class="tg-031e">Pavel Naumov, Jia Tao </td>
        <td class="tg-031e">Second-Order Know-How Strategies</td>
{#        <td class="tg-031e"> The fact that a coalition has a strategy does not mean that the coalition knows what the strategy is. If the coalition knows the strategy, then such a strategy is called a know-how strategy of the coalition. The paper proposes the notion of a second-order know-how strategy for the case when one coalition knows what the strategy of another coalition is. The main technical result is a sound and complete logical system describing the interplay between the distributed knowledge modality and the second-order coalition know-how modality.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">483</td>#}
        <td class="tg-031e">Julian Gutierrez, Paul Harrenstein, Thomas Steeples, Michael Wooldridge </td>
        <td class="tg-031e">Local Equilibria in Logic-Based Multi-Player Games</td>
{#        <td class="tg-031e"> Game theory provides a well-established framework for the analysis and verification of concurrent and multi-agent systems. In such a framework, typically, the analysis of a multi-agent system involves computing the set of equilibria in the associated multi-player game representing the behaviour of the system. In this setting, as systems grow larger, it becomes harder to find equilibria in the game -- which represent the rationally stable behaviours of the multi-agent system . To address this issue, in this paper, we study the concept of local equilibria in which we are interested in  stable coalitions of agents with respect to which an equilibrium can be found. We focus on solutions given by Nash equilibria, and base our study in Boolean games and iterated Boolean games, two logic-based models of concurrent and multi-agent systems where players' goals are given by formulae in, respectively, propositional logic and LTL.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">481</td>#}
        <td class="tg-031e">Maria-Florina Balcan, Avrim Blum, Shang-Tse Chen </td>
        <td class="tg-031e">Diversified Strategies for Mitigating Adversarial Attacks in Multiagent Systems</td>
{#        <td class="tg-031e">  In this work we consider online decision-making settings in which players have an additional constraint that at each time step they must play a diversified mixed strategy: one that does not put too much weight on any one action. This constraint is motivated by applications such as finance, routing, and resource allocation, in which one would like to limit the chance of catastrophic failure while still performing well in typical cases. We explore properties of diversified strategies in both zero-sum and general-sum games, and provide algorithms for minimizing regret within the family of diversified strategies as well as methods for using taxes or fees to guide standard regret-minimizing players towards diversified strategies. We also analyze equilibria produced by diversified strategies in general-sum games. We show that surprisingly, requiring diversification can actually lead to higher-quality equilibria, and give strong guarantees on both price of anarchy and the social welfare produced by regret-minimizing diversified agents. We additionally give algorithms for finding optimal diversified strategies in distributed settings where one must limit communication overhead.   </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="6" nowrap>Session 11 (13:30-15:30)<br> Learning and Adaptation 2 (T1 & T2)</td>
{#        <td class="tg-s6z2">630</td>#}
        <td class="tg-031e">Frits de Nijs, Georgios Theocharous, Nikos Vlassis, Mathijs de Weerdt, Matthijs Spaan </td>
        <td class="tg-031e">Capacity-aware Sequential Recommendations</td>
{#        <td class="tg-031e"> Personalized recommendations are increasingly important to engage users and guide them through large systems, for example when recommending points of interest to tourists visiting a popular city. To maximize long-term user experience it is imperative to consider issuing a sequence of recommendations, given that by observing the user's response to a recommendation, the recommender system can update its estimate of the user's  interests. However, when considering a large number of users and capacity limits,  the recommender system should not only consider the users' interests, but also the effect of recommendations on the available capacity.  The structure in such a constrained, multi-agent, partially observable decision problem can be exploited by a novel belief-space sampling algorithm which bounds the size of the state space by a limit on regret. This algorithm is significantly more scalable than state-of-the-art approximate POMDP planners. Moreover, by explicitly considering the information value of actions, this algorithm significantly improves the quality of recommendations over an extension of Thompson sampling to the multi-agent, constrained case. We show how&nbsp; constraint satisfaction can be decoupled from sequential recommendation policies, resulting in algorithms that compute recommendations for thousands of agents while respecting capacity limits.   </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">592</td>#}
        <td class="tg-031e">Ashiqur KhudaBukhsh, Jaime Carbonell </td>
        <td class="tg-031e">Expertise Drift in Referral Networks</td>
{#        <td class="tg-031e"> Learning-to-refer is a challenge in expert referral networks, wherein Active Learning helps experts  estimate the skills of other connected experts for different categories of tasks that the initial expert cannot solve and therefore must seek referral to experts with more appropriate expertise. Prior research has investigated different reinforcement action selection algorithms to assess viability of the learning setting both with uninformative priors and with partially available noisy priors, where experts are allowed to advertise a subset of their skills to their colleagues. Prior to this work, time-varying expertise drift  has not been considered though it is an aspect that may often arise in practice. This paper addresses the challenge of referral learning with time-varying expertise, proposing&nbsp; Hybrid, a novel combination of Optimistic Thompson Sampling, Pessimistic Thompson Sampling and Distributed Interval Estimation Learning . In our extensive empirical evaluation, considering both biased and unbiased drift, the proposed algorithm outperforms the previous state-of-the-art  and approaches the drift-aware oracle upper bound.&nbsp;  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">565</td>#}
        <td class="tg-031e">Thomas Spooner, John Fearnley, Rahul Savani, Andreas Koukorinis </td>
        <td class="tg-031e">Market making via reinforcement learning</td>
{#        <td class="tg-031e">Market making is a fundamental trading problem in which an agent provides liquidity by continually offering to buy and sell a security. The problem is challenging due to inventory risk, the risk of accumulating an unfavourable position and ultimately losing money. In this paper, we develop a high-fidelity simulation of limit order book markets, and use it to design a market making agent using temporal-difference reinforcement learning. We use a linear combination of tile codings as a value function approximator, and design a custom reward function that controls inventory risk. We demonstrate the effectiveness of our approach by showing that our agent outperforms both simple benchmark strategies and a recent online learning approach from the literature. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">485</td>#}
        <td class="tg-031e">Gregory Palmer, Karl Tuyls, Rahul Savani, Daan Bloembergen </td>
        <td class="tg-031e">Lenient Multi-Agent Deep Reinforcement Learning</td>
{#        <td class="tg-031e">Much of the success of single agent deep reinforcement learning  in recent years can be attributed to the use of experience replay memories,  which allow Deep Q-Networks  to be trained efficiently through sampling stored state transitions. However, care is required when using ERMs for multi-agent deep reinforcement learning,  as stored transitions can become outdated because agents update their policies in parallel . In this work we apply leniency   to MA-DRL. Lenient agents map state-action pairs to decaying temperature values that control the amount of leniency applied towards negative policy updates that are sampled from the ERM. This introduces optimism in the value-function update, and has been shown to facilitate cooperation in tabular fully-cooperative multi-agent reinforcement learning problems. We evaluate our Lenient-DQN  empirically against the related Hysteretic-DQN  algorithm  as well as a modified version we call scheduled-HDQN, that uses average reward learning near terminal states. Evaluations take place in extended variations of the Coordinated Multi-Agent Object Transportation Problem   which include fully-cooperative sub-tasks and stochastic rewards. We find that LDQN agents are more likely to converge on the optimal policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN agents. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">659</td>#}
        <td class="tg-031e">Rodrigo Toro Icarte, Toryn Klassen, Richard Valenzano, Sheila McIlraith </td>
        <td class="tg-031e">Teaching Multiple Tasks to an RL Agent using LTL</td>
{#        <td class="tg-031e"> This paper examines the problem of how to teach multiple tasks to an agent that learns using Reinforcement Learning . To this end, we propose the use of Linear Temporal Logic  as a compelling language for teaching multiple tasks to an RL agent in a manner that supports composition of learned skills. We also propose a novel algorithm that exploits LTL progression and off-policy RL to speed up learning without compromising convergence guarantees. Experiments over randomly generated Minecraft-like grids illustrate our superior performance relative to the state of the art.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">713</td>#}
        <td class="tg-031e">Maxime Bouton, Kyle Julian, Alireza Nakhaei, Kikuo Fujimura, Mykel Kochenderfer </td>
        <td class="tg-031e">Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty</td>
{#        <td class="tg-031e"> Decomposition methods have been proposed in the past to approximate solutions to large sequential decision making problems. In contexts where an agent interacts with multiple entities, utility decomposition can be used where each individual entity is considered independently. The individual utility functions are then combined in real time to solve the global problem. Although these techniques can perform well empirically, they sacrifice optimality. This paper proposes an approach inspired from multi-fidelity optimization to learn a correction term with a neural network representation. Learning this correction can significantly improve performance. We demonstrate this approach on a pedestrian avoidance problem for autonomous driving. By leveraging strategies to avoid a single pedestrian, the decomposition method can scale to avoid multiple pedestrians. We verify empirically that the proposed correction method leads to a significant improvement over the decomposition method alone and outperforms a policy trained on the full scale problem without utility decomposition.  </td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="6" nowrap>Session 12 (13:30-15:30)<br> Socially Interactive Agents 1 (C8)</td>
{#        <td class="tg-s6z2">S43</td>#}
        <td class="tg-031e">Jan Poppel; Stefan Kopp</td>
        <td class="tg-031e">Satisficing Models of Bayesian Theory of Mind for Explaining Behavior of Differently Uncertain Agents</td>
{#        <td class="tg-031e">The Bayesian Theory of Mind  framework has become a common approach to model reasoning about other agents' desires and beliefs based on their actions. Such models can get very complex when being used to explain the behavior of agents with different uncertainties, giving rise to the question if simpler models can also be satisficing, i.e. sufficing and satisfying, in different uncertainty conditions. In this paper we present a method to simplify inference in complex ToM models by switching between discrete assumptions about certain belief states  based on the resulting surprisal. We report on a study to evaluate a complex full model, simplified versions, and a switching model on human behavioral data in a navigation task under specific uncertainties. Results show that the switching model achieves inference results better than the full Bayesian ToM model and with higher efficiency, providing a basis for attaining the ability for "satisficing mentalizing" in social agents. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">S55</td>#}
        <td class="tg-031e">Abdelwahab Bourai; Jaime Carbonell</td>
        <td class="tg-031e">I Know What You Don't Know: Proactive Learning through Targeted Human Interaction</td>
{#        <td class="tg-031e">Humans communicate extensively through "meta-information" encoded in emitted non-verbal signals. This meta-information not only allows us to analyze an individual's external emotional state but also certain internal states. For example, humans are able to learn from others thanks to their ability to determine their most knowledgeable peers in a given domain through their interactions with these individuals. As autonomous agents expand into more socially oriented tasks, they must capture and reason through these emitted cues to better understand their human counterparts. In this work, we conduct two experiments. First, we train a model to predict the knowledgeability of speakers using non-verbal features. Next we simulate the process of selecting the most knowledgeable person in a given domain using a proactive learning approach. The results indicate our agent is capable of observing human behavior and using this information to select a specific human for aid on a given question. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">S10</td>#}
        <td class="tg-031e">Tim Miller; Ronal Singh; Joshua Newn; Liz Sonenberg; Eduardo Velloso; Frank Vetere</td>
        <td class="tg-031e">Combining Planning with Gaze for Online Human Intention Recognition</td>
{#        <td class="tg-031e">Intention recognition is the process of using behavioural cues to infer an agent's goals or future behaviour. People use many behavioural cues to infer others' intentions, such as deliberative actions, facial expressions, eye gaze, and gestures. In artificial intelligence, two approaches for intention recognition, among others, are gaze-based and model-based intention recognition. Approaches in the former class use gaze to determine which parts of a space a person looks at more often to infer a person's intention. Approaches in the latter use models of possible future behaviour to rate intentions as more likely if they are a better `fit' to observed actions. In this paper, we propose a novel model of human intention recognition that combines gaze and model-based approaches for online human intention recognition. Gaze data is used to build probability distributions over a set of possible intentions, which are then used as priors in a model-based intention recognition algorithm. In human-behavioural experiments  involving a multi-player board game, we found that adding gaze-based priors to model-based intention recognition more accurately determined intentions,  determined those intentions earlier,  and at no additional cost; all compared to a model-based-only approach.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">S33</td>#}
        <td class="tg-031e">Patrick Gebhard; Tanja Schneeberger; Tobias Baur; Elisabeth Andre</td>
        <td class="tg-031e">MARSSI: Model of Appraisal, Regulation, and Social Signal Interpretation</td>
{#        <td class="tg-031e">Understanding emotions of others requires a theory of mind approach providing knowledge of internal appraisal and regulation processes of emotions. Multi-modal social signal classification is insufficient for understanding emotional expressions. Mainly, because many communicative, emotional expressions are not directly related to internal emotional states. Moreover, the recognition of the expression's direction is neglected so far. Even if social signals reveal emotional aspects, the recognition with signal classifiers cannot explain internal appraisal or regulation processes. Using that information is one approach for building cognitive empathic agents with the ability to address observations and motives in an empathic dialogue. In this paper, we introduce a computational model of user emotions for empathic agents. It combines a simulation of appraisal and regulation processes with a social signal interpretation taking directions of expressions into account. Our evaluation shows that social signal sequences can be related to emotion regulation processes. Their recognition and using appraisal and regulation knowledge enables our agent to react empathically.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">S14</td>#}
        <td class="tg-031e">Filipa Correia; Carla Guerra; Samuel Mascarenhas; Francisco S. Melo; Ana Paiva</td>
        <td class="tg-031e">Exploring the impact of fault justification in human-robot trust</td>
{#        <td class="tg-031e">With the growing interest on human-robot collaboration, the development of robotic partners that we can trust has to consider the impact of error situations. In particular, human-robot trust has been pointed as mainly affected by the performance of the robot and as such, we believe that in a collaborative setting, trust towards a robotic partner may be compromised after a faulty behaviour. This paper contributes to a user study exploring how a technical failure of an autonomous social robot affects trust during a collaborative scenario, where participants play the Tangram game in turns with the robot. More precisely, in a 2x2  experiment we investigated 2 different recovery strategies, justify the failure or ignore the failure, after 2 different consequences of the failure, compromising or not the collaborative task. Overall, the results indicate that a faulty robot is perceived significantly less trustworthy. However, the recovery strategy of justifying the failure was able to mitigate the negative impact of the failure when the consequence was less severe. We also found an interaction effect between the two factors considered. These findings raise new implications for the development of reliable and trustworthy robots in human-robot collaboration.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">S19</td>#}
        <td class="tg-031e">Feyza Hafizoglu; Sandip Sen</td>
        <td class="tg-031e">The Effects of Past Experience on Trust in Repeated Human-Agent Teamwork</td>
{#        <td class="tg-031e">For human-agent virtual ad hoc teams to be effective, humans must be able to trust their agent counterparts. To earn the human's trust, agents need to quickly develop an understanding of the expectation of human team members and adapt accordingly. This study empirically investigates the impact of past experience on human trust in and behavior towards agent teammates. To do so, we developed a repeated team coordination game, the Game of Trust,  in which two players repeatedly cooperate to complete team tasks without prior assignment of subtasks. The effects of past experience on human trust are evaluated by performing an extensive set of controlled experiments with participants recruited from Amazon Mechanical Turk, a crowdsourcing marketplace. We collect both teamwork performance data as well as surveys to gauge participants' trust in their agent teammates. The results show that positive  past experience increases  human trust in agent teammates and past experience can affect three antecedents of trust: emotional state, game expertise, and expectation. These findings provide clear and significant evidence of the influence of key factors on human trust in virtual agent teammates and enhance our understanding of the changes in human trust in peer-level agent teammates with respect to past experience.</td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="6" nowrap>Session 13 (13:30-15:30)<br> Robotics: Multi-Robot Coordination (C7)</td>
{#        <td class="tg-s6z2">R33</td>#}
        <td class="tg-031e">Dario Albani, Tiziano Manoni, Daniele Nardi, Vito Trianni </td>
        <td class="tg-031e">Dynamic UAV Swarm Deployment for Non-Uniform Coverage</td>
{#        <td class="tg-031e">In many monitoring and mapping applications, high-resolution data are required only in certain areas while others can receive lower attention. To this end, unmanned aerial vehicles  can adjust the flight altitude to increase the resolution only where needed, making non-uniform coverage strategies efficient both in time and energy expenditure.  In a multi-UAV monitoring context, it is necessary to deploy UAVs to inspect in parallel those areas where a higher resolution is required. To address this problem, we propose a decentralised deployment strategy inspired by the collective behaviour of honeybees. This strategy dynamically assigns UAVs to different areas to be monitored, and suitably re-assigns them to other areas when needed. We introduce an analytical macroscopic model of area monitoring from UAVs, and we propose a parameterisation that leads to an efficient allocation of UAVs to the areas to be monitored. We exploit abstract multi-agent simulations to study the dynamics of the deployment of UAVs to multiple areas, and we present results with simulations of a UAV swarm engaged in a weed monitoring and mapping task.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R34</td>#}
        <td class="tg-031e">Erez Hartuv, Noa Agmon, Sarit Kraus </td>
        <td class="tg-031e">Scheduling Spare Drones for Persistent Task Performance under Energy Constraints</td>
{#        <td class="tg-031e">This paper considers the problem of enabling persistent execution of a multi-drone task under energy limitations. The drones are given a set of locations and their task is to ensure that at least one drone will be present, for example for monitoring, over each location at any given time. Because of energy limitations, drones must be replaced from time to time, and fly back home where their batteries can be replaced. Our goals are to identify the minimum number of spare drones needed to accomplish the task while no drone battery drains, and to provide a drone replacement strategy. We present an efficient procedure for calculating whether one spare drone is enough for a given task and provide an optimal replacement strategy. If more than one drone is needed, we aim at finding the minimum number of spare drones required, and extend the replacement strategy to multiple spare drones by introducing a new Bin-Packing variant, named Bin Maximum  Item Double Packing . Since the problem is presumably computationally hard, we provide a first fit greedy approximation algorithm for efficiently solving the $\bmidp$ problem. For the offline version, in which all locations are known in advance, we prove an approximation factor upper bound of 1.5, and for the online version, in which locations are given one by one, we show via extensive simulations, that the approximation yields an average factor of 1.7.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R63</td>#}
        <td class="tg-031e">Volker Strobel, Eduardo Castello Ferrer, Marco Dorigo</td>
        <td class="tg-031e">Managing Byzantine Robots via Blockchain Technology in a Swarm Robotics Collective Decision Making Scenario</td>
        <tr>
{#        <td class="tg-s6z2">R64</td>#}
        <td class="tg-031e">Thadeu Tucci, Benoit Piranda, Julien Bourgeois </td>
        <td class="tg-031e">A Distributed Self-Assembly Planning Algorithm for Modular Robots</td>
{#        <td class="tg-031e"> A distributed modular robot is composed of many autonomous modules, capable of organizing the overall robot into a specific goal structure. There are two possibilities to change the morphology of such a robot. The first one, self-reconfiguration, moves each module to the right place, whereas the second one, self-assembly docks the modules at the right place.&nbsp;  Self-assembly is composed of two steps,  identifying the free positions that are available for docking and  docking the modules to these positions. This work focuses on the first step.  This paper presents a distributed planning algorithm that can decide which positions can be filled and can create any 3D shape, including shapes with internal holes and concavities. Our algorithm consider kinematic constraints and prevents positions from being blocked.  Each module embeds the same algorithm and coordinates with the others by means of neighbor-to-neighbor communication. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R77</td>#}
        <td class="tg-031e">Laetitia Matignon, Olivier Simonin </td>
        <td class="tg-031e">Multi-Robot Simultaneous Coverage and Mapping of Complex Scene - Comparison of Different Strategies</td>
{#        <td class="tg-031e">This paper addresses the problem of optimizing the observation of a human scene using several mobile robots. Mobile robots have to cooperate to find a position around the scene maximizing its coverage. The scene coverage is defined as the observation of the human pose skeleton. It is assumed that the robots can communicate but have no map of the environment. Thus the robots have to simultaneously cover and map the scene and the environment. We consider an incremental approach to master state-space complexity. Robots build an hybrid metric-topological map while evaluating the observation of the human pose skeleton. To this end we propose and evaluate different online optimization strategies exploiting local versus global information. We discuss the difference of the performance and cost. Experiments are performed both in simulation and with real robots.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">R78</td>#}
        <td class="tg-031e">Ji Chen, Salar Moarref, Hadas Kress-Gazit </td>
        <td class="tg-031e">Verifiable Control of Robotic Swarm from High-level Specifications</td>
{#        <td class="tg-031e">Designing controllers for safe, scalable and flexible collective behaviors of large numbers of robots is an important and challenging problem in swarm robotics. In this paper, we focus on provably-correct controller synthesis from high-level specifications and demonstrate the approach on several physical swarms. To this end, we first automatically synthesize discrete controllers  from high-level task specifications expressed in temporal logic. Then, we automatically synthesize continuous controllers that implement the symbolic plans while ensuring collision avoidance and describe methods for mitigating deadlocks that might occur. In addition, centralized and decentralized continuous controller design are compared and analyzed. Finally, we demonstrate the flexibility and versatility of the control paradigm by applying it to three different examples of swarm systems with two different types of robots.</td>#}
        </tr>

        <tr>
            <td class="tg-s6z3" rowspan="5" nowrap>Session 14 (13:30-15:30)<br> Industrial Applications (C2)</td>
{#        <td class="tg-s6z2">I22</td>#}
        <td class="tg-031e">Shih-Fen Cheng, Shashi Shekhar Jha, Rishikeshan Rajendram </td>
        <td class="tg-031e">Taxis Strike Back: A Field Trial of the Driver Guidance System</td>
{#        <td class="tg-031e">Traditional taxi fleet operators world-over have been facing intense competitions from various ride-hailing services such as Uber and Grab . Based on our studies on the taxi industry in Singapore, we see that the emergence of Uber and Grab in the ride-hailing market has greatly impacted the taxi industry: the average daily taxi ridership for the past two years has been falling continuously, by close to 20% in total. In this work, we discuss how efficient real-time data analytics and large-scale multi-agent optimization technology could potentially help taxi drivers compete against more technologically advanced service platforms.#}
{##}
{#        Our technology is based on an earlier theoretical work proven to work in a series of simulation studies. Our major contribution in this paper is the demonstration that the proposed design, when coupled with a real-time data feed of close to 20,000 taxis around Singapore, can indeed help drivers to improve their performances. To provide concrete real-world evidence that such technology can indeed benefit taxi drivers, we have tested the driver guidance system  operationally since September 2017. With 57 recruited drivers and 2 months of operational data, we have demonstrated that when drivers actively follow our guidance during their roaming,  their expected roaming times can be reduced by 23% when compared to the cases where guidances are not followed. By further breaking down the analysis by time periods, workdays, and areas, we point out the spatial-temporal combinations in which the DGS is most useful.</td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">I19</td>#}
        <td class="tg-031e">Hussain Kazmi, Johan Suykens, Johan Driesen </td>
        <td class="tg-031e">Valuing knowledge, information and agency in Multi-agent Reinforcement Learning: a case study in smart buildings</td>
{#        <td class="tg-031e"> Increasing energy efficiency in buildings can reduce costs and emissions substantially. Historically, this has been treated as a local, or single-agent, optimization problem. However, many buildings utilize the same types of thermal equipment e.g. electric heaters and hot water vessels. During operation, occupants in these buildings interact with the equipment differently thereby driving them to diverse regions in the state-space. Reinforcement learning agents can learn from these interactions, recorded as sensor data, to optimize the overall energy efficiency. However, if these agents operate individually at a household level, they can not exploit the replicated structure in the problem. In this paper, we demonstrate that this problem can indeed benefit from multi-agent collaboration by making use of targeted exploration of the state-space allowing for better generalization. We also investigate trade-offs between integrating human knowledge and additional sensors. Results show that savings of over 40% are possible with collaborative multi-agent systems making use of either expert knowledge or additional sensors with no loss of occupant comfort. We find that such multi-agent systems comfortably outperform comparable single agent systems.  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">I25</td>#}
        <td class="tg-031e">Ayan Mukhopadhyay, Zilin Wang, Yevgeniy Vorobeychik </td>
        <td class="tg-031e">A Decision Theoretic Framework for Emergency Responder Dispatch</td>
{#        <td class="tg-031e"> Efficient emergency response is a major concern in urban areas across the globe. The problem of predicting incidents and subsequently allocating responders spatially has been studied extensively. The problem of dynamically deploying responders, however, has received considerably less attention and has been noted as a difficult problem in prior literature due to inherent complexities in the environment in which such problems evolve. We formulate a decision-theoretic framework for the emergency responder problem, which effectively leverages state-of-the-art methods for continuous-time spatio-temporal incident forecasting.&nbsp;  We formulate the responder dispatch problem as a Semi-Markov Decision Process  that evolves in continuous time, and efficiently engineer its representation leveraging structural insights of the problem space. We then propose a novel approach to solve the problem based on policy iteration. First, we transform the SMDP into a discrete-time MDP . Then, we simulate our system to estimate value of states as well as learn the state transition probabilities of the transformed DTMDP. We also design heuristic policies with which our algorithm can be seeded. We validate the efficacy of our approach on real traffic and assault data from a major metropolitan area in USA, as well as synthetic data, and highlight that our approach outperforms the state of the art emergency responder dispatch system. </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">I20</td>#}
        <td class="tg-031e">Michael Papasimeon </td>
        <td class="tg-031e">Multiagent Simulation of Adversarial Socio-Technical Systems</td>
{#        <td class="tg-031e">  We present and describe#}
{#        the Air Combat Environment ; a next generation industrial multiagent#}
{#        simulation environment for modelling adversarial socio-technical systems for#}
{#        computational operations research. Although ACE was designed to model domains#}
{#        such as air combat, the architectural framework is generic enough to model a#}
{#        wide range of complex adversarial socio-technical environments and scenarios. The#}
{#        paper begins by describing the legacy multiagent simulation environments that had#}
{#        a significant impact on the design of ACE.&nbsp;#}
{#        A motivating adversarial socio-technical scenario is presented followed#}
{#        by an overview of the key motivators that drove ACE's development. This leads#}
{#        into a high level, conceptual description of the key constructs which make up#}
{#        the core ACE software architecture. The paper then presents the three key ways#}
{#        ACE is used; as an agent-oriented software engineering platform, as an operations#}
{#        research platform and as a platform for conducting AI research. The paper#}
{#        concludes with a brief overview of the planned future directions for ACE as a#}
{#        platform for research into machine discovered behaviour in the context of#}
{#        modelling complex warfighting for force design.&nbsp;  </td>#}
        </tr>
        <tr>
{#        <td class="tg-s6z2">I21</td>#}
        <td class="tg-031e">Sethuramalingam Subramaniam, Pooja Aggarwal, Gargi B Dasgupta, Amit Paradkar </td>
        <td class="tg-031e">COBOTS - A Cognitive Multi-Bot Conversational Framework for Technical Support</td>
{#        <td class="tg-031e"> Human technical support agents spend significant time interacting with customers via various channels of voice, email and chat. There is a massive incentive to automate support with autonomous agents with the goal of reducing manual effort and time taken for problem resolution. As technical support questions are complex and diverse, building a generic agent capable of solving multiple domains is implausible. In this paper, we describe a scalable conversational framework that automates the process of guided troubleshooting called COBOTS . Our underlying premise is that scalability in such frameworks can be achieved by control and co-ordination across multiple domain expert bots. These bots co-ordinate to  understand user problems from natural language queries  engage in conversation&nbsp; and  provide assistance with troubleshooting. All of the above is done with minimum human assistance.&nbsp;&nbsp; COBOTS framework comprises of User Bots that monitor customer infrastructure for issues, the Orchestrator bot which co-ordinates and controls various request-response pairs and Domain Expert bots which handle issues pertaining to their domains, respectively. In a real environment, we have deployed an implementation of our COBOTS framework which can co-ordinate and control user queries across 11 different technical support domains. When evaluated by two different teams of expert support users, it was observed that more than 75% of the time our application was able to provide relevant solutions for their queries.  </td>#}
        </tr>
{#        <tr>#}
{#        <td class="tg-s6z2">I27</td>#}
{#        <td class="tg-031e">Cheng Wu </td>#}
{#        <td class="tg-031e">A Multi-agent Based Scheme for Unlicensed Spectrum Access in Railway Wireless Communication</td>#}
{#        <td class="tg-031e"> The rapid movement characteristics of the train in railway industry bring about a significant dynamic change in the communication network topology, resulting in unpredictable high volatility of the available spectrum. Such the uncertainty, coupled with the inherent spectrum of scarcity, is causing low efficiency. With this article, we first formulate spectrum management of railway cognitive radio as the distributed cooperative decision problem. By using reinforcement learning and agent theory, we propose the cognitive base station model. Furthermore, a multi-cognitive-base-station cascade collaboration algorithm is described according to the characteristics of the chain distribution and cascade operation of base stations along the track. Finally, this article evaluates the communication performance of test scenarios and proves that the system can significantly improve the probability of successful transmission and greatly reduce the number of wireless channel switching. This cognitive base station multi-agent system scheme provides a new idea for realizing the cognitive radio of railway industry and comprehensively solving the problem of low efficiency of the wireless spectrum. The article is also a typical case of artificial intelligence applied in the field of communication and signal processing.  </td>#}
{#        </tr>#}
{#        <tr>#}
{#        <td class="tg-s6z2">I29</td>#}
{#        <td class="tg-031e">Miguel Nunes </td>#}
{#        <td class="tg-031e">On a Multi-Agent Robotic System for Space Missions</td>#}
{#        <td class="tg-031e"> A revolution in the space sector is happening. It is expected that in the next decade there will be more satellites launched than in the previous sixty years of space exploration. Major challenges are associated with this growth of space assets such as the autonomy and management of large groups of satellites, in particular with small satellites. We present a flexible and distributed multiagent software architecture to expand the possibilities of spacecraft autonomy and we focus in particular on the autonomous motion. The approach taken is based on the concept of distributed software agents, also referred to as multi-agent robotic system. Agents are defined in this context as software programs that are social, reactive and proactive to autonomously maximize the chances of achieving the set goals. Part of the work is to demonstrate that a multi-agent robotic system is a feasible approach for different problems of autonomy such as satellite attitude determination and control and autonomous rendezvous and docking.&nbsp;  </td>#}
{#        </tr>#}
{#        ***********************************#}
{#        ************* NEXT DAY ************#}
{#        ***********************************#}
{#        ***********************************#}
        <tr>
            <td class="tg-9353" colspan="3"><font color="red"><H5><b>12 July 2018</b></H5></font></td>
        </tr>
        <tr>
<td class="tg-s6z3">Session<br></td>
{#<td class="tg-s6z2">Paper ID</td>#}
<td class="tg-031e">Authors</td>
<td class="tg-031e">Title</td>
{#<td class="tg-031e"> Abstract</td>#}
</tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 15 (10:30-11:50)<br>Auctions And Mechanism Design 3 (C2)</td>
{#    <td class="tg-s6z2">232</td>#}
    <td class="tg-031e">Matthias Gerstgrasser</td>
    <td class="tg-031e">On the Complexity of Optimal Correlated Auctions and Reverse Auctions</td>
{#    <td class="tg-031e"> &nbsp;&nbsp; We investigate the problem of finding a revenue-optimal auction with correlated bidders. We give an algorithm for the exact solution for two bidders, and for a 5/3-approximation for many bidders, improving from O runtime to O for both problems by exploiting structural properties of this problem directly. We show that for correlated bidders, reverse auctions behave differently from auctions. For two bidders we discuss a constant-factor reduction in complexity. For k &gt;= 3 bidders, we show that the optimal reverse auction must sometimes buy k copies of the item.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">85</td>#}
    <td class="tg-031e">Mason Wright, Michael Wellman</td>
    <td class="tg-031e">Evaluating the Stability of Non-Adaptive Trading in Continuous Double Auctions</td>
{#    <td class="tg-031e"> The continuous double auction  is the predominant mechanism in modern securities markets. Despite much prior study of CDA strategies, fundamental questions about the CDA remain open, such as:  to what extent can outcomes in a CDA be accurately modeled by optimizing agent actions over only a simple, non-adaptive policy class; and  when and how can a policy that conditions its actions on market state deviate beneficially from an optimally parameterized, but simpler, policy like Zero Intelligence . To investigate these questions, we present an experimental comparison of the strategic stability of policies found by reinforcement learning  over a massive space, or through empirical Nash-equilibrium solving over a smaller space of non-adaptive, ZI policies. Our findings indicate that in a plausible market environment, an adaptive trading policy can deviate beneficially from an equilibrium of ZI traders, by conditioning on signals of the likelihood a trade will execute or the favorability of the current bid and ask. Nevertheless, the surplus earned by well-calibrated ZI policies is empirically observed to be nearly as great as what a deviating reinforcement learner could earn, using a much larger policy space. This finding supports the idea that it is reasonable to use equilibrated ZI traders in studies of CDA market outcomes. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">170</td>#}
    <td class="tg-031e">Eleftherios Anastasiadis, Argyrios Deligkas</td>
    <td class="tg-031e">Heterogeneous Facility Location Games</td>
{#    <td class="tg-031e"> We study heterogeneous $k$-facility location games on a line segment. In this model there are $k$ facilities to be placed on a line segment where each facility serves a different purpose. Thus, the preferences of the agents over the facilities can vary arbitrarily. Our goal is to design strategy proof mechanisms that locate the facilities in a way to maximize the minimum utility among the agents. For $k=1$, if the agents' locations are known, we prove that the mechanism that locates the facility on an optimal location is strategy proof. For $k \geq 2$, we prove that there is no optimal strategy proof mechanism, deterministic or randomized, even when $k=2$ and there are only two agents with known locations. We derive inapproximability bounds for deterministic and randomized strategy proof mechanisms. Finally, we provide strategy proof mechanisms that achieve constant approximation. All of our mechanisms are simple and communication efficient. As a byproduct we show that some of our mechanisms can be used for other objectives as the social welfare and the happiness and achieve constant approximation. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">166</td>#}
    <td class="tg-031e">Wen Shen, Jacob Crandall, Ke Yan, Cristina Lopes</td>
    <td class="tg-031e">Information Design in Crowdfunding under Thresholding Policies</td>
{#    <td class="tg-031e"> In crowdfunding,&nbsp; an entrepreneur often has to decide how to disclose the campaign status in order to collect as many contributions as possible.&nbsp; We propose information design as a tool to help the entrepreneur to improve revenue by influencing backers' beliefs. We introduce a heuristic algorithm to dynamically compute information-disclosure policies for the entrepreneur, followed by an empirical evaluation to demonstrate its competitiveness over the widely-adopted immediate-disclosure policy. Our results demonstrate that despite its ease of implementation, the immediate-disclosure policy is not optimal when backers follow thresholding policies. With appropriate heuristics, an entrepreneur can benefit from dynamic information disclosure. Our work sheds light on information design in a dynamic setting where agents make decisions using thresholding policies.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 16 (10:30-11:50)<br>Economic Paradigms (C3)</td>
{#    <td class="tg-s6z2">414</td>#}
    <td class="tg-031e">Lei Niu, Fenghui Ren, Minjie Zhang</td>
    <td class="tg-031e">Feasible Negotiation Procedures for Multiple Interdependent Negotiations</td>
{#    <td class="tg-031e"> In an agent society, agents usually have different knowledge and goals and perform differently in order to achieve their individual or joint goals. Agent negotiation provides an effective solution to help agents reach agreements on their future behaviours in the society to guarantee their goals can be achieved successfully. In an agent society, agents may need to conduct Multiple Interdependent Negotiations,  with different opponents and for different purposes, in order to achieve a goal. By considering the complexity of negotiation environments, interdependencies, opponents and issues in the agent society, to efficiently conduct MIN is a challenging research issue. To the best of authors' knowledge, most of the state-of-art work primarily focuses on the single negotiation scenario and tries to propose sophisticated negotiation protocols and strategies to help individual agents to succeed in the single negotiation. However, very little work has been done with consideration of interdependencies and trade-offs among multiple negotiations, so as to help both individual agents as well as the agent society, to increase their welfare. This paper promotes the research on agent negotiations from the single negotiation level to the multiple negotiations level. To effectively conduct MIN in an agent society, this paper proposes three feasible negotiation procedures, which attempt to conduct MIN in a successive way, in a concurrent way, and in a clustered way by considering different negotiation situations, respectively. A simulated agent society is built to test the proposed negotiation procedures with random experimental settings. According to the experimental results, the successive negotiation procedure produces the highest time efficiency, the concurrent negotiation procedure promises the highest profits and success rates, and the clustered negotiation procedure provides a well-balanced solution between the negotiation efficiency and effectiveness.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">504</td>#}
    <td class="tg-031e">Benno Kuckuck, Jorg Rothe</td>
    <td class="tg-031e">Sequential Allocation Rules are Separable: Refuting a Conjecture on Scoring-Based Allocation of Indivisible Goods</td>
{#    <td class="tg-031e"> Baumeister et al. introduced scoring allocation correspondences and rules, parameterized by an aggregation function ⋆  and a scoring vector s. Among the properties they studied is separability, a.k.a. consistency [16], a central property important in many social decision contexts. Baumeister et al. [2] show that some common scoring allocation rules fail to be separable and conjecture that “, no positional scoring allocation rule is separable.” We refute this conjecture by showing that  the family of sequential allocation rules—an elicitation-free protocol for allocating indivisible goods based on picking sequences [10]—is separable for each coherent collection of picking sequences, and  every sequential allocation rule can be expressed as a scoring allocation rule for a suitable choice of scoring vector and social welfare ordering.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">423</td>#}
    <td class="tg-031e">David Klaska, Antonin Kucera, Tomas Lamser, Vojtech Rehak</td>
    <td class="tg-031e">Automatic Synthesis of Efficient Regular Strategies in Adversarial Patrolling Games</td>
{#    <td class="tg-031e"> We give a polynomial-time algorithm for synthesizing efficient regular strategies in patrolling games with general topology. Regular strategies use finite-state automata to gather some information about the history of defender's moves, which results in substantially better protection of the targets. So far, the scope of automatic strategy synthesis was limited to positional strategies  or to regular strategies where the underlying finite-state automata had to supplied manually. In this paper, we show how to synthesize the underlying finite-state automata  algorithmically,  and we also design a novel  gradient-based    strategy improvement method which runs in polynomial time and produces high-quality strategies for patrolling games of realistic size. To evaluate the quality of these strategies, we also develop an algorithm for computing an  upper   bound  on the best achievable protection, and compare the quality of the constructed strategies against this bound.   </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">307</td>#}
    <td class="tg-031e">Fanny Pascual, Krzysztof Rzadca, Piotr Skowron</td>
    <td class="tg-031e">Collective Schedules: Scheduling Meets Computational Social Choice</td>
{#    <td class="tg-031e"> When scheduling public works or events in a shared facility one needs to accomodate preferences of a population.&nbsp; We formalize this problem by introducing the notion of a collective schedule. We show how to extend fundamental tools from the social choice theory---the Kemeny rule and the Condorcet principle---to collective scheduling. We study the computational complexity of finding collective schedules. We also perform simulations demonstrating that optimal collective schedules can be found for instances with realistic sizes. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 17 (10:30-11:50)<br>Game Theory 2 (T5)</td>
{#    <td class="tg-s6z2">503</td>#}
    <td class="tg-031e">Alvaro Perez-Diaz, Enrico Gerding, Frank McGroarty</td>
    <td class="tg-031e">Coordination of Electric Vehicle Aggregators: A Coalitional Approach</td>
{#    <td class="tg-031e">  Given the rapid rise of electric vehicles  worldwide, and the ambitious targets set for the near future, the smart charging of an EV fleet must be seen as a priority. Specifically, we study a scenario where EV charging is managed through self-interested EV aggregators  who compete in the day-ahead market in order to purchase the electricity needed to meet their clients' requirements. In order to reduce electricity costs and lower the impact on electricity markets, we study the possibility of inter-aggregator cooperation. Specifically, we model the system as a coalitional game and prove that the resulting game is superadditive and balanced, hence having a non-empty core. However, due to the game not being convex, the Shapley value is not guaranteed to lie in the core. As an alternative, we propose employing the payment mechanism provided by the least-core, which we show to be in the core in our setting. Furthermore, a realistic empirical evaluation is presented, using real market and driver data from the Iberian Peninsula. The simulations show that large payment reductions can be achieved when using the coordination mechanism. Moreover, we show that the individual payments of the least-core are very close to the Shapley value, suggesting that the payment mechanism is both fair and stable.                 </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">749</td>#}
    <td class="tg-031e">Sai Ganesh, Sameh Mohamed, Georgios Piliouras</td>
    <td class="tg-031e">Three body problems in evolutionary game dynamics: Convergence, Periodicity and Limit Cycles</td>
{#    <td class="tg-031e">  We study the asymptotic behavior of replicator dynamics in settings of network interaction. We&nbsp;focus on three agent graphical games where each edge/game is either a 2x2 zero-sum or a 2x2 coordination/partnership&nbsp;game. Using tools from dynamical systems such as Lyapunov functions and&nbsp;invariant functions we establish that this simple family of games can exhibit an interesting range of behaviors such as global convergence, periodicity for all initial conditions as well as limit cycles.&nbsp;   In contrast, we do not observe more complex behavior such as toroids or chaos whilst it is possible to reproduce them in slightly more complicated settings.    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">756</td>#}
    <td class="tg-031e">Haris Aziz,Serge Gaspers, Edward Lee, Kamran Najeebullah</td>
    <td class="tg-031e">Defender Stackelberg Game with Inverse Geodesic Length as Utility Metric</td>
{#    <td class="tg-031e">  The inverse geodesic length  is a well-known and widely used measure of network performance. It equals the sum of the inverse distances of all pairs of vertices in the network. A Stackelberg game is a strategic game in which one player commits to a strategy while taking into account that other players will respond accordingly. We propose a natural defender-attacker Stackelberg game on a network in which the defender wants to maximize the IGL level of the network and commits to protecting parts of the network while having knowledge of the strength of an attacker that wants to weaken the network. We present several algorithmic and complexity results concerning the problem of finding the optimal commitment for the defender. Some of our computational hardness results also answer open problems posed in prior work on IGL.&nbsp;   </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">176</td>#}
    <td class="tg-031e">Jiarui Gan, Edith Elkind, Michael Wooldridge</td>
    <td class="tg-031e">Stackelberg Security Games with Multiple Uncoordinated Defenders</td>
{#    <td class="tg-031e"> Stackelberg security games have received much attention in recent years. While most existing work focuses on single-defender games, there are many real-world scenarios that involve multiple defenders . It is therefore important to investigate security games with multiple defenders. In this paper, we focus on uncoordinated defenders who jointly protect a set of targets, but may have different valuations for these targets; each defender schedules her own resources and selfishly optimizes her own utility. We generalize the standard  model of Stackelberg security games to this setting and formulate an equilibrium concept that captures the nature of strategic interaction among the players. We argue that an exact equilibrium may fail to exist, and, in fact, deciding whether it exists is NP-hard. However, under mild assumptions, every multi-defender security game admits an $\epsilon$-equilibrium for every $\epsilon&gt;0$, and the respective limit points can be efficiently approximated.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 18 (10:30-11:50)<br>Agent Cooperation 1 (T3)</td>
{#    <td class="tg-s6z2">632</td>#}
    <td class="tg-031e">Mohammad Rostami, Soheil Kolouri, Kyungnam Kim, Eric Eaton</td>
    <td class="tg-031e">Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition</td>
{#    <td class="tg-031e"> Lifelong machine learning methods acquire knowledge over a series of consecutive tasks, continually building upon their experience.&nbsp; Current lifelong learning algorithms rely upon a single learning agent that has centralized access to all data. In this paper, we extend the idea of lifelong learning from a single agent to a network of multiple agents that collectively learn a series of tasks. Each agent faces some  set of tasks; the key idea is that knowledge learned from these tasks may benefit other agents trying to learn different  tasks.&nbsp; Our Collective Lifelong Learning Algorithm  provides an efficient way for a network of agents to share their learned knowledge in a distributed and decentralized manner, while preserving the privacy of the locally observed data. We provide theoretical guarantees for robust performance&nbsp; of the algorithm and empirically demonstrate that CoLLA outperforms existing approaches for distributed multi-task learning on a variety of data sets.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">403</td>#}
    <td class="tg-031e">Shizhao Sun, Wei Chen, Jiang Bian, Xiaoguang Liu, Tie-Yan Liu</td>
    <td class="tg-031e">Slim-DP: A Multi-Agent System for Communication-Efficient Distributed Deep Learning</td>
{#    <td class="tg-031e"> To afford the huge computational cost, large-scale deep neural networks  are usually trained on the distributed system, especially the widely-used parameter server architecture, consisting of a parameter server as well as multiple local workers with powerful GPU cards. During the training, local workers frequently pull the global model and push their computed gradients from/to the parameter server. Due to the limited bandwidth, such frequent communication will cause severe bottleneck for the training acceleration. As recent attempts to address this problem, quantization methods have been proposed to compress the gradients for efficient communication. However, such methods overlook the effects of compression on the model performance such that they either suffer from a low compression ratio or an accuracy drop. In this paper, to better address this problem, we investigate the distributed deep learning as a multi-agent system  problem. Specifically, 1) local workers and the parameter server are separate agents in the system; 2) the objective of these agents is to maximize the efficacy of the learned model through their cooperative interactions; 3) the strategy of the agents describes how they take actions, i.e. communicate their computed gradients or the global model, given the certain state; 4) rational agents always select the best-response strategy with the optimal utility. Inspired by this, we design a MAS approach for distributed training of DNN. In our method, the agents first estimate the utility  of each action,  and then take the best-response strategy based on their estimated utilities mixed with $\epsilon$-random exploration. We call our new method \emph{Slim-DP} as it, being different from the standard data-parallelism, only communicates a subset of the gradient or the global model. Our experimental results demonstrate that our proposed Slim-DP can reduce more communication cost and achieve better speedup without loss of accuracy than the standard data parallelism and its quantization version.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">489</td>#}
    <td class="tg-031e">Thomy Phan, Lenz Belzner, Thomas Gabor, Kyrill Schmid</td>
    <td class="tg-031e">Leveraging Statistical Multi-Agent Online Planning with Emergent Value Function Approximation</td>
{#    <td class="tg-031e"> Making decisions is a great challenge in distributed autonomous environments due to enormous state spaces and uncertainty. Many online planning algorithms rely on statistical sampling to avoid searching the whole state space, while still being able to make acceptable decisions. However, planning often has to be performed under strict computational constraints making online planning in multi-agent systems highly limited, which could lead to poor system performance, especially in stochastic domains.  In this paper, we propose  Emergent Value function Approximation&nbsp;  for Distributed Environment  an approach to integrate global experience into multi-agent online planning in stochastic domains to consider global effects during local planning. For this purpose, a value function is approximated online based on the emergent system behaviour by using methods of reinforcement learning.  We empirically evaluated EVADE with two statistical multi-agent online planning algorithms in a highly complex and stochastic smart factory environment, where multiple agents need to process various items at a shared set of machines. Our experiments show that EVADE can effectively improve the performance of multi-agent online planning, while offering efficiency w.r.t. the breadth and depth of the planning process. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">656</td>#}
    <td class="tg-031e">Joanna Turner, Qinggang Meng, Gerald Schaefer, Andrea Soltoggio</td>
    <td class="tg-031e">Distributed Strategy Adaptation with a Prediction Function in Multi-Agent Task Allocation</td>
{#    <td class="tg-031e"> Coordinating multiple agents to complete a set of tasks under time constraints is a complex problem. Distributed consensus-based task allocation algorithms address this problem without the need for human supervision. With such algorithms, agents add tasks to their own schedule according to specified allocation strategies. Various factors, such as the available resources and number of tasks, may affect the efficiency of a particular allocation strategy. The novel idea we suggest is that each individual agent can predict the best task inclusion strategy locally, based on the limited task assignment information communicated among networked agents. Using supervised classification learning, a function is trained to predict the most appropriate strategy between two well known insertion heuristics. Using the proposed method, agents are shown to correctly predict and select the optimal insertion heuristic to achieve the overall highest number of task allocations. The adaptive agents consistently match the performances of the best non-adaptive agents across a variety of scenarios. This study aims to demonstrate the possibility and potential performance benefits of giving agents greater decision making capabilities to independently adapt the task allocation process in line with the problem of interest. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 19 (10:30-11:50)<br>Scheduling And Planning (C7)</td>
{#    <td class="tg-s6z2">99</td>#}
    <td class="tg-031e">Roman Bartak, Jiri Svancara, Marek Vlk</td>
    <td class="tg-031e">A Scheduling-Based Approach to Multi-Agent Path Finding with Weighted and Capacitated Arcs</td>
{#    <td class="tg-031e"> Multi-agent path finding  deals with the problem of finding a collision-free path for a set of agents. The agents are located at nodes of a directed graph, they can move over the arcs, and each agent has its own destination node. It is not possible for two agents to be at the same node at the same time. The usual setting is that each arc has length one so at any time step, each agent either stays in the node, where it is, or moves to one of its neighboring nodes.     This paper suggests to model the MAPF problem using scheduling techniques, namely, nodes and arcs are seen as resources. The concept of optional activities is used to model which nodes and arcs an agent will visit. We first describe a model, where each agent can visit each node at most once. Then, we extend the model to allow agents re-visiting the nodes.     The major motivation for the scheduling model of MAPF is its capability to naturally include other constraints. We will study particularly the problems, where the capacity of arcs can be greater than one,  and the lengths of arcs can be greater than one . These extensions make the model closer to reality than the original MAPF formulation. We compare the efficiency of models experimentally. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">549</td>#}
    <td class="tg-031e">Wolfgang Hoenig, Scott Kiesel, Andrew Tinka, Joseph Durham, Nora Ayanian</td>
    <td class="tg-031e">Conflict-Based Search with Optimal Task Assignment</td>
{#    <td class="tg-031e"> We consider a variant of the Multi-Agent Path-Finding problem that seeks both task assignments and collision-free paths for a set of agents navigating on a graph, while minimizing the sum of costs of all agents. Our approach extends Conflict-Based Search,  a framework that has been previously used to find collision-free paths for a given fixed task assignment. Our key ideas are to operate on a search forest rather than a search tree and to create the forest on demand, avoiding the factorial explosion of all possible task assignments. We show that our new algorithm, CBS-TA, is complete and optimal. The CBS framework allows us to extend our method to ECBS-TA, a bounded suboptimal version. We provide extensive empirical results comparing CBS-TA to task assignment followed by CBS, Conflict-Based Min-Cost-Flow,  and an integer linear program  solution, demonstrating the advantages of our algorithm. Our results highlight a significant advantage in jointly optimizing the task assignment and path planning for very dense cases compared to the traditional method of solving those two problems independently. For large environments with many robots we show that the traditional approach is reasonable, but that we can achieve similar results with the same runtime but stronger suboptimality guarantees. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">480</td>#}
    <td class="tg-031e">Bruno Escoffier, Evripidis Bampis, Sasa Mladenovic</td>
    <td class="tg-031e">Fair resource allocation over time</td>
{#    <td class="tg-031e"> We consider the over-time version of the Max-Min Fair Allocation problem. In the usual  problem, given a set of resources and a set of agents, we have to allocate the resources to agents in such a way that the utility of the least happiest agent is maximized. In the over-time version there is a time horizon t=1,2,..., T, with at each time t a set of agents and a set of available resources that may change over the time defining instance I_t; we seek a sequence of allocations  that&nbsp;  are near-optimal at each time t, and  are as stable as possible: we want to minimize transition costs induced by modification between allocations at time t and time .   We focus on the impact of the knowledge of the future on the quality and the stability of the returned solutions by distinguishing three settings: the off-line setting where the whole set of instances through the time horizon is known in advance, the online setting where no future instance is known, and the k-lookahead setting where at time t, the instances at times t+1,..., t+k are known. We first consider the case without restrictions where the set of resources and the set of agents are the same for all instances and where every resource can be allocated to any agent. For the off-line setting, we show that the over-time version of the problem is much harder than the static one, since it becomes NP-hard even for families of instances for which the static problem is trivial. Then, we provide a r/-approximation algorithm for the off-line setting using as&nbsp; subroutine an r-approximation algorithm for the static version. We also give a r/-competitive algorithm for the online setting using also as subroutine an r-approximation algorithm for the static version.   Furthermore, for the case with restrictions, we show that in the off-line setting it is possible to get a polynomial-time algorithm with the same approximation ratio as in the case without restrictions, while for the online setting, we prove that it is not possible to find an online algorithm with bounded competitive ratio. For the 1-lookahead setting however, we give a r/-approximation algorithm using as subroutine an r-approximation algorithm for the static version.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS4</td>#}
    <td class="tg-031e">Vivek Nallur and Siobhan Clarke</td>
    <td class="tg-031e">Clonal Plasticity: An Autonomic Mechanism for Multi-Agent Systems to Self-Diversify</td>
    <td class="tg-031e"></td>
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 20 (10:30-11:50)<br>Agent-Based Simulation 1 (C8)</td>
{#    <td class="tg-s6z2">262</td>#}
    <td class="tg-031e">Emilio Cruciani, Emanuele Natale, Andre Nusser, Giacomo Scornavacca</td>
    <td class="tg-031e">Phase Transition of the 2-Choices Dynamics on Core-Periphery Networks</td>
{#    <td class="tg-031e"> Consider the following process on a network: Each agent initially holds either opinion  blue &nbsp;or  red ; then, in each round, each agent looks at two random neighbors and, if the two have the same opinion, the agent adopts it. This process is known as the  2-Choices &nbsp;dynamics and is arguably the most basic non-trivial  opinion dynamics &nbsp;modeling voting behavior on social networks. Despite its apparent simplicity, 2-Choices has been analytically characterized only on networks with a strong expansion property - under assumptions on the initial configuration that establish it as a fast  majority consensus  protocol.&nbsp;  In this work, we aim at contributing to the understanding of the 2-Choices dynamics by considering its behavior on a class of networks with Core-Periphery structure, a well-known topological assumption in social networks. In a nutshell, assume that a densely-connected subset of agents, the  core,  holds a different opinion from the rest of the network, the  periphery . Then, depending on the strength of the cut between the core and the periphery, a phase-transition phenomenon occurs: Either the core's opinion rapidly spreads among the rest of the network, or a  metastability &nbsp;phase takes place, in which both opinions coexist in the network for superpolynomial time. The interest of our result is twofold. On the one hand, by looking at the 2-Choices dynamics as a simplistic model of competition among opinions in social networks, our theorem sheds light on the  influence &nbsp;of the core on the rest of the network, as a function of the core's connectivity towards the latter. On the other hand, to the best of our knowledge, we provide the first analytical result which shows a heterogeneous behavior of a simple dynamics as a function of structural parameters of the network. Finally, we validate our theoretical predictions with extensive experiments on real networks. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">334</td>#}
    <td class="tg-031e">Flavio Pinheiro, Fernando Santos</td>
    <td class="tg-031e">Local Wealth Redistribution Promotes Cooperation in Multiagent Systems</td>
{#    <td class="tg-031e"> Designing mechanisms that promote cooperation in Multiagent Systems has been a long-lasting goal in artificial intelligence. The task is especially challenging when agents are selfish, lack common goals and face social dilemmas, i.e., situations in which individual interest conflicts with social welfare. Past works explored mechanisms that explain cooperation in biological and social systems, providing important clues for the aim of designing cooperative artificial societies. In particular, several works show that cooperation is able to emerge when specific network structures underlie agents' interactions. Notwithstanding, social dilemmas in which defection is highly tempting still lack mechanisms that allow cooperation to be effectively sustained. Here we propose a new redistribution mechanism that can be applied in structured populations of agents. Importantly, we show that, when implemented locally,  redistribution excels in promoting cooperation under regimes where, before, only defection prevailed. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">443</td>#}
    <td class="tg-031e">Yixi Wang, Jianye Hao, Ho-fung Leung, Jianguo Wei, Wenhuan Lu</td>
    <td class="tg-031e">Efficient Convention Emergence through Decoupled Reinforcement Social Learning with Teacher-Student Mechanism</td>
{#    <td class="tg-031e"> In this paper, we design reinforcement learning based  strategies to promote convention emergence in multiagent systems  with large convention space. We apply our approaches to a language coordination problem in which agents need to coordinate on a dominant lexicon for efficient communication. By modeling each lexicon which maps each concept to a single word as a Markov strategy representation, the original single-state convention learning problem can be transformed into a muti-state multiagent coordination problem. The dynamics of lexicon evolutions during an interaction episode can be modeled as a Markov game, which allows agents to improve the action values of each concept separately and incrementally. Specifically we propose two learning strategies, multiple-Q and multiple-R, and also propose incorporating teacher-student mechanism on top of the learning strategies to accelerate lexicon convergence speed. Extensive experiments verify that our approaches outperform the state-of-the-art approaches in terms of convergence efficiency and convention quality.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">398</td>#}
    <td class="tg-031e">Raquel Roses, Cristina Kadar, Charlotte Gerritsen, Chris Ovi Rouly</td>
    <td class="tg-031e">Agent-Based Simulation of Offender Mobility: Integrating Activity Nodes from Location-Based Social Networks</td>
{#    <td class="tg-031e">In recent#}
{#    years, simulation techniques have been applied to investigate the#}
{#    spatio-temporal dynamics of crime. Researchers have instantiated mobile offenders#}
{#    in agent-based simulations for theory testing, experimenting with prevention#}
{#    strategies, and crime prediction purposes, despite facing challenges due to the#}
{#    complex dynamics of crime and the lack of detailed information about offender#}
{#    mobility. This paper presents an agent-based model to explore offender#}
{#    mobility, focusing on the interplay between the agent’s awareness space and#}
{#    activity nodes. To instantiate a realistic urban environment, we use open and location-based#}
{#    social networks data to design the road network, and as proxy for human#}
{#    activity we use activity nodes, respectively. 18 mobility strategies have been#}
{#    tested, combining search distance strategies  and target selection strategies#}
{#    . We analyze and compare the different mobility#}
{#    strategies, and show the impact of using activity nodes extracted from social#}
{#    networks to simulate offender mobility. This agent-based model provides a basis#}
{#    for comparing offender mobility in crime simulations by inferring offender#}
{#    mobility in urban areas from real world data.#}
{##}
{#     </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 21 (10:30-11:50)<br>Engineering Multiagent Systems 1 (T4)</td>
{#    <td class="tg-s6z2">543</td>#}
    <td class="tg-031e">Andrei Ciortea, Simon Mayer, Florian Michahelles</td>
    <td class="tg-031e">Repurposing Manufacturing Lines on the Fly with Multi-agent Systems for the Web of Things</td>
{#    <td class="tg-031e"> Multi-agent systems  have long been envisioned as a key enabling technology in manufacturing, but this promise is yet to be realized: the lack of proper models, architectures, tooling, and the high level of expertise required for designing and programming agent-based manufacturing systems hindered their large-scale acceptance. The emerging Web of Things now being standardized at W3C and IETF provides new research opportunities that can help MAS enter the mainstream and achieve their long-promised impact. In this paper, we integrate these new developments with MAS and automated planning in order to design scalable and flexible agent-based manufacturing systems that can be re-purposed on-the-fly: our agents synthesize production plans using semantic descriptions of Web-based artifacts and coordinate with one another via semantic organizations. The deployed systems use the Web as an application architecture,  which facilitates the seamless integration of geographically distributed production cells. Engineers can program and re-purpose the systems using an intuitive interface that runs in any standard Web browser and on any device. To demonstrate our approach, we implemented a prototypical production cell that integrates two industry-grade robots and an augmented reality interface for human workers. Together, these contributions demonstrate a means to achieve an intriguing vision for the forthcoming fourth industrial revolution: a global collective intelligence for manufacturing. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">689</td>#}
    <td class="tg-031e">Shahrzad Gholami, Milind Tambe, Sara Mc Carthy, Bistra Dilkina, Andrew Plumptre, Margaret Driciru, Fred Wanyama, Aggrey Rwetsiba, Mustapha Nsubaga, Joshua Mabonga, Eric Enyel, Tom Okello </td>
    <td class="tg-031e">Adversary models account for imperfect crime data: Forecasting and planning against real-world poachers</td>
{#    <td class="tg-031e"> Poachers are engaged in extinction#}
{#    level wholesale slaughter, so it is critical to harness historical data for#}
{#    predicting poachers' behavior. However, in these domains, data collected about#}
{#    adversarial actions are remarkably imperfect, where reported negative instances#}
{#    of crime may be mislabeled or uncertain. Unfortunately, past attempts to#}
{#    develop predictive and prescriptive models to address this problem suffer from#}
{#    shortcomings from a modeling perspective as well as in the implementability of#}
{#    their techniques. Most notably these models i) neglect the uncertainty in crime#}
{#    data, leading to inaccurate and biased predictions of adversary behavior, ii)#}
{#    use coarse-grained crime analysis and iii) do not provide a convincing#}
{#    evaluation as they only look at a single protected area. Additionally, they iv)#}
{#    proposed time-consuming techniques which cannot be directly integrated into low#}
{#    resource outposts. In this innovative application paper, we  introduce#}
{#    iWare-E a novel imperfect-observation aWare Ensemble  technique, which#}
{#    is designed to handle the uncertainty in crime information efficiently. This#}
{#    approach leads to superior accuracy for adversary behavior prediction  compared to the previous state-of-the-art. We also demonstrate#}
{#    the country-wide efficiency of the models and are the first to  evaluate#}
{#    our adversary behavioral model across different protected areas in Uganda,#}
{#    i.e., Murchison Fall and Queen Elizabeth National,  as#}
{#    well as  on fine-grained temporal resolutions. Lastly,  we provide a#}
{#    scalable planning algorithm to design fine-grained patrol routes for the rangers,#}
{#    which achieves up to 150% improvement in number of predicted attacks detected.#}
{#    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">471</td>#}
    <td class="tg-031e">Jan Mrkos, Antonin Komenda, Michal Jakob</td>
    <td class="tg-031e">Revenue Maximization for Electric Vehicle Charging Service Providers using Sequential Dynamic Pricing</td>
{#    <td class="tg-031e">With the rising penetration of electric vehicles,  the provision of EV charging is becoming a standard commercial service. With this shift, EV charging service providers are looking for ways to make their business more profitable. Dynamic pricing is a proven technique to increase revenue in markets with time-variant, heterogeneous demand. In this paper, we propose a Markov Decision Process -based approach to revenue-maximizing dynamic pricing for charging service providers. We implement the approach using an ensemble of policy iteration MDP solvers and evaluate it using a simulation based on real-world data. We show that our proposed method achieves significantly higher revenue than methods utilizing flat-based pricing. In addition to achieving higher revenue for charging service providers, the method also increases the efficiency of allocation measured in terms of the total utilization of the charging station.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">184</td>#}
    <td class="tg-031e">Bryan Wilder,Han Ching Ou, Kayla de la Haye, Milind Tambe</td>
    <td class="tg-031e">Optimizing network structure for preventative health</td>
{#    <td class="tg-031e"> Diseases such as heart disease, stroke, or diabetes affect hundreds of millions of people. Such conditions are strongly impacted by obesity, and establishing healthy lifestyle behaviors is a critical public health challenge with many applications. Changing health behaviors is inherently a multiagent problem since people's behavior is strongly influenced by those around them. Hence, practitioners often attempt to modify the social network of a community by adding or removing edges in ways that will lead to desirable behavior change. To our knowledge, no previous work considers the algorithmic problem of finding the optimal set of edges to add and remove. We propose the RECONNECT algorithm, which efficiently finds high-quality solutions for a range of different network intervention problems. We evaluate RECONNECT in a highly realistic simulated environment based on the Antelope Valley region in California which draws on demographic, social, and health-related data. We find the RECONNECT outperforms an array of baseline policies, in some cases yielding a 150% improvement over the best alternative.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="4" nowrap>Session 22 (10:30-11:50)<br>Robotics: Human-Robot Interaction (T1 & T2)</td>
{#    <td class="tg-s6z2">R70</td>#}
    <td class="tg-031e">Mihai Pomarlan, John Bateman</td>
    <td class="tg-031e">Robot Program Construction via Grounded Natural Language Semantics & Simulation</td>
{#    <td class="tg-031e"> Robots acting in semi-structured, human environments need to understand the effects of their actions and the instructions given by a human user. Simulation has been considered a promising reasoning technique to help tackle both problems. In this paper, we present a system that constructs an executable robot program from a linguistic semantic specification resulting from parsing a natural language sentence; in effect, our system grounds the semantic specification into the produced robot plan. The plan can then be run in a simulated environment, which allows one to infer more about the plan than was present in the initial semantic specification. Our system allows modeling how actions can be modified by subclauses, which we showcase by a transport action. Simulation runs allow discovery of better parameters, either locally for a subtask or such that the entire task is better performed; simulation reveals these parameterizations may differ.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R73</td>#}
    <td class="tg-031e">Andrea Vanzo, Jose Luis Part, Yanchao Yu, Daniele Nardi, Oliver Lemon</td>
    <td class="tg-031e">Incrementally Learning Semantic Attributes through Dialogue Interaction</td>
{#    <td class="tg-031e"> Enabling a robot to properly interact with users plays a key role in the effective deployment of robotic platforms in domestic environments. Robots must be able to rely on interaction to improve their behaviour and adaptively understand their operational world. Semantic mapping is the task of building a representation of the environment, that can be enhanced through interaction with the user. In this task, a proper and effective acquisition of semantic attributes of targeted entities is essential for the task accomplishment itself. In this paper, we focus on the problem of learning dialogue policies to support semantic attributes acquisition, that optimise the effort required by humans in providing knowledge to the robot through dialogue. To this end, we design our Dialogue Manager as a hierarchical Markov Decision Process, solving the optimisation problem through Reinforcement Learning. The Dialogue Manager depends on an on-line incremental visual classifier, based on a Load-Balancing Self-Organizing Incremental Neural Network . Experiments in a simulated scenario show the effectiveness of the proposed solution, suggesting that perceptual information can be properly exploited to reduce human tutoring cost.Moreover, a policy trained on a small amount of data generalises well to larger datasets, and so the proposed on-line scheme, as well as the real-time nature of the processing, are suited for an extensive deployment in real scenarios. To this end, the whole system has been tested on a real robot. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R76</td>#}
    <td class="tg-031e">Dogancan Kebude, Cem Eteke, Tevfik Metin Sezgin, Baris Akgun</td>
    <td class="tg-031e">Communicative Cues for Reach-to-Grasp Motions: From Humans to Robots</td>
{#    <td class="tg-031e">Intent communication is an important challenge in the context of human-robot interaction. The aim of this work is to identify subtle non-verbal cues that make communication among humans fluent and using them to generate intent expressive robot motion. A human-human reach-to-grasp experiment  identified two temporal and two spatial cues:  relative time to reach maximum hand aperture,   overall motion duration,   exaggeration in motion,  and  change in grasp modality . Results showed there was statistically significant difference in the temporal cues between no-intention and intention conditions. A follow-up experiment  was conducted based on these results. Reach-to-grasp motions of a simulated robot containing different cue combinations were shown to the participants. They were asked to guess the target object during robot's motion, based on the assumption that intent expressive motion would result in earlier and more accurate guesses. Results showed that, OT, GM and several cue combinations led to faster and more accurate guesses which imply they can be used to generate communicative motion. However, MA had no effect, and surprisingly Exg had a negative effect on expressiveness.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">R103</td>#}
    <td class="tg-031e">Michiel de Jong, Kevin Zhang, Aaron Roth, Travers Rhodes, Robin Schmucker, Chenghui Zhou, Sofia Ferreira, Joao Cartucho, Manuela Veloso</td>
    <td class="tg-031e">Towards a Robust Interactive and Learning Social Robot</td>
{#    <td class="tg-031e">Pepper is a humanoid robot, specifically designed for social interaction, that has been deployed in a variety of public environments. A programmable version of Pepper is also available, enabling our focused research on perception and behavior robustness and capabilities of an interactive social robot. We address Pepper perception by integrating state-of-the-art vision and speech recognition systems and experimentally analyzing their effectiveness. As we recognize limitations of the individual perceptual modalities, we introduce a multi-modality approach to increase the robustness of human social interaction with the robot. We combine vision, gesture, speech, and input from an onboard tablet, a remote mobile phone, and external microphones. Our approach includes the proactive seeking of input from a different modality, adding robustness to the failures of the separate components. We also introduce a learning algorithm to improve communication capabilities over time, updating speech recognition through social interactions. Finally, we realize the rich robot body-sensory data and introduce both a nearest-neighbor and a deep learning approach to enable Pepper to classify and speak up a variety of its own body motions. We view the contributions of our work to be relevant both to Pepper specifically and to other general social robots.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 23 (13:30-15:30)<br>Applications Of Game Theory (C3)</td>
{#    <td class="tg-s6z2">648</td>#}
    <td class="tg-031e">Aaron Schlenker, Milind Tambe, Long Tran-Thanh, Phebe Vayanos, Yevgeniy Vorobeychik, Omkar Thakoor, Haifeng Xu, Fei Fang </td>
    <td class="tg-031e">Deceiving Cyber Adversaries: A Game Theoretic Approach</td>
{#    <td class="tg-031e"> An important way cyber adversaries find vulnerabilities in modern networks is through reconnaissance, in which they attempt to identify configuration specifics of network hosts. To increase uncertainty of adversarial reconnaissance, the network administrator  can introduce deception into responses to network scans, such as obscuring certain system characteristics.  We introduce a novel game theoretic model of deceptive interactions of this kind between a defender and a cyber attacker, which we call the Cyber Deception Game. We consider both a powerful  attacker, who is knows the defender's exact deception strategy, and a naive attacker who is not. We show that the problem is NP-hard for both types of attackers. For the case with a powerful attacker, we provide a mixed-integer linear program solution, sped up with a novel cut generation method, as well as a fast and effective greedy algorithm. Similarly, we provide complexity results and propose exact and heuristic approaches when the attacker is naive. Our extensive experimental analysis demonstrates the effectiveness of our approaches. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">342</td>#}
    <td class="tg-031e">Atiyeh Ashari Ghomi, Allan Borodin, Omer Lev</td>
    <td class="tg-031e">Seasonal Goods and Spoiled Milk: Pricing for a Limited Shelf-Life</td>
{#    <td class="tg-031e"> We examine the case of items with a limited shelf-life where storing an item  may carry a cost to a buyer . For example, eggs, milk, or Groupon coupons have a fixed expiry date, and seasonal goods can suffer a decrease in value. We show how this setting contrasts with recent results by Berbeglia et al. for items with infinite shelf-life.  We prove tight bounds on the seller's profits showing how they relate to the items' shelf-life. We show, counterintuitively, that in our limited shelf-life setting, increasing storage costs can sometimes lead to less profit for the seller which cannot happen when items have unlimited shelf-life. We also provide an algorithm that calculates optimal prices.  Finally, we examine empirically the relationship between profits and buyer utility as the storage cost and shelf-life duration change, and observe properties, some of which are unique to the limited shelf-life setting. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">151</td>#}
    <td class="tg-031e">Mohammad Irfan, Tucker Gordon</td>
    <td class="tg-031e">The Power of Context in Networks: Ideal Point Models with Social Interactions</td>
{#    <td class="tg-031e"> Game theory has been widely used for modeling strategic behaviors in networked multiagent systems. However, the context within which these strategic behaviors take place has not received much attention. We present a model of strategic behavior in networks that incorporates the behavioral context. We focus on the contextual aspects of Senate voting. A senator's decision to vote  yea &nbsp;or  nay &nbsp;on a bill comes as a result of their ideologies, agendas, and their interactions with other senators. One salient model in political science is the  ideal point model,  which assigns each senator and each bill a number on the real line of political spectrum. These points then allow for prediction of future voting behavior. We extend the classical ideal point model with network-structured interactions among senators. In contrast to the ideal point model's prediction of individual voting behavior, we predict  joint voting behaviors &nbsp;in a game-theoretic fashion. Our model also includes the characteristics of a bill. This allows it to outperform previous models that solely focus on the networked interactions among senators with no bill-specific parameters. We focus on two fundamental questions: learning the model using real-world data and computing  stable outcomes &nbsp;of the model in order to predict joint voting behaviors. We demonstrate the effectiveness of our model through experiments using data from the 114th U.S. Congress. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">339</td>#}
    <td class="tg-031e">Kai Wang, Qingyu Guo, Phebe Vayanos, Milind Tambe, Bo An</td>
    <td class="tg-031e">Equilibrium Refinement in Security Games with Arbitrary Scheduling Constraints</td>
{#    <td class="tg-031e"> Significant research effort in security games has focused in devising strategies that perform well even when the attacker deviates from optimal  behavior. In most of these frameworks, a price needs to be paid to ensure robustness against this unpredictability. However, equilibrium refinement is an attractive alternative to boost solution robustness at no cost even though it has not received as much attention in security game literature. In this framework, resources are strategically allocated to secure an optimal outcome against a rational adversary while simultaneously protecting other targets to ensure good outcomes against boundedly rational or constrained attackers. Unfortunately, existing approaches for equilibrium refinement in security games cannot effectively address scheduling constraints that arise frequently in real-world applications. In this paper, we aim to fill this gap and make several key contributions. First, we show that existing approaches for equilibrium refinement can fail in the presence of scheduling constraints. Second, we investigate the properties of the best response of the attacker. Third, we leverage these properties to devise novel iterative algorithms to compute the optimally refined equilibrium, with polynomially many calls to an LP oracle for zero-sum games. Finally, we conduct extensive experimental evaluations that showcase i) the superior performance of our approach in the face of a boundedly rational attacker and ii) the attractive scalability properties of our algorithm that can solve realistic-sized instances. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">716</td>#}
    <td class="tg-031e">Weiran Shen, Pingzhong Tang, Yuan Deng</td>
    <td class="tg-031e">Coalitional Permutation Manipulations in the Gale-Shapley Algorithm</td>
{#    <td class="tg-031e"> In this paper, we consider permutation manipulations by any subset of women, which is motivated by the college admissions process in China. Our result also answer the open problem on what can be achieved by permutation manipulations. We present an efficient algorithm to find a strategy profile such that the induced matching is stable and Pareto-optimal while the strategy profile itself is inconspicuous. Surprisingly, we show that such a strategy profile actually forms a Nash equilibrium of the manipulation game.#}
{#        In the end, we show that it is NP-complete to find a manipulation that is strictly better for all members of the coalition. This result demonstrates a sharp contrast between weakly better off outcomes and strictly better off outcomes.#}
{#     </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">269</td>#}
    <td class="tg-031e">Gianpiero Monaco, Luca Moscardelli, Yllka Velaj</td>
    <td class="tg-031e">Stable Outcomes in Modified Fractional Hedonic Games</td>
{#    <td class="tg-031e"> In  coalition formation games  self-organized coalitions are created as a result of the strategic interactions of independent agents. For each couple of agents,  weight w i,j  = w j,i  reflects how much agents i and j benefit from belonging to the same coalition. We consider the modified fractional hedonic game, that is a coalition formation game in which agents’ utilities are such that the total benefit of agent i belonging to a coalition  is averaged over all the other members of that coalition, i.e., excluding herself. Modified fractional hedonic games constitute a class of succinctly representable hedonic games.   We are interested in the scenario in which agents, individually or jointly, choose to form a new coalition or to join an existing one, until a stable outcome is reached. To this aim, we consider common stability notions, leading to strong Nash stable outcomes, Nash stable outcomes or core stable outcomes: we study their existence, complexity and performance, both in the case of general weights and in the case of 0-1 weights. In particular, we completely characterize the existence of the considered stable outcomes and show many tight or asymptotically tight results on the performance of these natural stable outcomes for modified fractional hedonic games, also highlighting the differences with respect to the model of fractional hedonic games, in which the total benefit of an agent in a coalition is averaged over all members of that coalition, i.e., including herself. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="5" nowrap>Session 24 (13:30-15:30)<br>Social Choice Theory 2 (C2)</td>
{#    <td class="tg-s6z2">612</td>#}
    <td class="tg-031e">Ulle Endriss </td>
    <td class="tg-031e">Judgment Aggregation with Rationality and Feasibility Constraints</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">322</td>#}
    <td class="tg-031e">Andrea Loreggia, Nicholas Mattei, Francesca Rossi, K. Brent Venable</td>
    <td class="tg-031e">On the Distance Between CP-nets</td>
{#    <td class="tg-031e"> Preferences play a key role in decision making, whether such decision are made by a single individual or a group. In a multi-agent context, it is also important to know how to aggregate preferences to reach a collective decision. Moreover, being able to measure the distance between the preference of two individuals is important to identify the amount of disagreement and possibly reach consensus. In this paper we define a notion of distance between CP-nets, a formalism that can compactly encode conditional qualitative preferences. We consider the Kendall-tau distance between the partial orders induced by CP-nets, and we define two tractable approximations of that distance, which can be computed in time polynomial in the number of features of the CP-nets. We then perform experiments to demonstrate the quality of these approximations compared to the Kendall-tau distance. We also relate our two notions of distance to the distance rationalizability of sequential plurality voting for CP-nets. </td>#}
    </tr>
{#    <tr>#}
{# <td class="tg-s6z2">110</td>#}
{#    <td class="tg-031e">Haris Aziz</td>#}
{#    <td class="tg-031e">Generalizing Top Trading Cycles for Housing Markets with Fractional Endowments</td>#}
{#    <td class="tg-031e"> The housing market setting constitutes a fundamental model of exchange economies of goods. Most of the work concerning housing markets does not cater for randomized assignments or allocation of time-shares. Recently, house allocation with fractional endowment of houses was considered by Athanassoglou and Sethuraman  who posed the open problem of generalizing Gale's Top Trading Cycles  algorithm for fractional endowments. In this paper, we present a generalization of TTC called FTTC that is polynomial-time as well as core stable and Pareto optimal with respect to stochastic dominance. For the standard setting in which each agent owns one discrete house, FTTC coincides with a state of the art strategyproof mechanism for housing markets with discrete endowments and weak preferences. We show that FTTC satisfies a maximal set of desirable properties by proving two impossibility theorems. One of the theorems implies several impossibility results in the literature.&nbsp;  </td>#}
{#    </tr>#}
    <tr>
{#    <td class="tg-s6z2">109</td>#}
    <td class="tg-031e">Haris Aziz, Jiayin Chen, Serge Gaspers, Zhaohong Sun</td>
    <td class="tg-031e">Stability and Pareto Optimality in Refugee Allocation Matchings</td>
{#    <td class="tg-031e"> We focus on the refugee matching problem---a general ``two-sided matching under preferences'' model with multi-dimensional feasibility constraints that was formalized by Delacretaz, Kominers, and Teytelboym . We propose a taxonomy of stability concepts for the problem; identify relations between them; and show that even for two natural weakenings of the standard stability concept, &nbsp;non-existence and NP-hardness results persist. We then identify several natural weaker stability concepts for which we present a polynomial-time and strategy-proof algorithm that returns a stable matching. We also examine the complexity of computing and {testing} Pareto optimal matchings.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">198</td>#}
    <td class="tg-031e">Nawal Benabbou, Mithun Chakraborty, Xuan-Vinh Ho, Jakub Sliwinski, Yair Zick</td>
    <td class="tg-031e">Diversity Constraints in Public Housing Allocation</td>
{#    <td class="tg-031e"> The state of Singapore operates a national public housing program, accounting for over $80\%$ of its residential real estate. Singapore uses its housing allocation program to ensure ethnic diversity in its neighborhoods; it does so by imposing ethnic quotas: every ethnic group must not own more than a certain percentage in a housing project, thus ensuring that every neighborhood contains members from each ethnic group. However, imposing diversity constraints naturally results in some welfare loss. Our work studies the tradeoff between diversity and social welfare from the perspective of computational economics. We model the problem as a an extension of the classic assignment problem, with additional diversity constraints. While the classic assignment program is poly-time computable, we show that adding diversity constraints makes the problem computationally intractable; however, we identify a $\tfrac{1}{2}$-approximation algorithm, as well as reasonable agent utility models which admit poly-time algorithms. In addition, we study the {\em price of diversity}: this is the loss in welfare incurred by imposing diversity constraints; we provide upper bounds on the price of diversity as a function of natural problem parameters; next, we analyze public data from Singapore's Housing Development Board, and create a simulated framework testing the welfare loss due to diversity constraints in realistic large-scale scenarios. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">293</td>#}
    <td class="tg-031e">Marco Faella, Luigi Sauro</td>
    <td class="tg-031e">Do all tournaments admit irrelevant matches?</td>
{#    <td class="tg-031e"> We consider tournaments played by a set of agents in order to establish a ranking among them. We introduce the notion of irrelevant match, as a match that does not influence the ultimate ranking of the involved parties. After discussing the basic properties of this notion, we seek out tournaments that have no irrelevant matches, focusing on the class of tournaments where each agent challenges each other exactly once. We prove that tournaments with a static schedule and at least 5 agents always include  irrelevant matches. Conversely, dynamic schedules can be devised in ways that avoid irrelevant matches, at least for one of the involved agents.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 25 (13:30-15:30)<br>Learning And Adaptation 3 (C7)</td>
{#    <td class="tg-s6z2">727</td>#}
    <td class="tg-031e">Elad Liebman, Eric Zavesky, Peter Stone</td>
    <td class="tg-031e">A Stitch in Time - Autonomous Model Management via Reinforcement Learning</td>
{#    <td class="tg-031e"> Concept drift - a change, either sudden or gradual, in the underlying  properties of data - is one of the most prevalent challenges to  maintaining high-performing learned models over time in autonomous  systems.  In the face of concept drift, one can hope that the old model  is sufficiently representative of the new data despite the concept  drift, one can discard the old data and retrain a new model with  new data, or one can use transfer learning methods to combine  the old data with the new to create an updated model.  Which of  these three options is chosen affects not only near-term decisions, but  also future needs to transfer or retrain.  In this paper, we thus model  response to concept drift as a sequential decision making problem and  formally frame it as a Markov Decision Process.  Our reinforcement  learning approach to the problem shows promising results on one  synthetic and two real-world datasets.session`</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">559</td>#}
    <td class="tg-031e">Merwan Barlier, Olivier Pietquin, Romain Laroche</td>
    <td class="tg-031e">Training Dialogue Systems With Human Advice</td>
{#    <td class="tg-031e"> One major drawback of Reinforcement Learning  Spoken Dialogue Systems is that they inherit from the general exploration requirements of RL which makes them hard to deploy from an industry perspective. On the other hand, industrial systems rely on human expertise and hand written rules so as to avoid irrelevant behavior to happen and maintain acceptable experience from the user point of view.&nbsp;&nbsp;  In this paper, we attempt to bridge the gap between those two worlds by providing an easy way to incorporate all kinds of human expertise in the training phase of a Reinforcement Learning Dialogue System. Our approach, based on the TAMER framework, enables safe and efficient policy learning by combining the traditional Reinforcement Learning reward signal with an additional reward, encoding expert advices.  Experimental results show that our method leads to substantial improvements over more traditional Reinforcement Learning methods. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">582</td>#}
    <td class="tg-031e">Ayush Jain, Doina Precup</td>
    <td class="tg-031e">Eligibility Traces for Options</td>
{#    <td class="tg-031e"> Temporally extended actions not only represent knowledge in the hierarchical setup in reinforcement learning, they also improve exploration while reducing the complexity of choosing actions. The option framework provides a concrete way to implement and reason about temporal abstraction. This work attempts to test the utility of eligibility traces with options and find good ways of doing multi-step intra-option updates. Three algorithms, based on off-policy methods - importance sampling, tree backup and retrace, are proposed for using eligibility traces with options.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">677</td>#}
    <td class="tg-031e">Ramya Ramakrishnan, Ece Kamar, Debadeepta Dey, Julie Shah, Eric Horvitz</td>
    <td class="tg-031e">Discovering Blind Spots in Reinforcement Learning</td>
{#    <td class="tg-031e"> Agents trained in simulation often make errors in the real world, due to mismatches between training and testing environments. These mistakes can be dangerous and difficult to discover because the agent cannot a priori predict them. In this work, we propose using oracle feedback to learn a predictive model of these blind spots to reduce costly errors in real world execution. We focus on blind spots in reinforcement learning that occur due to incomplete state representation: The agent does not have the appropriate features to represent the true state of the world and thus cannot distinguish many states from each other. We formalize the problem of discovering blind spots in RL as a noisy supervised learning problem with class imbalance. Our learning methodology combines techniques for label aggregation, calibration, and supervised learning to reason explicitly about various forms of noise emerging from different forms of oracle feedback, including oracle demonstrations and corrections, to predict blind spots in unseen regions of the state space. We evaluate our approach on two domains and show that its predictive performance achieves higher performance than baseline approaches, and that the learned model can be used to selectively query the oracle at execution time to prevent errors. We also empirically analyze the biases of various forms of oracle feedback, including demonstrations and corrections, and how they impact the discovery of blind spots.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">32</td>#}
    <td class="tg-031e">Felipe Leno Da Silva, Anna Helena Reali Costa</td>
    <td class="tg-031e">Object-Oriented Curriculum Generation for Reinforcement Learning</td>
{#    <td class="tg-031e">#}
{#     Autonomously learning a complex task takes a very long time for Reinforcement Learning  agents.&nbsp; One way to learn faster is by dividing a complex task into several simple subtasks and organizing them in a Curriculum that guides Transfer Learning  methods to reuse knowledge in a convenient &nbsp;sequence.&nbsp;  &nbsp;However, previous works do not take into account the TL method to build specialized Curricula, leaving the burden of a careful subtask selection to a human.&nbsp;  We here rely on Object-Oriented task descriptions to guide both the Curriculum generation and knowledge reuse procedures, autonomously building object-based Curricula.&nbsp;  We also propose a novel procedure for autonomously dividing the target task into simpler ones under minimal human supervision.&nbsp;  Our experiments show that our proposal achieves a better performance using both manually given and autonomously generated subtasks when compared to the state-of-the-art technique in two different domains.#}
{#     </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">277</td>#}
    <td class="tg-031e">Zhuoshu Li, Zhitang Chen, Pascal Poupart, Sanmay Das, Yanhui Geng</td>
    <td class="tg-031e">Faster Policy Adaptation in Environments with Exogeneity: A State Augmentation Approach</td>
{#    <td class="tg-031e"> The reinforcement learning literature typically assumes fixed state transition functions for the sake of tractability. However, in many real-world tasks, the state transition function changes over time, and this change may be governed by exogenous variables outside of the control loop. This can make policy learning difficult. In this paper, we propose a new algorithm to address the aforementioned challenge by embedding the state transition functions at different timestamps into a Reproducing Kernel Hilbert Space; the exogenous variable, as the cause of the state transition evolution, is estimated by projecting the embeddings into the subspace that preserves maximum variance. By augmenting the observable state vector with the estimated exogenous variable, standard RL algorithms such as Q-learning are able to learn faster and better. Experiments with both synthetic and real data demonstrate the superiority of our proposed algorithm over standard and advanced variants of Q-learning algorithms in dynamic environments.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 26 (13:30-15:30)<br>Agent-Based Simulation 2 (C8)</td>
{#    <td class="tg-s6z2">248</td>#}
    <td class="tg-031e">Yuexin Ma, Dinesh Manocha, Wenping Wang</td>
    <td class="tg-031e">Efficient Reciprocal Collision Avoidance between Heterogeneous Agents Using CTMAT</td>
{#    <td class="tg-031e"> We present a novel algorithm for reciprocal collision avoidance between heterogeneous agents of different shapes and sizes. We present a novel CTMAT representation based on medial axis transform to compute a tight fitting bounding shape for each agent. Each CTMAT is represented using tuples, which are composed of circular arcs and line segments. Based on the reciprocal velocity obstacle formulation, we reduce the problem to solving a low-dimensional linear programming between each pair of tuples belonging to adjacent agents. We precompute the Minkowski Sums of tuples to accelerate the runtime performance. Finally, we provide an efficient method to update the orientation of each agent in a local manner. We have implemented the algorithm and highlight its performance on benchmarks corresponding to road traffic scenarios and different vehicles. The overall runtime performance is comparable to prior multi-agent collision avoidance algorithms that use circular or elliptical agents. Our approach is less conservative and results in fewer false collisions.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">36</td>#}
    <td class="tg-031e">Weihua Li, Quan Bai, Minjie Zhang, Tung Doan Nguyen</td>
    <td class="tg-031e">Modelling Multiple Influences Diffusion in On-line Social Networks</td>
{#    <td class="tg-031e"> In on-line social networks, innovations in the presence of one or more influences disseminate through the topological structure of the networks rapidly. In reality, various influences normally coexist in the same context and have subtle relations, such as supportive, contradictory and competitive relations, affecting the users' decisions of adopting any innovations. Therefore, modelling diffusion process of multiple influences is an important, yet challenging research question. By employing the agent-based modelling, in this paper, a distributed approach has been proposed to model the diffusion process of multiple influences in social networks. The proposed model has been applied in the undesirable influence minimisation problem, where the time series is taken into consideration. The experimental results show our model can be utilised to minimise the adverse impact of a certain influence by injecting other influences. Furthermore, the proposed model also sheds light on understanding, investigating and analysing multiple influences in social networks  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">637</td>#}
    <td class="tg-031e">Gizem Korkmaz, Monica Capra, Adriana Kraig, Chris Kuhlman, Kiran Lakkaraju, Fernando Vega-Redondo</td>
    <td class="tg-031e">Coordination and Common Knowledge on Communication Networks</td>
{#    <td class="tg-031e"> Protest is a collective action problem and can be modeled as a coordination game in which two or more people each take an action with the potential to achieve shared mutual benefits, only if their actions coincide. In the context of protest participation, successful coordination requires that people know each others' willingness to participate, and that this information is common knowledge.&nbsp; Social networks can facilitate the creation of common knowledge through the flow of messages.&nbsp; Although there is a rich experimental literature that documents behavior in coordination games with and without communication, little is known about how people coordinate behaviors within a social network and how different types of communication structures affect behavior.  In this paper, we develop a theoretically based on-line experiment with Amazon Mechanical Turk participants to characterize the emergence of common knowledge and coordination through interactions within a network. Our experiment is designed to identify the effects of both social network topology and communication and to falsify the game-theoretic predictions.&nbsp; Our data reveal that choices are affected by the network structure and they move towards the theoretical predictions with communication. We use our behavioral findings to simulate dynamics in more complex networks through agent-based modeling. Thus, we combine human behaviors identified in experiments with realistic social network structures to reveal patterns not previously observed.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">548</td>#}
    <td class="tg-031e">Alex Kuefler, Mykel Kochenderfer</td>
    <td class="tg-031e">Burn-In Demonstrations for Multi-Modal Imitation Learning</td>
{#    <td class="tg-031e"> Recent work on imitation learning has generated policies that reproduce expert behavior from multi-modal data. However, past approaches have focused only on recreating a small number of distinct, expert maneuvers, or have relied on supervised learning techniques that produce unstable policies. This work extends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce behavior over an extended period of time. Our approach involves reformulating the typical imitation learning setting to include ``burn-in demonstrations'' upon which policies are conditioned at test time. We demonstrate that our approach outperforms standard InfoGAIL in maximizing the mutual information between predicted and unseen style labels in road scene simulations, and we show that our method leads to policies that imitate expert autonomous driving systems over long time horizons.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">323</td>#}
    <td class="tg-031e">Adam Coates, Anthony Kleerekoper, Liangxu Han</td>
    <td class="tg-031e">A Unified Framework for Opinion Dynamics</td>
{#    <td class="tg-031e">      Opinion dynamics is the study of how large groups#}
{#    interact with one another and reach consensus, with applications to#}
{#    various areas such as computer networks, politics, and sociology. It is#}
{#    typically explored using agent-based modeling, with a wide variety of#}
{#    available models. Numerous opinion dynamics models have been#}
{#    proposed, but it has been pointed out that there is a lack of a shared#}
{#    framework. We extend earlier attempts and provide a unified framework.#}
{#    The advantages of such a framework include the reduction of duplication#}
{#    and the identification of unexplored parameter space.      Our framework is implemented in a modular simulator which is then used to verify the validity of the framework. We show that the modular approach we propose is able to perfectly replicate results from purpose-built, stand-alone simulators for two widely used models, namely Relative Agreement and CODA.      </td>#}
{#    </tr>#}
    <tr>
{#    <td class="tg-s6z2">704</td>#}
    <td class="tg-031e">Blake Wulfe, Mykel Kochenderfer, Sunil Chintakindi, Sou Cheng Choi, Rory Hartong-Redden, Anuradha Kodali</td>
    <td class="tg-031e">Real-time Prediction of Intermediate-horizon Automotive Collision Risk</td>
{#    <td class="tg-031e">   Advanced collision avoidance and driver hand-off systems can benefit from the ability to accurately predict, in real time, the probability a vehicle will be involved in a collision within an intermediate horizon of 10 to 20 seconds. The rarity of collisions in real-world data poses a significant challenge to developing this capability because, as we demonstrate empirically, intermediate-horizon risk prediction depends heavily on high-dimensional driver behavioral features. As a result, a large amount of data is required to fit an effective predictive model. In this paper, we assess whether simulated data can help alleviate this issue. Focusing on highway driving, we present a three-step approach for generating data and fitting a predictive model capable of real-time prediction. First, high-risk automotive scenes are generated using importance sampling on a learned Bayesian network scene model. Second, collision risk is estimated through Monte Carlo simulation. Third, a neural network domain adaptation model is&nbsp; trained on real and simulated data to address discrepancies between the two domains. Experiments indicate that simulated data can mitigate issues resulting from collision rarity, thereby improving risk prediction in real-world data.    </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 27 (13:30-15:30)<br>Argumentation (T3)</td>
{#    <td class="tg-s6z2">98</td>#}
    <td class="tg-031e">Ofer Arieli, AnneMarie Borg</td>
    <td class="tg-031e">Hypersequential Argumentation Frameworks: An Instantiation in the Modal Logic S5</td>
{#    <td class="tg-031e"> In this paper we introduce hypersequent-based frameworks for the modeling of defeasible reasoning by means of logic-based argumentation. These frameworks are an extension of sequent-based argumentation frameworks, in which arguments are represented not only by sequents, but by more general expressions, called hypersequents. This generalization allows to incorporate, as the deductive-base of our formalism, some well-studied logics like the modal logic S5, the relevance logic RM, and Gödel-Dummett logic LC, to which no cut-free sequent calculi are known. In this paper we take S5 as the core logic and show that the hypersequent-based argumentation frameworks that are obtained in this case yield a robust defeasible variant of S5 with several desirable properties.  </td>#}
    </tr>
    <tr>
    <td class="tg-031e">Ofer Arieli, AnneMarie Borg, Christian Straber</td>
    <td class="tg-031e">Prioritized Sequent-Based Argumentation</td>
    <tr>
{#    <td class="tg-s6z2">225</td>#}
    <td class="tg-031e">Zhiwei Zeng, Xiuyi  Fan,  Chunyan  Miao,  Cyril  Leung,  Chin Jing  Jih,  Ong Yew  Soon</td>
    <td class="tg-031e">Context-based and Explainable Decision Making with Argumentation</td>
{#    <td class="tg-031e"> Argumentation-based approaches to decision making have gained#}
{#    considerable research interest, due to their ability to select and#}
{#    justify decisions. In order to make better decisions, context is a key#}
{#    piece of information that needs to be considered. However, most existing#}
{#    argumentation-based models and frameworks have not modelled#}
{#    or reasoned with context explicitly. In this paper, we present a#}
{#    new argumentation-based approach for making context-based and#}
{#    explainable decisions. We propose a graphical representation for#}
{#    modelling decision problems involving varying contexts, Decision#}
{#    Graph with Context,  and a reasoning mechanism for making#}
{#    context-based decisions which relies on the Assumption-based#}
{#    Argumentation formalism. Based on these constructs, we introduce#}
{#    two types of explanations, argument explanation and context explanation, identifying the reasons for the decisions made from an#}
{#    argument-view and a context-view respectively. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">81</td>#}
    <td class="tg-031e">Abdelraouf Hecham, Pierre Bisquert, Madalina Croitoru</td>
    <td class="tg-031e">On a Flexible Representation for Defeasible Reasoning Variants</td>
{#    <td class="tg-031e"> We propose Statement Graphs,  a new logical formalism for defeasible reasoning based on argumentation. Using a flexible labeling function, SGs can capture the variants of defeasible reasoning . We evaluate our approach with respect to human reasoning and propose a working first order defeasible reasoning tool that, compared to the state of the art, has richer expressivity at no added computational cost.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">42</td>#}
    <td class="tg-031e">Pierpaolo Dondio</td>
    <td class="tg-031e">Ranking Semantics Based on Subgraphs Analysis</td>
{#    <td class="tg-031e"> In this paper we first propose a measure of the sensitivity of an argument in an abstract argumentation framework. The index is an indicator of how sensitive is the label assigned to the argument by an argumentation semantics. This numerical indicator is derived from the topology of the graph via a subgraphs analysis, coupled with the postulates of the chosen semantics.   Using the total rank on arguments induced by such indicator, we propose two ranking-based semantics. We compare the behaviour of our ranking-semantics with recent proposals and a widespread set of properties identified in literature.  A key feature of the semantics is that the attack relation between arguments keeps the same meaning as found in Dung' abstract semantics.#}

{##}
{#      By still relying on Dung' semantics we can soundly deal with any graph configuration, produce justified results, minimize the addition of ad-hoc postulates and provide a clear interpretation of the ranking of arguments.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">501</td>#}
    <td class="tg-031e">Emmanuel Hadoux, Anthony Hunter</td>
    <td class="tg-031e">Learning and Updating User Models for Subpopulations in Persuasive Argumentation Using Beta Distributions</td>
{#    <td class="tg-031e"> Persuasion is an activity that involves one party  trying to induce another party  to believe or do something. It is an important and multifaceted human facility both in professional life  and everyday life . Recently, some proposals in the field of computational models of argument have been made for probabilistic models of what the persuadee knows about, or believes. However, they cannot efficiently model uncertainty on the belief of individuals and cannot represent populations. We propose to use mixtures of beta distributions and apply them on real data gathered by linguists. We show that we can represent the belief and its uncertainty using beta mixtures and that we can predict the evolution of this belief after an argument is given. We also present examples of how to use the mixtures in practice to replace general belief update functions. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="5" nowrap>Session 28 (13:30-15:30)<br>Commuication (T4)</td>
{#    <td class="tg-s6z2">579</td>#}
    <td class="tg-031e">Paula Chocron, Marco Schorlemmer</td>
    <td class="tg-031e">Inferring Commitment Semantics in Multi-Agent Interactions</td>
{#    <td class="tg-031e"> Commitments are a useful abstraction to specify the social semantics of multi-agent communication languages. To use them in open and heterogeneous systems, it is necessary to develop solutions to the problem of interoperability, an effort that has already provided methods to, for example, align commitments between interlocutors. In this paper we consider the problem of commitment semantics inference, which can be summarized as follows: how can an agent that arrives to a community with an established language discover its social semantics, only by observing interactions? We introduce a method based on simple learning techniques that tackles this problem. We show that the basic commitment semantics is not possible to infer, and discuss different ways of enriching it that make inference feasible. We show experimentally how our technique performs for each of these extensions. To the best of our knowledge, that is the first approach that tackles the problem of inferring commitment semantics.  </td>#}
    </tr>
    <tr>
    <td class="tg-031e">Chenxi Qiu, Anna Squicciarini, Dev Khare, Barbara Carminati, James Caverlee </td>
    <td class="tg-031e">CrowdEval: A Cost-Efficient Strategy to Evaluate Crowdsourced Workers Reliability</td>
    </tr>
    <tr>
{#    <td class="tg-s6z2">274</td>#}
    <td class="tg-031e">Samuel Christie, Amit Chopra, Munindar Singh</td>
    <td class="tg-031e">Compositional Correctness in Multiagent Interactions</td>
{#    <td class="tg-031e"> &nbsp; An interaction protocol specifies the constraints on communication  &nbsp; between agents in a multiagent system.&nbsp; Ideally, we would like to be  &nbsp; able to treat protocols as modules and compose them in a declarative  &nbsp; manner to systematically build more complex protocols.&nbsp; Supporting  &nbsp; composition correctly requires taking into account the causal  &nbsp; dependencies between protocols.&nbsp; One particular problem that may  &nbsp; arise from inadequate consideration of causal dependencies is that  &nbsp; the enactment of a composite protocol may violate \emph{atomicity};  &nbsp; that is, some components may be initiated but prevented from  &nbsp; completing.&nbsp; We use this \emph{all or nothing} principle as the  &nbsp; basis for formalizing atomicity as a novel correctness property for  &nbsp; protocols.     &nbsp; Our contributions are the following.&nbsp; One, we motivate and formalize  &nbsp; atomicity and highlight its distinctiveness from related correctness  &nbsp; notions.&nbsp; Two, we give a decision procedure for verifying atomicity  &nbsp; and report results from an implementation.&nbsp; For concreteness of  &nbsp; exposition and technical development, we adopt BSPL as an exemplar  &nbsp; of information-based approaches. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS2</td>#}
    <td class="tg-031e">Kurtulus Kullu, Ugur Gudukbay and Dinesh Manocha</td>
    <td class="tg-031e">ACMICS: an Agent Communication Model for Interacting Crowd Simulation</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">JAAMAS3</td>#}
    <td class="tg-031e">Michael Winikoff, Nitin Yadav and Lin Padgham</td>
    <td class="tg-031e">A new Hierarchical Agent Protocol Notation</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 29 (13:30-15:30)<br>Blue Sky (T1 & T2)</td>
{#    <td class="tg-s6z2">B27</td>#}
    <td class="tg-031e">Markus Brill</td>
    <td class="tg-031e">Interactive Democracy</td>
{#    <td class="tg-031e">Interactive Democracy is an umbrella term that encompasses a variety of approaches to make collective decision making processes more engaging and responsive. A common goal of these approaches is to utilize modern information technology---in particular, the Internet---in order to enable more interactive decision making processes. An integral part of many interactive democracy proposals are online decision platforms that provide much more  flexibility and interaction possibilities than traditional democratic systems. This is achieved by embracing the novel paradigm of delegative voting, often referred to as liquid democracy, which aims to reconcile the idealistic appeal of direct democracy with the practicality of representative democracy. The successful design of interactive democracy systems presents a multidisciplinary research challenge; one important aspect concerns the elicitation and aggregation of preferences. However, existing proposals are mostly disconnected from the vast body of scientific literature on preference aggregation and related topics. In this article, I argue that tools and techniques developed in the multiagent systems literature should be employed to aid the design of online decision platforms and other interactive democracy systems. Insights from computational social choice, an emerging research area at the intersection of computer science and economics, will be particularly relevant for this endeavor.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B29</td>#}
    <td class="tg-031e">Ehud Shapiro, Nimrod Talmon</td>
    <td class="tg-031e">Incorporating Reality into Social Choice</td>
{#    <td class="tg-031e">When voting on a proposal one in fact chooses between two alternatives:  A new hypothetical social state depicted by the proposal and  the status quo ; a Yes vote favors a transition to the proposed hypothetical state, while a No vote favors Reality. Social Choice theory generalizes voting on one proposal to ranking multiple proposals; that Reality was forsaken during this generalization is, in our view, inexplicable. Here we propose to rectify this neglect and incorporate Reality into Social Choice, distinguishing Reality from hypothesis. We show that doing so:  Offers a natural resolution to Condorcet's paradox;  Explains what approval voters approve;  Produces a simple and efficient Condorcet-consistent show-of-hands agenda;  Produces democratic action plans, which  start with Reality and proceed in democratically-supported transitions; and  Nullifies Independence of Irrelevant Alternatives and hence abdicates Arrow's Theorem. Arrow's theorem was taken to show that democracy, conceived as government by the will of the people, is an incoherent illusion. Incorporating Reality into Social Choice may clear this intellectual blemish on democracy and offer a coherent, simple, efficient, easy to communicate, and trustworthy path forward to democracy.</td>#}
    </tr>
    <tr>
    <td class="tg-031e">Lois Vanhee, Melania Borit, Jorge Santos</td>
    <td class="tg-031e">Autonomous fishing vessels roving the seas: what multiagent systems have got to do with it</td>
    <tr>
{#    <td class="tg-s6z2">B36</td>#}
    <td class="tg-031e">Sandip Sen, Zenefa Rahaman, Chad Crawford, Osman Yucel</td>
    <td class="tg-031e">Agents for Social  Change</td>
{#    <td class="tg-031e">We are addicted to the Internet and spend a significant portion of our waking hours engaged to that virtual world through the "window" of our electronic devices. A large majority of these interactions occur on online social media. From advertising campaigns to political debates and from trending news topics to communications from family and social circles, social media platforms and services have become invaluable and irreplaceable tools for most of us. Our beliefs and preferences are increasingly shaped and defined by what we see and experience on social media. With this increased reliance also comes the uneasy realization that information and knowledge of value to us is being drowned out in the deluge of forwarded messages and targeted communication from paid advertisers on various social media platforms. This paper seeks to highlight the research challenges underlying the potential for intelligent agents to help stem the tide, to help us deliberate, prioritize and process information of value to us and to our communities, as well as help us reach out, connect to, share and disseminate mutually interesting knowledge with other users. We posit an agent-based ecosystem, where both individual users and organizations see the value and creative possibilities of agent-based solutions to critical problems of connectivity, relevance, varying interest profiles, context, etc.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B39</td>#}
    <td class="tg-031e">Ofra Amir, Finale Doshi-Velez, David Sarne</td>
    <td class="tg-031e">Agent Strategy Summarization</td>
{#    <td class="tg-031e">Intelligent agents and AI-based systems are becoming increasingly prevalent. They support people in different ways, such as providing users with advice, working with them to achieve goals or acting on users’ behalf. One key capability missing in such systems is the ability to present their users with an effective summary of their strategy and expected behaviors under different conditions and scenarios. This capability, which we see as complimentary to those currently under development in the context of “interpretable machine learning” and “explainable AI”, is critical in various settings. In particular, it is likely to play a key role whenever a user needs to understand the strategy of an agent she is working along with, when having to choose between different available agents to act on her behalf, or when requested to determine the level of autonomy to be granted to the agent or approve its strategy. In this paper, we pose the challenge of developing capabilities for strategy summarization, which is not addressed by current theories and methods in the field. We propose a conceptual framework for strategy summarization, which we envision as a collaborative process that involves both agents and people. Last, we suggest possible testbeds that could be used to evaluate progress in research on strategy summarization.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">B40</td>#}
    <td class="tg-031e">Petros Papapanagiotou, Alan Davoust, Dave Murray-Rust, Areti Manataki, Max Van Kleek, Nigel Shadbolt, Dave Robertson</td>
    <td class="tg-031e">Social Machines for All</td>
{#    <td class="tg-031e">In today's interconnected world, people interact to a unprecedented degree through the use of digital platforms and services, forming complex `social machines'. These are now homes to autonomous agents as well as people, providing an open space where human and computational intelligence can mingle---a new frontier for distributed agent systems. However, participants typically have limited autonomy to define and shape the machines they are part of. In this paper, we envision a future where individuals are able to develop their own Social Machines, enabling them to interact in a trustworthy, decentralized way. To make this possible, development methods and tools must see their barriers-to-entry  dramatically lowered. People should be able to specify the agent roles and interaction patterns in an intuitive, visual way, analyse and test their designs and deploy them as easy to use systems. We argue that this is a challenging but realistic goal, which should be tackled by navigating the trade-off between the accessibility of the design methods --primarily the modelling formalisms-- and their expressive power. We support our arguments by drawing ideas from different research areas including electronic institutions, agent-based simulation, process modelling, formal verification, and model-driven engineering.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="6" nowrap>Session 30 (13:30-15:30)<br>Socially Interactive Agents 2 (T5)</td>
{#    <td class="tg-s6z2">S61</td>#}
    <td class="tg-031e">Hendrik Buschmeier, Stefan Kopp</td>
    <td class="tg-031e">Communicative Listener Feedback in Human–Agent Interaction: Artificial Speakers Need to Be Attentive and Adaptive</td>
    <tr>
{#    <td class="tg-s6z2">S74</td>#}
    <td class="tg-031e">Sebastien Lalle,  Cristina Conati,  Roger Azevedo</td>
    <td class="tg-031e">Prediction of Student Achievement Goals and Emotion Valence during Interaction with Pedagogical Agents</td>
{#    <td class="tg-031e">There is evidence that Pedagogical Agents  can influence students' emotions while learning with Intelligent Tutoring Systems, and that this influence is modulated by the students' achievement goals for learning. This suggests that students may benefit from personalized PAs that could rectify episodes of negative affect depending on their achievement goals. To ascertain the possibility of devising such personalized PAs, this paper investigates the real-time prediction of both students‚Äô achievement goals and affective valence while interacting with MetaTutor, an agent-based intelligent tutoring system. We train classifiers using eye-tracking data to make such prediction, and show that these classifiers can outperform a majority-class baseline at predicting both achievement goals and emotion valence.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S28</td>#}
    <td class="tg-031e">Katherine Metcalf,  Barry-John Theobald,  Nicholas Apostoloff</td>
    <td class="tg-031e">Learning Sharing Behaviors with Arbitrary Numbers of Agents</td>
{#    <td class="tg-031e">We propose a method for modeling and learning turn-taking behaviors for accessing a shared resource.  We model the individual behavior for each agent in an interaction and then use a multi-agent fusion model to generate a summary over the expected actions of the group to render the model independent of the number of agents.  The individual behavior models are weighted finite state transducers  with weights dynamically updated during interactions, and the multi-agent fusion model is a logistic regression classifier.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S51</td>#}
    <td class="tg-031e">Florian Pecune,  Justine Cassell,  Jingya Chen,  Yoichi Matsuyama</td>
    <td class="tg-031e">Field Study Analysis of a Socially Aware Robot Assistant</td>
{#    <td class="tg-031e">The Socially-Aware Robot Assistant  is an embodied conversational agent that works toward using detection of visual, vocal and verbal cues as an input to estimate the strength of its relationship  with a user. SARA then answers to the user through similar visual, vocal and verbal behaviors with the goal of building and maintaining rapport with that user as we hypothesize that this will improve task performance and user satisfaction over time. In this paper, we report results of a field trial with a semi-automatic SARA system that took place in a large high-profile conference. Participants interacted with SARA during the whole conference, receiving recommendations about sessions to attend and/or people to meet. We analyzed these interactions to shed light on the dynamics of the rapport level between SARA and the conference attendees, and investigate how SARA's task performance would influence the evolution of rapport over time. Although we did not find evidence supporting our claim that the recommendations' outcomes would influence rapport dynamics, our findings emphasize the importance of interactional features plays in both rapport and SARA's task performance.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S52</td>#}
    <td class="tg-031e">Johnathan Mell,  Gale Lucas,  Jonathan Gratch</td>
    <td class="tg-031e">Welcome to the Real World: How Agent Strategy Increases Human Willingness to Deceive</td>
{#    <td class="tg-031e">Humans that negotiate through representatives often instruct those representatives to act in certain ways that align with both the client's goals and his or her social norms. However, which tactics and ethical norms humans endorse vary widely from person to person, and these endorsements may be easy to manipulate. This work presents the results of a study that demonstrates that humans that interact with an artificial agent may change what kinds of tactics and norms they endorse‚Äîoften dramatically. Previous work has indicated that people that negotiate through artificial agent representatives may be more inclined to fairness than those people that negotiate directly. Our work qualifies that initial picture, demonstrating that subsequent experience may change this tendency toward fairness. By exposing human negotiators to tough, automated agents, we are able to shift the participant‚Äôs willingness to deceive others and utilize ‚Äúhard-ball‚Äù negotiation techniques. In short, what techniques people decide to endorse is dependent upon their context and experience. We examine the effects of interacting with four different types of automated agents, each with a unique strategy, and how this subsequently changes which strategies a human negotiator might later endorse. In the study, which was conducted on an online negotiation platform, four different types of automated agents negotiate with humans over the course of a 10-minute interaction. The agents differ in a 2x2 design according to agent strategy  and agent attitude . These results show that in this multi-issue bargaining task, humans that interacted with a tough agent were more willing to endorse deceptive techniques when instructing their own representative. These kinds of techniques were endorsed even if the agent the human encountered did not use deception as part of its strategy. In contrast to some previous work, there was not a significant effect of agent attitude. These results indicate the power of allowing people to program agents that follow their instructions, but also indicate that these social norms and tactic endorsements may be mutable in the presence of real negotiation experience.</td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">S31</td>#}
    <td class="tg-031e">Tibor Bosse,  Tilo Hartmann,  Romy Blankendaal,  Nienke Dokter,  Marco Otte,  Linford Goedschalk</td>
    <td class="tg-031e">Virtually Bad: A Study on Virtual Agents that Physically Threaten Human Beings</td>
{#    <td class="tg-031e">This paper introduces the concept of "virtual bad guys": intelligent virtual agents that take a negative or even aggressive stance towards the user. Although they pave the way to various interesting applications, it is hard to create virtual bad guys that are taken seriously by the user, since they are typically unable to apply serious sanctions. To address this issue, this study experimentally investigated the effect of ‚Äúconsequential‚Äù agents that are able to physically threaten their human interlocutors. A consequential agent was developed by equipping users with a  device, through which they were made to believe the agent could mildly shock them. Effects on participants‚Äô levels of anxiety and  stress were measured, and the role of presence and perceived believability of the virtual agent was assessed. The consequential agent triggered a stronger physiological stress response than the non-consequential agent, whereas self-reported levels of anxiety and stress did not significantly differ. Furthermore, while presence and believability were substantially associated with users‚Äô stress response, both states did not mediate or explain the effect of a consequential vs. non-consequential agent on stress, as they did not significantly differ between conditions. Implications of these findings and suggestions for follow-up studies on ‚Äúvirtual bad guys‚Äù are discussed. </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 31 (17:00-18:00)<br>Noncooperative Games (C3)</td>
{#    <td class="tg-s6z2">53</td>#}
    <td class="tg-031e">Erel Segal-Halevi</td>
    <td class="tg-031e">Competitive Equilibrium for almost All Incomes</td>
{#    <td class="tg-031e"> Competitive equilibrium from equal incomes &nbsp; is a well-known rule for fair allocation of resources among agents with different preferences. It has many advantages, among them is the fact that a CEEI allocation is both Pareto efficient and envy-free. However, when the resources are indivisible, a CEEI allocation might not exist even when there are two agents and a single item.  In contrast to this discouraging non-existence result, Babaioff and Nisan and Talgam-Cohen  recently suggested a new and more encouraging approach to allocation of indivisible items: instead of insisting that the incomes be equal, they suggest to look at the entire space of possible incomes, and check whether there exists a competitive equilibrium for almost all income-vectors  --- all income-space except a subset of measure zero.  They show that a CEFAI exists when there at most 3 indivisible items, or when there are 4 indivisible items and two agents. They also show that when there are 5 items and two agents with arbitrary monotone preferences, there might not exist a CEFAI. They leave open the cases of 4 items with three or four agents.  This paper presents a new way to implement a CEFAI, as&nbsp; a subgame-perfect equilibrium of a sequential game.&nbsp;&nbsp; This new implementation allows us to both offer much simpler solutions to the known cases,  and to prove that a CEFAI exists even in the much more difficult case of 4 items and three agents.&nbsp; Moreover, we prove that a CEFAI might not exist with 4 items and four agents.&nbsp; Thus, this paper completes the characterization of CEFAI for monotone preferences.  </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">63</td>#}
    <td class="tg-031e">Erel Segal-Halevi</td>
    <td class="tg-031e">Fairly Dividing a Cake after Some Parts Were Burnt in the Oven</td>
{#    <td class="tg-031e"> There is a heterogeneous resource that contains both good parts and bad parts, for example, a cake with some parts burnt, a land-estate with some parts heavily taxed, or a chore with some parts fun to do. The resource has to be divided fairly among n agents, each of whom has a personal value-density function on the resource. The value-density functions can accept any real value --- positive, negative or zero. Can standard cake-cutting procedures, developed for positive valuations, be adapted to this setting? This paper focuses on the question of envy-free cake-cutting with connected pieces. It is proved that such a division exists for 3 agents.    </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">635</td>#}
    <td class="tg-031e">Felix Brandt, Christian Saile, Christian Stricker</td>
    <td class="tg-031e">Voting with Ties: Strong Impossibilities via SAT Solving</td>
{#    <td class="tg-031e">Voting rules allow groups of agents to aggregate their preferences in order to reach joint decisions. The Gibbard-Satterthwaite theorem, a seminal result in social choice theory, implies that, when agents have  strict  preferences, all anonymous, Pareto-optimal, and  single-valued  voting rules can be strategically manipulated. In this paper, we consider multi-agent voting when there can be ties in the preferences as well as in the outcomes. These assumptions are extremely natural--especially when there are large numbers of alternatives--and enable us to prove much stronger results than in the overly restrictive setting of strict preferences. In particular, we show that    all anonymous Pareto-optimal rules where ties are broken according to the preferences of a chairman or by means of even-chance lotteries are manipulable, and that    all pairwise Pareto-optimal rules are manipulable, no matter how ties are broken. These results are proved by reducing the statements to finite--yet very large--problems, which are encoded as formulas in propositional logic and then shown to be unsatisfiable by a SAT solver. We also extracted human-readable proofs from minimal unsatisfiable cores of the formulas in question, which were in turn verified by an interactive higher-order theorem prover.</td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 32 (17:00-18:00)<br>Norms And Trust (C3)</td>
{#    <td class="tg-s6z2">415</td>#}
    <td class="tg-031e">Maite Lopez-Sanchez, Juan Antonio Rodriguez-Aguilar, Javier Morales, Michael Wooldridge, Marc Serramia, Carlos Ansotegui, Manel Rodriguez</td>
    <td class="tg-031e">Moral values in norm decision making</td>
{#    <td class="tg-031e"> Most often, both agents and human societies use norms to coordinate their on-going activities. Nevertheless, choosing the 'right' set of norms to regulate these societies constitutes an open problem. Firstly, intrinsic norm relationships may lead to inconsistencies in the chosen set of norms. Secondly, and more importantly, there is an increasing demand of including ethical considerations in the decision making process. This paper focuses on choosing the 'right' norms by considering moral values together with society's partial preferences over these values and the extent to which candidate norms promote them. The resulting decision making problem can then be encoded as a linear program, and hence solved by state-of-the art solvers. Furthermore, we empirically test several optimisation scenarios so to determine the system's performance and the characteristics of the problem that affect its hardness.   </td>#}
    </tr>
    <tr>
    <td class="tg-s6z2">Celso de Melo, Stacy Marcella and Jonathan Gratch</td>
    <td class="tg-031e">Social Decisions and Fairness Change When People’s Interests Are Represented by Autonomous Agents</td>
    </tr>
    <tr>
    <td class="tg-s6z2">Jessica Soares dos Santos, Jean O. Zahn, Eduardo A. Silvestre, Viviane T. Silva and Wamberto W. Vasconcelos</td>
{#    <td class="tg-031e"></td>#}
    <td class="tg-031e">Detection and Resolution of Normative Conflicts in Multi-agent Systems: A Literature Survey</td>
{#    <td class="tg-031e"></td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="3" nowrap>Session 33 (17:00-18:00)<br>Planning (C7)</td>
{#    <td class="tg-s6z2">460</td>#}
    <td class="tg-031e">Vaishak Belle</td>
    <td class="tg-031e">On Plans With Loops and Noise</td>
{#    <td class="tg-031e"> In an influential paper, Levesque proposed a formal specification for analysing the correctness of program-like plans, such as conditional plans, iterative plans, and knowledge-based plans. He motivated a logical characterisation within the situation calculus that included binary sensing actions. While the characterisation does not immediately yield a practical algorithm, the specification serves as a general skeleton to explore the synthesis of program-like plans for reasonable, tractable fragments.&nbsp;     Increasingly, classical plan structures are being applied to stochastic environments such as robotics applications. This raises the question as to what the specification for correctness should look like, since Levesque's account makes the assumption that sensing is exact and actions are deterministic. Building on a situation calculus theory for reasoning about  degrees of belief and noise, we revisit the execution  semantics of generalized plans. The specification is then used to  analyse the correctness of example plans.&nbsp; </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">178</td>#}
    <td class="tg-031e">Miquel Ramirez, Michael Papasimeon, Nir Lipovetzky, Tim Miller, Adrian Pearce, Lyndon Benke, Enrico Scala, Mohammad Zamani </td>
    <td class="tg-031e">Integrated Hybrid Planning and Programmed Control for Real--Time UAV Maneuvering</td>
{#    <td class="tg-031e"> The automatic generation of realistic behaviour such as tactical intercepts for  Unmanned Aerial Vehicle s  in air combat is a&nbsp;challenging problem. State-of-the-art solutions propose hand--crafted&nbsp;algorithms and heuristics whose performance depends heavily on the initial&nbsp;conditions and aerodynamic properties of the UAVs involved. This&nbsp;paper shows how to employ domain--independent planners, embedded into professional&nbsp;multi--agent simulations, to implement  Model Predictive Control   two--level&nbsp;hybrid control systems for UAVs. Width-based search techniques,&nbsp;taken off-the-shelf from the literature in  classical planning over simulators, &nbsp;are used to generate  real--time control signals  that steer&nbsp;   simulated aircraft as best suits the situation. We compare experimentally the controllers&nbsp;using planners with a behaviour tree that implements tactics widely&nbsp;accepted and used in the real world. Our results indicate hybrid planners derive novel and effective tactics from  first principles  inherent to the dynamical constraints UAVs are subject to. </td>#}
    </tr>
    <tr>
{#    <td class="tg-s6z2">369</td>#}
    <td class="tg-031e">Aleck MacNally, Nir Lipovetzky, Miquel Ramirez, Adrian Pearce </td>
    <td class="tg-031e">Action Selection for Transparent Planning</td>
{#    <td class="tg-031e"> We introduce a novel framework to formalise and solve  transparent planning tasks &nbsp;by executing actions selected in a suitable and timely fashion. A  transparent planning task &nbsp;is defined as task where the objective of the agent is to communicate its true goal to observers, thereby making its intentions and its action selection  transparent . We formally define and model these tasks as  Goal POMDP  where the state space is the Cartesian product of the states of the world and a given set of hypothetical goals. Action effects are deterministic in the world states of the problem but probabilistic in the observer's beliefs. Transition probabilities are obtained from making a call to a model-based plan recognition algorithm, which we refer to as an  observer stereotype . We propose an action selection strategy via on-line planning that seeks actions to quickly convey the goal being pursued to an observer assumed to fit a given stereotype. In order to keep run-times feasible, we propose a novel model-based plan recognition algorithm that approximates well-known probabilistic plan recognition methods. The resulting on-line planner, after being evaluated over a diverse set of domains and three different observer stereotypes, is found to convey goal information faster than purely goal-directed planners.  </td>#}
    </tr>
    <tr>
    <td class="tg-s6z3" rowspan="1" nowrap>Session 34 (17:00-18:00)<br>Engineering Multiagent Systems 2 (C2)</td>
{#    <td class="tg-s6z2">515</td>#}
{#    <td class="tg-031e"> A networked opinion diffusion process that usually involves extensive spontaneous discussions between connected users, is often propelled by external sources of news or feeds recommended to them. In many applications like marketing design, or product launch, etc., corporations often post curated news or feeds on social media in order to steer the users’ opinions in a desired way. We call such scenarios as opinion shaping or opinion control whereby a few select users called control users post opinionated messages to drive the others’ opinion to reach a given state. In this paper, we propose SmartShape, an opinion control package that jointly selects the control users, as well as computes the optimum rate of control messages, thereby driving the networked opinion dynamics to the desired direction. Furthermore, our proposal also includes a robust shaping suit which makes our control framework resilient to stochastic fluctuations of opinion dynamics, orginating from several sources of randomness. Experiments on several synthetic and real datasets gathered from Twitter, show that SmartShape can accurately determine the quality of a set of control users as well as shape the opinion dynamics more effectively than several baselines. </td>#}
{#    <td class="tg-s6z2">379</td>#}
    <td class="tg-031e">Anshuka Rangi, Massimo Franceschetti </td>
    <td class="tg-031e">Multi-armed bandit algorithms for  crowdsourcing systems with  online estimation of  workers' ability</td>
{#    <td class="tg-031e"> Crowdsourcing systems have become a valuable solution for various organizations to outsource work on a temporary basis. &nbsp;Quality assurance in these systems remains a key issue due to the distributed setup of the crowdsourcing platforms and the absence of a priori information about the workers. Our work proposes a notion of Limited-information Crowdsourcing Systems,  where the task master can assign the work &nbsp; based on some &nbsp;knowledge of the workers' ability acquired &nbsp; &nbsp;over time. The key challenges in this new setup are determining an efficient workers' selection policy and estimating the abilities of the workers. For the former challenge, we reduce the problem to an arm-limited, budget limited, multi-armed bandit  set-up and use the simplified bounded KUBE  algorithm &nbsp;of \cite{tran2014efficient} &nbsp;as a solution. This algorithm has previously &nbsp;only been experimentally evaluated, and we provide provable performance guarantees, showing that it is order optimal. This work closes the gap in the literature of budget limited arm limited MAB by proving that expected regret of B-KUBE is $O)$ where $B$ is the total budget of the task master. The latter challenge is solved by &nbsp;formalizing the notion of workers' ability mathematically, and proposing a strategy for the estimation of the workers' &nbsp;ability. Later, we experimentally evaluate B-KUBE in conjunction with this &nbsp;strategy, showing that it outperforms other state-of- the-art MAB algorithms when applied in the same setting.&nbsp;  </td>#}
    </tr>

    <tr>
        <td class="tg-9353" colspan="3"><font color="red"><H5><b>13 July 2018</b></H5></font></td>
    </tr>
    <tr>
<td class="tg-s6z3">Session<br></td>
{#<td class="tg-s6z2">Paper ID</td>#}
<td class="tg-031e">Authors</td>
<td class="tg-031e">Title</td>
{#<td class="tg-031e"> Abstract</td>#}
</tr>
    <tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 36 (09:00-10:00)<br>Coalition Formation</td>
{#<td class="tg-s6z2">272</td>#}
<td class="tg-031e">Gianpiero Monaco, Luca Moscardelli, Michele Flammini, Mordechai Shalom, Shmuel Zaks </td>
<td class="tg-031e">Online Coalition Structure Generation in Graph Games</td>
{#<td class="tg-031e"> We consider the online version of the coalition structure generation in graph games problem, where agents are vertices in a graph. After each step $t$, in which the $t$-th agent appears in an online fashion, agents are partitioned into $c$ coalitions $\clust=\{\C_1^t, \C_2^t, \ldots, \C_{c}^t \}$, such that every agent belongs to exactly one coalition $C_i^t$. When an agent appears, it may either join an existing coalition or form a new one having it as the only agent. The profit of a such a coalition structure $\clust$ is the sum of the profits of its coalitions. We consider two cases for the profit of a coalition:  the sum of the weights of its edges, and  the sum of the weights of its edges divided by its size . Such coalition structures appear in a variety of application in AI, multi-agent systems, networks, as well as in social networks, data analysis, computational biology, game theory, and scheduling.  For each of the profit functions we consider the bounded and unbounded cases depending on whether or not the size of a coalition can exceed a given value $\alpha$. Furthermore, we consider the case of limited number of coalitions and various weight functions for the edges, namely the cases of unrestricted, positive and constant weights. We show tight or nearly tight bounds for the competitive ratio in each case.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">408</td>#}
<td class="tg-031e">Emir Demirovic, Nicolas Schwind, Tenda Okimoto, Katsumi Inoue </td>
<td class="tg-031e">Recoverable Team Formation: Building Teams Resilient to Change</td>
{#<td class="tg-031e"> Team formation consists in finding the least expensive team of agents such that a certain set of skills is covered. In this paper, we formally introduce recoverable team formation, a generalization of the above problem, by taking into account the dynamic nature of the environment, e.g. after a team has been formed, agents may unexpectedly become unavailable due to failure or illness. We analyze the computational complexity of RTF, provide both complete and heuristic algorithms, and empirically evaluate their performance. Furthermore, we demonstrate that RTF generalizes robust team formation, where the task is to build a team capable of covering all required skills even after any k agents are removed. Despite the high complexity of forming a recoverable team, we argue that recoverability is a crucial feature, and experimentally show that it is more appropriate for some applications than robustness.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">522</td>#}
<td class="tg-031e">Fahad Panolan, Sushmita Gupta, Saket Saurabh, Meirav Zehavi </td>
<td class="tg-031e">Stability in Barter Exchange Markets</td>
{#<td class="tg-031e"> The notion of stability is the foundation of several classic problems in economics and computer science that arise in a wide-variety of real-world situations, including Stable Marriage, Stable Roommate, Hospital Resident and Group Activity Selection. We study this notion in the context of barter exchange markets. The input of our problem of interest consists of a set of people offering goods/services, with each person subjectively assigning values to a subset of goods/services offered by other people. The goal is to find a  stable transaction, a set of cycles that is  stable  in the following sense: there does not exist a cycle such that every person participating in that cycle prefers to his current “status”. For example, consider a market where families are seeking vacation rentals and offering their own homes for the same. Each family wishes to acquire a vacation home in exchange of its own home without any monetary exchange. We study such a market by analyzing a stable transaction of houses involving cycles of fixed length. The underlying rationale is that an entire trade/exchange fails if any of the participating agents cancels the agreement; as a result, shorter  cycles are desirable.  We show that given a transaction, it can be verified whether or not it is stable in polynomial time, and that the problem of finding a stable transaction is NP-hard even if each person desires only a small number of other goods/services. Having established these results, we study the problem of finding a stable transaction in the framework of parameterized algorithms. </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 37 (09:00-10:00)<br>Learning And Adaptation 4</td>
{#<td class="tg-s6z2">119</td>#}
<td class="tg-031e">Xinlei pan, Yilin Shen </td>
<td class="tg-031e">Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning</td>
{#<td class="tg-031e"> Humans are able to understand and perform complex tasks&nbsp;  by strategically structuring tasks into incremental steps  or sub-goals. For a robot attempting to learn to perform&nbsp;  a sequential task with critical subgoal states, these&nbsp;  subgoal states can provide a natural opportunity for&nbsp;  interaction with a human expert. This paper&nbsp;  analyzes the benefit of incorporating a notion of subgoals  into Inverse Reinforcement Learning  with&nbsp;  a Human-In-The-Loop  framework. The learning process&nbsp;  is interactive, with a human expert first providing input&nbsp;  in the form of full demonstrations along with subgoal states. These  subgoal states defines a set of sub-tasks for the learning&nbsp;  agent to complete in order to achieve the final goal. The learning agent&nbsp;  queries for partial demonstrations corresponding to each sub-task  as needed when the learning agent struggles with individual&nbsp;  sub-tasks. The proposed Human Interactive IRL  framework  is evaluated on several discrete path-planning tasks. We&nbsp;  demonstrate that subgoal-based interactive&nbsp;  structuring of the learning task results in significantly more&nbsp;  efficient learning, requiring only a fraction of the demonstration&nbsp;  data needed for learning the underlying reward function with a&nbsp;  baseline IRL model.&nbsp; </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">384</td>#}
<td class="tg-031e">Zhang-Wei Hong, Shih-Yang Su, Tzu-Yun Shann, Yi-Hsiang Chang, Chun-Yi Lee </td>
<td class="tg-031e">A Deep Policy Inference Q-Network for Multi-Agent Systems</td>
{#<td class="tg-031e"> We present DPIQN, a deep policy inference Q-network that targets multi-agent systems composed of controllable agents, collaborators, and opponents that interact with each other. We focus on one challenging issue in such systems---modeling agents with varying strategies---and propose to employ "policy features" learned from raw observations  of collaborators and opponents by inferring their policies. DPIQN incorporates the learned policy features as a hidden vector into its own deep Q-network, such that it is able to predict better Q values for the controllable agents than the state-of-the-art deep reinforcement learning models. We further propose an enhanced version of DPIQN, called deep recurrent policy inference Q-network, for handling partial observability. Both DPIQN and DRPIQN are trained by an adaptive training procedure, which adjusts the network's attention to learn the policy features and its own Q-values at different phases of the training process. We present a comprehensive analysis of DPIQN and DRPIQN, and highlight their effectiveness and generalizability in various multi-agent settings. Our models are evaluated in a classic soccer game involving both competitive and collaborative scenarios. Experimental results performed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate superior performance to the baseline DQN and deep recurrent Q-network  models. We also explore scenarios in which collaborators or opponents dynamically change their policies, and show that DPIQN and DRPIQN do lead to better overall performance in terms of stability and mean scores.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">197</td>#}
<td class="tg-031e">Pol Rosello, Mykel Kochenderfer </td>
<td class="tg-031e">Multi-Agent Reinforcement Learning for Multi-Object Tracking</td>
{#<td class="tg-031e"> We present a novel, multi-agent reinforcement learning formulation of multi-object tracking that treats creating, propagating, and terminating object tracks as actions in a sequential decision-making problem. In our formulation, each agent tracks a single object at a time by updating a Bayesian filter according to a discrete number of actions. At each timestep, the reward received is dependent on the joint actions taken by all agents and the ground truth object tracks. We optimize for different tracking metrics directly while propagating covariance information about each object's state. We use trust region policy optimization  to train a shared policy across all agents, parameterized by a multi-layer neural network. Our experiments show an improvement in tracking accuracy over similar state-of-the-art, rule-based approaches on a popular multi-object tracking dataset.  </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 38 (09:00-10:00)<br>Engineering And Applications Of Multiagent Systems</td>
{#<td class="tg-s6z2">286</td>#}
<td class="tg-031e">Ferdinando Fioretto, Chansoo Lee, Pascal Van Hentenryck </td>
<td class="tg-031e">Constrained-Based Differential Privacy for Mobility Services</td>
{#<td class="tg-031e"> Ubiquitous mobile and wireless communication systems have the potential to revolutionize transportation systems, making accurate mobility traces and activity-based patterns available to optimize the design and operations of mobility systems. However, these rich data sets also pose significant privacy risks, potentially revealing highly sensitive information about individual agents.  This paper studies how to use  differential privacy  to release mobility data for transportation applications. It shows that existing approaches do not provide the desired fidelity for practical uses. To remedy this limitation, the paper proposes the idea of  Constraint-Based Differential Privacy   that casts the production of a private data set as an optimization problem that redistributes the noise introduced by a randomized mechanism to satisfy fundamental constraints of the original data set.  The CBDP has strong theoretical guarantees: It is a constant factor away from optimality and, when the constraints capture categorical features, it runs in polynomial time. Experimental results show that CBDP ensures that a city-level multi-modal transit system has similar performance measures when designed and optimized over the real and private data sets and improves state-of-art privacy methods by an order of magnitude. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">381</td>#}
<td class="tg-031e">Bryan Wilder, Laura Onasch-Vera,Juliana Hudson, Jose Luna, Nicole Wilson, Robin Petering, Darlene Woo, Milind Tambe, Eric Rice </td>
<td class="tg-031e">End-to-End Influence Maximization in the Field</td>
{#<td class="tg-031e"> This work is aims to overcome the challenges in deploying influence maximization to support community driven interventions. Influence maximization is a crucial technique used in preventative health interventions, such as HIV prevention amongst homeless youth. Drop-in centers for homeless youth train a subset of youth as peer leaders who will disseminate information about HIV through their social networks. The challenge is to find a small set of peer leaders who will have the greatest possible influence. While many algorithms have been proposed for influence maximization, none can be feasibly deployed by a service provider: existing algorithms require costly surveys of the entire social network of the youth to provide input data, and high performance computing resources to run the algorithm itself. Both requirements are crucial bottlenecks to widespread use of influence maximization in real world interventions.  To address the above challenges, this innovative applications paper introduces the CHANGE agent for influence maximization. CHANGE handles the end-to-end process of influence maximization, from data collection to peer leader selection. Crucially, CHANGE only surveys a fraction of the youth to gather network data and minimizes computational cost while providing comparable performance to previously proposed algorithms. We carried out a pilot study of CHANGE in collaboration with a drop-in center serving homeless youth in a major U.S. city. CHANGE surveyed only 18\% of the youth to construct its social network. However, the peer leaders it selected reached just as many youth as previously field-tested algorithms which surveyed the entire network. This is the first real-world study of a network sampling algorithm for influence maximization. Simulation results on real-world networks also support our claims. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">388</td>#}
<td class="tg-031e">Amulya Yadav, Ritesh Noothigattu, Eric Rice,Laura Onasch-Vera,Leandro Soriano Marcolino,Milind Tambe </td>
<td class="tg-031e">Please be an Influencer? Contingency-Aware Influence Maximization</td>
{#<td class="tg-031e"> Most previous work on influence maximization in social networks assumes that the chosen influencers  can be influenced with certainty . In this paper, we focus on using influence maximization in public health domains for assisting low-resource communities, where contingencies are common. It is very difficult in these domains to ensure that the seed nodes are influenced, as influencing them entails contacting/convincing them to attend training sessions, which may not always be possible.&nbsp; Unfortunately, previous state-of-the-art algorithms for influence maximization are unusable in this setting. This paper tackles this challenge via the following four contributions:  we propose the Contingency Aware Influence Maximization problem and analyze it theoretically;  we cast this problem as a Partially Observable Markov Decision Process and propose CAIMS  to solve it, which leverages a natural action space factorization associated with real-world social networks; and  we provide extensive simulation results to compare CAIMS with existing state-of-the-art influence maximization algorithms. Finally,  we provide results from a real-world feasibility trial conducted to evaluate CAIMS, in which key influencers in homeless youth social networks were influenced in order to spread awareness about HIV.              </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 39 (09:00-10:00)<br>Logic For Multiagent Systems 2</td>
{#<td class="tg-s6z2">291</td>#}
<td class="tg-031e">Bita Banihashemi, Giuseppe De Giacomo, Yves Lesperance </td>
<td class="tg-031e">Hierarchical Agent Supervision</td>
{#<td class="tg-031e"> Agent supervision is a form of control/customization where  a supervisor restricts the behavior of an agent to enforce certain  requirements, while leaving the agent as much autonomy  as possible. To facilitate supervision, it is often of interest  to consider hierarchical models where a high level abstracts  over low-level behavior details. We study hierarchical agent  supervision in the context of the situation calculus and the  ConGolog agent programming language, where we have a  rich first-order representation of the agent state. We define  the constraints that ensure that the controllability of individual  actions at the high level in fact captures the controllability  of their implementation at the low level. On the basis of  this, we show that we can obtain the maximally permissive  supervisor by first considering only the high-level model and  obtaining a high-level supervisor and then refining its actions  locally, thus greatly simplifying the supervisor synthesis task. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">655</td>#}
<td class="tg-031e">Dario Della Monica, Aniello Murano </td>
<td class="tg-031e">Parity-energy ATL for qualitative and quantitative reasoning in MAS</td>
{#<td class="tg-031e"> In this paper, we introduce a new logic suitable to reason about strategic  abilities of multi-agent systems where  agents are subject to  qualitative  and quantitative  constraints and where goals are  represented, as usual, by means of temporal properties.  We formally define such a logic, named parity-energy-ATL,  and we study its model checking problem, which we prove to be decidable &nbsp;with   different complexity upper bounds, depending on different choices for the  energy range.    </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">318</td>#}
<td class="tg-031e">Jieting Luo,Max Knobbout, John-Jules Meyer </td>
<td class="tg-031e">Eliminating Opportunism using an Epistemic Mechanism</td>
{#<td class="tg-031e"> Opportunism is a behavior that takes advantage of knowledge asymmetry and results in promoting agents' own value and demoting other agents' value. It is important to eliminate such a selfish behavior in multi-agent systems, as it has undesirable results for the participating agents. However, as the context we study here is multi-agent systems, system designers actually might not be aware of the value system for each agent thus they have no idea whether an agent will perform opportunistic behavior. Given this fact, this paper designs an epistemic mechanism to eliminate opportunism given a set of possible value systems for the participating agents: an agent's knowledge gets updated so that the other agent is not able to perform opportunistic behavior, and there exists a balance between eliminating opportunism and respecting agents' privacy.  </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 40 (09:00-10:00)<br>Human And Agent Interaction</td>
{#<td class="tg-s6z2">311</td>#}
<td class="tg-031e">Tiep Le, Atena MTabakhi, Long Tran-Thanh, William Yeoh, Tran Cao Son </td>
<td class="tg-031e">Preference Elicitation with Interdependency and User Bother Cost</td>
{#<td class="tg-031e"> Agent-based scheduling systems, such as automated systems that schedule meetings for users and systems that schedule smart devices in smart homes, require the elicitation of user preferences in order to operate in a manner that is consistent with user expectations. Unfortunately, interactions between such systems and users can be limited as human users prefer to not be overly bothered by such systems. As such, a key challenge is for the system to efficiently elicit key preferences without bothering the users too much.&nbsp;  To tackle this problem, we propose a cost model that models the cognitive or bother cost associated with asking a question. We incorporate this model into our iPLEASE system, an interactive preference elicitation system. iPLEASE represents a user's preferences as a matrix, called preference matrix, and uses heuristics to select, from a given set of questions, an efficient sequence of questions to ask the user such that the total bother cost incurred to the user does not exceed a given bother cost budget. The user's response to those questions will partially populate the preference matrix. It then performs an exact matrix completion via convex optimization to approximate the remaining preferences that are not directly elicited. We empirically apply iPLEASE on randomly-generated problems as well as on a real-world dataset for the smart device scheduling problem to demonstrate that our approach outperforms other non-trivial benchmarks in eliciting user preferences.&nbsp; </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">407</td>#}
<td class="tg-031e">David Sarne, Nadav Lisovtsev </td>
<td class="tg-031e">Modeling Assistant's Autonomy Constraints as a Means for Improving Autonomous Assistant-Agent Design</td>
{#<td class="tg-031e"> In this paper we introduce and experimentally evaluate a new&nbsp; sub-optimal decision-making design to be used by autonomous agents acting on behalf of a user in repeated tasks, whenever the agent's autonomy level is continuously controlled by the user. This mode of operation is common and can be found whenever user's perception of the agent's competence is affected by the nature of the outcomes resulting from the agent's decisions rather than the optimality of the decisions made, e.g., in spam filtering, CV filtering, poker agents, and robotic vacuum cleaners as well as in newly arriving systems such as autonomous cars. Our proposed design relies on choosing the action that offers the best tradeoff between decision optimality and the influence over future allowed autonomy, where the latter is predicted using standard machine learning techniques. The design is found to be highly effective compared to following the theoretic-optimal decision rule, over various measures, through extensive experimentation with a virtual investment agent, making virtual investments on behalf of 679 subjects using Amazon Mechanical Turk.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">767</td>#}
<td class="tg-031e">Luisa Zintgraf, Diederik Roijers, Sjoerd Linders, Catholijn Jonker, Ann Nowe </td>
<td class="tg-031e">Ordered Preference Elicitation Strategies for Supporting Multi-Objective Decision Making</td>
{#<td class="tg-031e"> In multi-objective decision planning and learning, much attention is paid to producing optimal solution sets that contain an optimal policy for every possible user preference profile. We argue that the step that follows, i.e, determining which policy to execute by maximising the user's intrinsic utility function over this  set, is under-studied. This paper aims to fill this gap. We build on previous work on Gaussian processes and pairwise comparisons for preference modelling, extend it to the multi-objective decision support scenario, and propose new ordered preference elicitation strategies based on ranking and clustering. Our main contribution is an in-depth evaluation of these strategies using computer and human-based experiments. We show that our proposed elicitation strategies outperform the currently used pairwise methods, and found that users prefer ranking most. Our experiments further show that utilising monotonicity information in GPs by using a linear prior mean at the start and virtual comparisons to the nadir and ideal points, increases performance. We demonstrate our decision support framework in a real-world study on traffic regulation, conducted with the city of [blinded for review]. </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="3" nowrap>Session 41 (09:00-10:00)<br>Trust And Reputation</td>
{#<td class="tg-s6z2">573</td>#}
{#    <td class="tg-s6z2">148</td>#}
<td class="tg-031e">Dan Amir, Ofra Amir</td>
<td class="tg-031e">HIGHLIGHTS: Summarizing Agent Behavior to People</td>
{#    <td class="tg-031e">People increasingly interact with autonomous agents. This paper introduces and formalizes the problem of automatically generating a summary of an agent's behavior with the goal of increasing people's familiarity with the agent's capabilities and limitations. In contrast with prior approaches&nbsp; which developed methods for explaining a single decision made by an agent, our approach aims to provide users with a summary that describes the agent's behavior in different situations. We hypothesize that reviewing such summaries could help people in tasks such as choosing between agents or determining the level of autonomy to grant to an agent. We develop ``HIGHLIGHTS'', an algorithm that produces a summary of an agent's behavior by extracting important trajectories from simulations of the agent.&nbsp;   We conducted a human-subject experiment to evaluate whether HIGHLIGHTS summaries help people assess the capabilities of agents. Our results show that participants were more successful at evaluating the capabilities of agents when presented with HIGHLIGHTS summaries compared to baseline summaries, and rated them as more helpful. We also explore a variant of the HIGHLIGHTS algorithm which aims to increase the diversity of states included in the summary, and show that this modification further improves people's ability to assess agents' capabilities.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">722</td>#}
<td class="tg-031e">David Pynadath, Ning Wang, Ericka Rovira, Michael J. Barnes</td>
<td class="tg-031e">Clustering Behavior to Recognize Subjective Beliefs in Human-Agent Teams</td>
{#<td class="tg-031e"> Trust is critical to the success of human-agent teams, and one of the critical antecedents to trust is transparency. To best interact with human teammates, an agent must be able to explain itself so that they understand its decision-making process. However, individual differences among human teammates require that the agent dynamically adjust its explanation strategy based on their current unobservable subjective beliefs. We therefore need methods by which an agent can recognize its teammates' subjective beliefs relevant to trust-building . We leverage a nonparametric method to enable an agent to use its history of prior interactions as a means for recognizing and predicting a new teammate's subjective beliefs. We first gather data combining observable behavior sequences with survey-based observations of typically unobservable perceptions. We then use a nearest-neighbor approach to identify the prior teammates most similar to the new one. We use these neighbors' responses to infer the likelihood of possible beliefs, as in collaborative filtering. The results provide insights into the types of beliefs that are easy  to infer from purely behavioral observations. </td>#}
</tr>
<tr>
<td class="tg-031e">Abir De, Sourangshu Bhattacharya, Niloy Ganguly </td>
<td class="tg-031e">Shaping Opinion Dynamics in Social Networks</td>
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 42 (10:30-11:50)<br>Auction And Mechanism Design 4</td>
{#<td class="tg-s6z2">206</td>#}
<td class="tg-031e">Qingpeng Cai, Pingzhong Tang, Yulong Zeng </td>
<td class="tg-031e">Ranking mechanism design for price-setting agents in e-commerce</td>
{#<td class="tg-031e"> Ranking algorithms of e-commerce sites take the buyer's search query and information of the corresponding sellers' items as input, and output a ranking of sellers' items that maximizes sites' objectives. However, the conversion rate of each item  not only depends on the ranking given by the site, but also depends on the item price set by its seller. As a result, a ranking algorithm is in fact a mechanism that deals with sellers who strategically set item prices.  An interesting fact about this setting, at least   the   status     quo for the largest e-commerce sites such as Taobao, Amazon, and eBay, is that sellers are usually not given the option to report their private costs but can only communicate with the site by setting item prices. In terms of mechanism design, this is a setting where the designer is restricted to design a specific type of indirect mechanisms.  We follow the framework of implementing optimal direct mechanisms by indirect mechanisms to tackle this optimal indirect ranking mechanism design problem. We firstly define a related optimal direct ranking mechanism design setting and use Myerson's characterization to optimize in that setting. We then characterize the class of direct mechanisms which could be implemented by indirect mechanisms, and construct a mapping that maps the mechanisms designed in the previous direct setting to indirect mechanisms in the original setting where sellers are allowed only to set item prices. We show that, using this technique, one can obtain mechanisms in the indirect setting that maximize expected total trading volume. We then present the mechanism employed by Taobao currently, get a Bayesian Nash Equilibrium of it and obtain the gap of the volume of Taobao and the optimal mechanism. Given real dataset from Taobao, we also simulate our optimal mechanism and Taobao's mechanism, and it shows that our mechanism outperforms Taobao's mechanism significantly. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">421</td>#}
<td class="tg-031e">Yulong Zeng, Pingzhong Tang, Weiran Shen </td>
<td class="tg-031e">Buyer-optimal distribution</td>
{#<td class="tg-031e"> We consider the problem of how a buyer can optimize his utility if he is flexible to choose his own valuation distribution to attend a prior-dependent auction, such as the revenue-optimal auction. The problem is motivated by and equivalent to a variation of the market segmentation problem, where a principal tries to find a subset of agents  from the set of all agents, each with a constant valuation, to attend a posted price auction for selling M identical items, in order to maximize the total utilities from the agents who are selected into the segment. Our results are closed-form solutions in both the single buyer case and multi-buyer case where several buyers best response to each other. Interestingly, in the two-buyer case, essentially all commitments that satisfy a certain condition are equilibria.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">451</td>#}
<td class="tg-031e">ZUN LI, Zhenzhe Zheng, Fan Wu, Guihai Chen </td>
<td class="tg-031e">On Designing Optimal Data Purchasing Strategies for Online Ad Auctions</td>
{#<td class="tg-031e"> In online advertising, advertisers can purchase consumer relevant data from data marketplaces with a certain expenditure, and exploit the purchased data to guide the bidding process in ad auctions. One of the pressing problem faced by advertisers is to design the optimal data purchasing strategy  in online ad auctions. In this paper, we model the data purchasing strategy design as a convex optimization problem, jointly considering the expenditure paid during data purchasing and the benefits obtained from ad auctions. Using the techniques from Baysian game theory and convex analysis, we derive the optimal purchasing strategies for advertisers in different market scenarios. We also theoretically prove that the resulting strategy profile is the unique one that achieves Nash Equilibrium. Our analysis shows that the proposed data purchasing strategy can handle diverse ad auctions and valuation learning models. Our numerical results further confirm intuitions that the advertisers would typically purchase less data to avoid the risks of wasted purchasing under fiercer competition, and purchase more to extract huger profits when the website gains more popularity.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">706</td>#}
<td class="tg-031e">Weiran Shen, Pingzhong Tang, Yulong Zeng </td>
<td class="tg-031e">A Closed-Form Characterization of Buyer Signaling Schemes in Monopoly Pricing</td>
{#<td class="tg-031e"> We consider a setting where a revenue maximizing monopolist sells a single item to a buyer. A mediator first collects the buyer's value and can reveal extra information about the buyer's value by sending signals. Mathematically, a signal scheme can be thought of as a decomposition of the prior value distribution into a linear combination of posterior value distributions, and based on each of them, the monopolist separately posts a price. According to the theory of Bayesian persuasion, a well designed signal scheme can lead to utility improvements for both the monopolist and the buyer.  We put forward a novel technique to analyze the effects of signal schemes of the mediator. Using this technique, we are able to construct explicitly a closed-form solution, and thus characterize the set of seller-buyer utility pairs achievable by any signal scheme, for any prior type distribution. Our result generalizes a well-known result by Bergemann et. al., who derive a characterization for the same problem but only restricted to the discrete distribution case.   Similar to the result derived by Bergermann et. al., we show that the set of seller and buyer utility pairs achievable form a triangle: any point within the triangle can be achieved by an explicitly constructed signal scheme and any point outside the triangle cannot be achievable by any such scheme. Our result is obtained by establishing the endpoints of the triangle: one corresponds to the point where the buyer obtains the highest utility among all schemes, another corresponds to the point where the buyer obtains zero utility and the seller has the lowest possible revenue, and the third corresponds to the point where the buyer has zero utility while the seller extracts full social surplus. We then prove that the triangle described fully characterizes all possible&nbsp; signal schemes.  </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 43 (10:30-11:50)<br>Social Choice Theory 3</td>
{#<td class="tg-s6z2">168</td>#}
<td class="tg-031e">Enrico Malizia </td>
<td class="tg-031e">More complexity results about reasoning over CP-nets</td>
{#<td class="tg-031e">  Aggregating preferences over combinatorial domains has several applications in AI. Due to the exponential nature of combinatorial preferences, compact representations are needed, and CP-nets are among the most studied formalisms. Unlike CP-nets, which received an extensive complexity analysis, mCP-nets, as mentioned several times in the literature, lacked such a thorough characterization. In fact, an initial complexity analysis for mCP-nets was carried out only recently. In this paper, we further investigate the complexity of mCP-nets. In particular, we prove the \Sigma^P_3-completeness of the existence of Max optimal outcomes. Furthermore, we prove that various tasks known to be feasible in polynomial time are actually P-complete. This shows that these problems are inherently sequential, and hence they cannot benefit from highly parallel computation.   </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">172</td>#}
<td class="tg-031e">Dominik Peters </td>
<td class="tg-031e">Proportionality and Strategyproofness in Multiwinner Elections</td>
{#<td class="tg-031e"> Multiwinner voting rules can be used to select a fixed-size committee from a larger set of candidates.&nbsp;We consider approval-based committee rules, which allow voters to approve or disapprove candidates. In this setting, several voting rules such as Proportional Approval Voting  and Phragmén's rules have been shown to produce committees that are proportional, in the sense that they proportionally represent voters' preferences; all of these rules are strategically manipulable by voters. On the other hand, a generalisation of Approval Voting gives a non-proportional but strategyproof voting rule. We show that there is a fundamental tradeoff between these two properties: we prove that no multiwinner voting rule can simultaneously satisfy a weak form of proportionality  and a weak form of strategyproofness. Our impossibility is obtained using a formulation of the problem in propositional logic and applying SAT solvers; a human-readable version of the computer-generated proof is obtained by extracting a minimal unsatisfiable set . We also discuss several related axiomatic questions in the domain of committee elections.  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">267</td>#}
<td class="tg-031e">Zack Fitzsimmons, Edith Hemaspaandra </td>
<td class="tg-031e">High-Multiplicity Election Problems</td>
{#<td class="tg-031e">  The computational study of elections generally assumes that the preferences of the electorate come in as a list of votes. Depending on the context, it may be much more natural to represent the list succinctly, as the distinct votes of the electorate and their counts, i.e., high-multiplicity representation. We consider how this representation affects the complexity of election problems. High-multiplicity representation may be exponentially smaller than standard representation, and so many polynomial-time algorithms for election problems in standard representation become exponential. Surprisingly, for polynomial-time election problems, we are often able to either adapt the same approach or provide new algorithms to show that these problems remain polynomial-time in the high-multiplicity case; this is in sharp contrast to the case where each voter has a weight, where the complexity usually increases. In the process we explore the relationship between high-multiplicity scheduling and manipulation of high-multiplicity elections. And we show that for any fixed set of job lengths, high-multiplicity scheduling on uniform parallel machines is in P, which was previously known for only two job lengths. We did not find any natural case where a polynomial-time election problem does not remain in P when moving to high-multiplicity representation. However, we found one natural NP-hard election problem where the complexity does increase, namely   winner determination for Kemeny elections.   </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">510</td>#}
<td class="tg-031e">Cynthia Maushagen, Marc Neveling, Jorg Rothe, Ann-Kathrin Selker </td>
<td class="tg-031e">Complexity of Shift Bribery in Iterative Elections</td>
{#<td class="tg-031e"> In iterative voting systems, candidates are eliminated in consecutive rounds until either a fixed number of rounds is reached or the set of remaining candidates does not change anymore. We focus on iterative voting systems based on the positional scoring rules plurality, veto, and Borda and study their resistance against shift bribery attacks. In constructive shift bribery, an attacker seeks to make a designated candidate win the election by bribing voters to shift this candidate in their preferences; in destructive shift bribery, the briber’s goal is to prevent this candidate’s victory. We show that many iterative voting systems, including those due to Hare, Coombs, Baldwin, and Nanson, are resistant to these types of attack.  </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 44 (10:30-11:50)<br>Agent Cooperation 2</td>
{#<td class="tg-s6z2">516</td>#}
<td class="tg-031e">Luca Becchetti, Vincenzo Bonifaci, Emanuele Natale </td>
<td class="tg-031e">Pooling or Sampling: Collective Dynamics for Electrical Flow Estimation</td>
{#<td class="tg-031e"> The computation of electrical flows is a crucial primitive for many#}
{#recently proposed optimization algorithms on weighted networks. While#}
{#typically implemented as a centralized subroutine, the ability to#}
{#perform this task in a fully decentralized way is implicit in a number#}
{#of biological systems. Thus, a natural question is whether this task can#}
{#provably be accomplished in an efficient way by a network of agents#}
{#executing a simple protocol.#}
{#  We provide a positive answer, proposing two distributed approaches to#}
{#electrical flow computation on a weighted network: a deterministic#}
{#process mimicking Jacobi's iterative method for solving linear systems,#}
{#and a randomized token diffusion process, based on revisiting a#}
{#classical random walk process on a graph with an absorbing node.#}
{#We show that both processes converge to a solution of Kirchhoff's node#}
{#potential equations, derive bounds on their convergence rates in terms#}
{#of the weights of the network, and analyze their time and message#}
{#complexity.&nbsp;    </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">136</td>#}
<td class="tg-031e">Md. Mosaddek Khan, Long Tran-Thanh, Nick Jennings </td>
<td class="tg-031e">A Generic Domain Pruning Technique for GDL-based DCOP algorithms in Cooperative Multi-Agent Systems</td>
{#<td class="tg-031e">  Generalized Distributive Law  based message passing algorithms, such as Max-Sum and Bounded Max-Sum, are often used to solve distributed constraint optimization problems in cooperative multi-agent systems . However, scalability becomes a challenge when these algorithms have to deal with constraint functions with high arity or variables with a large domain size. In either case, the ensuing exponential growth of search space can make such algorithms computationally infeasible in practice. To address this issue, we develop a generic domain pruning technique that enables these algorithms to be effectively applied to larger and more complex problems. We theoretically prove that the pruned search space obtained by our approach does not affect the outcome of the algorithms. Moreover, our empirical evaluation illustrates a significant reduction of the search space, ranging from   33%   to   81%,  without affecting the solution quality of the algorithms, compared to the state-of-the-art. &nbsp;&nbsp;  </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">138</td>#}
<td class="tg-031e">Md. Mosaddek Khan, Long Tran-Thanh, William Yeoh, Nick Jennings </td>
<td class="tg-031e">A Near-Optimal Node-to-Agent Mapping Heuristic for GDL-based DCOP Algorithms in Multi-Agent Systems</td>
{#<td class="tg-031e">Distributed Constraint Optimization Problems  can be used#}
{#to model a number of multi-agent coordination problems. The conventional DCOP model assumes that the subproblem that each agent#}
{#is responsible for  is part of the model description. While this assumption is#}
{#often reasonable, there are many applications where there is some#}
{#ﬂexibility in making this assignment. In this paper, we focus on#}
{#this gap and make the following contributions:  We formulate#}
{#this problem as an optimization problem, where the goal is to fnd#}
{#an assignment that minimizes the completion time of the DCOP#}
{#algorithm  that operates on this mapping.  We propose a novel heuristic, called MNA, that can be#}
{#executed in a centralized or decentralized manner.  Our empirical evaluation illustrates a substantial reduction in completion time,#}
{#ranging from 16% to 40%, without affecting the solution quality of#}
{#the algorithms, compared to the current state-of-the-art. In addition,#}
{#we observe empirically that the completion time obtained from our#}
{#approach is near-optimal; it never exceeds more than 10% of what#}
{#can be achieved from the optimal node-to-agent mapping.</td>#}
</tr>
<tr>
{#<td class="tg-s6z2">371</td>#}
<td class="tg-031e">Lily Hu,Bryan Wilder, Amulya Yadav, Eric Rice, Milind Tambe </td>
<td class="tg-031e">Activating the "Breakfast Club": Modeling Influence Spread in Natural-World Social Networks</td>
{#<td class="tg-031e"> &nbsp; While reigning models of diffusion have privileged the structure of a given social network as the key to informational exchange, real human interactions do not appear to take place on a single graph of connections. Using data collected from a pilot study of the spread of HIV awareness in social networks of homeless youth, we show that health information did not diffuse in the field according to the processes outlined by dominant models. Since physical network diffusion scenarios often diverge from their more well-studied counterparts on digital networks, we propose an alternative Activation Jump Model  that describes information diffusion on physical networks from a multi-agent team perspective. Our model exhibits two main differentiating features from leading cascade and threshold models of influence spread: 1) The structural composition of a seed set team impacts each individual node's influencing behavior, and 2) an influencing node may spread information to non-neighbors. We show that the AJM significantly outperforms existing models in its fit to the observed node-level influence data on the youth networks. We then prove theoretical results, showing that the AJM exhibits many well-behaved properties shared by dominant models. Our results suggest that the AJM presents a flexible and more accurate model of network diffusion that may better inform influence maximization in the field. </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 45 (10:30-11:50)<br>Agent-Based Simulation 3</td>
{#<td class="tg-s6z2">542</td>#}
<td class="tg-031e">Meghendra Singh, Achla Marathe, Samarth Swarup, Madhav Marathe </td>
<td class="tg-031e">Behavior Model Calibration for Epidemic Simulations</td>
{#<td class="tg-031e">   Computational epidemiologists frequently employ large-scale agent-based simulations of human populations to study disease outbreaks and assess intervention strategies. The agents used in such simulations rarely capture the real-world decision-making of human beings. An absence of realistic agent behavior can undermine the reliability of insights generated by such simulations and might make them ill-suited for informing public health policies. In this paper, we address this problem by developing a methodology to create and calibrate an agent decision making model for a large multi-agent simulation, using survey data. Our method optimizes a cost vector associated with the various behaviors to match the behavior distributions observed in a detailed survey of human behaviors during influenza outbreaks. Our approach is a data driven way of incorporating decision making for agents in large-scale epidemic simulations.    </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">604</td>#}
<td class="tg-031e">S. S. Ravi, Daniel Rosenkrantz, Madhav Marathe, Richard Stearns </td>
<td class="tg-031e">Testing Phase Space Properties of Synchronous Dynamical Systems with Nested Canalyzing Local Functions</td>
{#<td class="tg-031e">  Discrete dynamical systems serve as effective formal models in many    contexts, including simulations of agent-based models, propagation    of contagions in social networks and study of biological phenomena.    A class of Boolean functions, called nested canalyzing functions ,   have been found as good models of certain biological    phenomena.&nbsp; Motivated by these biological applications, we study a    variety of analysis problems for synchronous dynamical systems     over the Boolean domain, where each local function is a    nested canalyzing function. Each analysis problem involves testing    whether the phase space of a given SyDS satisfies a certain property.    Problems considered include reachability, predecessor existence,    fixed point existence and garden of Eden existence.&nbsp; We present    computational intractability results for some problems as well as efficient    algorithms for other problems.&nbsp; In many cases, our results provide    a clear delineation between intractable and efficiently     solvable&nbsp; versions of problems. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">494</td>#}
<td class="tg-031e">Daniel Y. Fu, Emily S. Wang, Peter Krafft, Barbara Grosz </td>
<td class="tg-031e">Influencing Flock Formation in Low-Density Settings</td>
{#<td class="tg-031e"> Flocking is a coordinated collective behavior that results from local sensing between individual agents who have a tendency to orient towards each other. Flocking is common amongst animal groups and could also be useful in robotic swarms. In the interest of learning how to control flocking behavior, several pieces of recent work in the multiagent systems literature have explored the use of influencing agents for guiding flocking agents to face a target direction. However, the existing work in this domain has focused on simulation settings of small areas with toroidal shapes. In such settings, agent density is high, so interactions are common, and flock formation occurs easily. In our work, we study new environments with lower agent density, wherein interactions are more rare. We study the efficacy of placement strategies and influencing agent behaviors drawn from the literature, and find that the behaviors that have been shown to work well in high-density conditions tend to be much less effective in the environments we introduce. The source of this ineffectiveness is a tendency of influencing agents explored in prior work to face directions intended for maximal influence that actually separate the influencing agents from the flock. We find that in low-density conditions maintaining a connection to the flock is more important than rushing to orient towards the desired direction. We use these insights to propose new placement strategies and influencing agent behaviors that overcome the difficulties posed by our new environments. The best influencing agents we identify act like normal members of the flock to achieve positions that allow for control, and then exert their influence. We dub this strategy "follow-then-influence." </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">234</td>#}
<td class="tg-031e">F. Jordan Srour, Neil Yorke-Smith </td>
<td class="tg-031e">On Collusion and Coercion: Agent Interconnectedness and In-Group Behaviour</td>
{#<td class="tg-031e"> The interconnectedness of actors is an antecedent for collective corruption, which in turn can lead to endemic corruption in a society. As a testbed for studying the effects of social interconnectedness on corrupt behaviours, we examine the domain of maritime customs. Taking an extant agent-based simulation, we add to the simulation a nuanced model of actor relatedness, consisting of clan, in-group, and town of origin, and encode associated behavioural norms. We examine the effects of social interconnectedness on domain performance metrics such as revenue, container outcomes, time, coercive demands, and collusion. Results confirm that, when corruption is widespread, localized punitive- or incentive-based policies are weakened, and that the effect of process re-engineering is frustrated when interconnectedness increases beyond a critical point, for two out of three forms of homophily connections. Our work connects with and provides a complementary methodology to works in the political economy literature. </td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 46 (10:30-11:50)<br>Socially Interactive Agents 3</td>
{#<td class="tg-s6z2">S48</td>#}
<td class="tg-031e">Joana Campos, James Kennedy, Jill Fain Lehman</td>
<td class="tg-031e">Challenges in Exploiting Conversational Memory in Human-Agent Interaction</td>
{#<td class="tg-031e">In human interactions, language is used to project and maintain a social identity over time. The way people speak with others and revisit language across repeated interactions helps to create rapport and develop a feeling of coordination between conversational partners. Memory of past conversations is the main mechanism that allows us to exploit and explore ways of speaking, given knowledge acquired in previous encounters. As such, we introduce an agent that uses its conversational memory to revisit shared history with users to maintain a coherent social relationship over time. In this paper, we describe the dialog management mechanisms to achieve these goals when applied to a robot that engages in social chit-chat. In a study lasting 14 days with 28 users, totaling 474 interactions, we find that it is difficult to leverage the shared history with individual users and to also accommodate to expected conversational coordination patterns. We discuss the implications of this finding for long-term human-agent interaction. In particular, we highlight the importance of topic modeling and signaling explicit recall of previous episodes. Moreover, the way that users contribute to interactions requires additional adaptation, indicating a significant challenge for language interaction designers.</td>#}
</tr>
<tr>
{#<td class="tg-s6z2">S63</td>#}
<td class="tg-031e">Samuel Spaulding, Huili Chen, Safinah Ali, Michael Kulinski, Cynthia Breazeal</td>
<td class="tg-031e">A Social Robot System for Modeling Children's Word Pronunciation</td>
{#<td class="tg-031e">Autonomous educational social robots can be used to help promote literacy skills in young children. Such robots, which emulate the emotive, perceptual, and empathic abilities of human teachers, are capable of replicating some of the benefits of one-on-one tutoring from human teachers, in part by leveraging individual student's behavior and task performance data to infer sophisticated models of their knowledge. These student models are then used to provide personalized educational experiences by, for example, determining the optimal sequencing of curricular material. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">S37</td>#}
<td class="tg-031e">Brian Ravenet, Chloe Clavel, Catherine Pelachaud</td>
<td class="tg-031e">Automatic Nonverbal Behavior Generation from Image Schemas</td>
{#<td class="tg-031e">One of the main challenges when developing Embodied Conversational Agents is to give them the ability to autonomously produce meaningful and coordinated verbal and nonverbal behaviors. The relation between these means of communication is more complex than a direct mapping that has often been applied in previous models. In this paper, we propose an intermediate mapping approach we apply on metaphoric gestures first but that could be extended to other representational gestures. Leveraging from previous work in text analysis, embodied cognition and co-verbal behavior production, we introduce a framework articulating speech and metaphoric gesture invariants around a common mental representation: Image Schemas. We establish the components of our framework, detailing the different steps leading to the production of the metaphoric gestures, and we present some preliminary results and demonstrations. We end the paper by laying down the perspectives to integrate, evaluate and improve our model.</td>#}
</tr>
<tr>
{#<td class="tg-s6z2">S22</td>#}
<td class="tg-031e">Shivashankar Halan, Benjamin Lok, Isaac Sia, Anna Miles, Michael Crary</td>
<td class="tg-031e">Engineering Social Agent Creation into an Opportunity for Interviewing and Interpersonal Skills Training</td>
{#<td class="tg-031e">The use of intelligent, interactive social agents for clinical interviewing and interpersonal skills training in healthcare education has been observed to be on the increase. However, enabling rapid and scalable creation of robust and diverse intelligent social agents that can be integrated into educational curriculum for pedagogical reasons is still a challenge. In this paper, we present a novel approach for creating virtual patients  by reusing conversational corpus information from previous student-created interactive social agents. In this approach, healthcare students as part of an interpersonal skills training exercise create their own virtual patients. These virtual patient agents created are demonstrated to be effective tools to train other students in the future with their interviewing and interpersonal skills. By integrating virtual patient creation exercises in seven health professions courses over six years, we have demonstrated that healthcare students can create robust and diverse virtual patient social agents that can be used as pedagogical tools and in the process of creation also improve their own clinical interviewing and interpersonal skills.</td>#}
</tr>
<tr>
<td class="tg-s6z3" rowspan="4" nowrap>Session 47 (10:30-11:50)<br>Robotics: Planning</td>
{#<td class="tg-s6z2">R66</td>#}
<td class="tg-031e">Daniel Bebler, Mihai Pomarlan, Michael Beetz </td>
<td class="tg-031e">OWL-enabled Assembly Planning for Robotic Agents</td>
{#<td class="tg-031e">Assembly cells run by intelligent robotic agents promise highly flexible product customization without the cost implication product individualization has nowadays. One of the main questions an assembly robot has to answer is which sequence of manipulation actions it should perform to create an assembled product from scattered pieces available. We propose a novel approach to assembly planning that employs Description Logics  to describe what an assembled product should look like, and to plan the next action according to faulty and missing assertions in the robot's beliefs about an ongoing assembly task. To this end we extend the KnowRob knowledge base  with representations and inference rules that enable robots to reason about incomplete assemblies. We show that our approach performs well for large batches of assembly pieces available, as well as for varying structural complexity of assembled products.</td>#}
</tr>
<tr>
{#<td class="tg-s6z2">R83</td>#}
<td class="tg-031e">Alberto Quattrini Li, Raffaele Fioratto, Francesco Amigoni, Volkan Isler </td>
<td class="tg-031e">A Search-Based Approach to Solve Pursuit-Evasion Games with Limited Visibility in Polygonal Environments</td>
{#<td class="tg-031e"> A pursuit-evasion game is a non-cooperative game in which a pursuer tries to detect or capture an adversarial evader. We study a pursuit-evasion game which takes place in a known polygonal environment. The goal of the pursuer is to capture the evader by moving onto its location. The players can observe each others' locations only if they can ``see'' each other -- i.e., if the line segment connecting their locations lies entirely inside the polygonal environment.&nbsp;  The complexity of representing the information available to the players at a given time makes solving pursuit-evasion games with visibility limitations difficult.   We represent the state of the game using an efficient visibility-based decomposition of the environment paired with a more classical grid-based decomposition. The optimal players' strategies are computed using a min-max search algorithm improved with some speedup techniques that preserve optimality. We show that our approach is complete for a rash evader, which hides from the pursuer and does not move from its hiding location when the pursuer is not visible. Simulations in realistic indoor environments show the viability of our approach, compared to a Monte Carlo tree search. </td>#}
</tr>
<tr>
{#<td class="tg-s6z2">R85</td>#}
<td class="tg-031e">Anoop Aroor, Susan Epstein, Raj Korpan</td>
<td class="tg-031e">Online Learning for Crowd-sensitive Path Planning</td>
{#<td class="tg-031e">In crowded environments, the shortest path for an autonomous robot navigator may not be the best choice - another plan that avoids crowded areas might be preferable. Such a crowd-sensitive path planner, however, requires knowledge about the crowd's global behavior. This paper formulates a Bayesian approach that relies only on an onboard range scanner to learn a global crowd model online. Two new algorithms, CUSUM-A* and Risk-A*, use local observations to continuously update the crowd model. CUSUM-A* tracks the spatio-temporal changes in the crowd; Risk-A* adjusts for changes in navigation cost due to human-robot interactions. Extensive evaluation in a challenging simulated environment demonstrates that both algorithms generate plans that significantly reduce their proximity to moving obstacles, and thereby protect people from actuator error and inspire their trust in the robot.</td>#}
</tr>
<tr>
{#<td class="tg-s6z2">R102</td>#}
<td class="tg-031e">Julia Ebert, Melvin Gauci, Radhika Nagpal </td>
<td class="tg-031e">Multi-Feature Collective Decision Making in Robot Swarms</td>
{#<td class="tg-031e">Collective decision making has been studied extensively in the fields of multi-agent systems and swarm robotics, inspired by its pervasiveness in biological systems such as honeybee and ant colonies. However, most previous research has focused on collective decision making on a single feature. In this work, we introduce and investigate the multi-feature collective decision making problem, where a collective must decide on multiple binary features simultaneously, given no a priori information about their relative difficulties. Each agent may only estimate one feature at any given time, but the agents can locally communicate their noisy estimates to arrive at a decision.  We demonstrate a decentralized algorithm for single-feature decision making and a dynamic task allocation strategy that allows the agents to lock in decisions on multiple features in finite time. We validate our approach using simulated and physical Kilobot robots. Our results show that a collective can correctly classify a multi-feature environment, even if presented with pathological initial agent-to-feature allocations.</td>#}
</tr>
    </table>
</div>

{% endblock %}